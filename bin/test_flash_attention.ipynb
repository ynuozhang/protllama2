{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, DatasetDict, load_from_disk, concatenate_datasets\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['attention_mask', 'input_ids', 'labels'],\n        num_rows: 253440\n    })\n    valid: Dataset({\n        features: ['attention_mask', 'input_ids', 'labels'],\n        num_rows: 232711\n    })\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = f'/data/rozen/home/e0833634/lama/protllama/batch_script/uniref50_random90split_8k_512_first_1million_dataset.hf'\n",
    "dataset = load_from_disk(dataset_path)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['attention_mask', 'input_ids', 'labels'],\n        num_rows: 10\n    })\n    valid: Dataset({\n        features: ['attention_mask', 'input_ids', 'labels'],\n        num_rows: 10\n    })\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset_dict = DatasetDict({\n",
    "    'train': dataset['train'].select(range(10)),\n",
    "    'valid': dataset['valid'].select(range(10))\n",
    "})\n",
    "small_dataset_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d25f7d8c2974cf4bb59aab57efad7a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea840d728cef4190b1e31d47c9ee8645"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_dataset_dict.save_to_disk('small_small.hf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[[769188, 769231, 769281, 770055, 770166, 770414],\n [55962],\n [951805, 951834],\n [34696, 36909],\n [39459, 39650, 39713, 39794, 39797, 39858, 40168, 40532, 40713, 40750, 41035],\n [139898, 139951, 140097],\n [223249, 224129],\n [181],\n [227032,\n  227315,\n  227702,\n  227839,\n  227841,\n  228178,\n  228288,\n  228420,\n  228457,\n  228582],\n [94817, 94880]]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/data/rozen/home/e0833634/lama/protllama/batch_script/train_intermediate_checkpoint_batches_1000000.pkl', 'rb') as f:\n",
    "    batch_indices_train = pickle.load(f)\n",
    "batch_indices_train = batch_indices_train[:10]\n",
    "batch_indices_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[[178154, 178417],\n [913267, 913283, 913593, 913710, 913882, 913995],\n [419540],\n [291646, 292406],\n [63716, 63773, 63979, 64054, 64094, 64127, 64206, 64264, 64340, 64459, 64520],\n [363967, 364260, 364909],\n [595243, 595280, 595306, 595422, 595542],\n [220497],\n [78772, 79030],\n [689663, 689682]]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/data/rozen/home/e0833634/lama/protllama/batch_script/valid_intermediate_checkpoint_batches_1000000.pkl', 'rb') as f:\n",
    "    batch_indices_val = pickle.load(f)\n",
    "batch_indices_val = batch_indices_val[:10]\n",
    "batch_indices_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class DynamicBatchingDataset(Dataset):\n",
    "    def __init__(self, dataset_dict, batch_indices):\n",
    "        print('Initializing dataset...')\n",
    "        self.dataset_dict = dataset_dict\n",
    "        self.batch_indices = batch_indices  # This is mainly for informational purposes, if needed.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_dict['attention_mask'])  # Assuming each entry in dataset_dict represents a batch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Check if idx is an integer or a list\n",
    "        if isinstance(idx, int):\n",
    "            indices = [idx]\n",
    "        else:\n",
    "            indices = idx\n",
    "\n",
    "        attention_masks = []\n",
    "        input_ids = []\n",
    "        labels = []\n",
    "        for index in indices:\n",
    "            attention_masks.append(torch.tensor(self.dataset_dict['attention_mask'][index]))\n",
    "            input_ids.append(torch.tensor(self.dataset_dict['input_ids'][index]))\n",
    "            labels.append(torch.tensor(self.dataset_dict['labels'][index]))\n",
    "\n",
    "        return {\n",
    "            'attention_mask': attention_masks,\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # Since DataLoader's batch_size is 1, batch[0] contains your pre-batched data\n",
    "        item = batch[0]\n",
    "\n",
    "        attention_mask = item['attention_mask'][0]\n",
    "        input_ids = item['input_ids'][0]\n",
    "        labels = item['labels'][0]\n",
    "\n",
    "        # These are already pre-padded, so you can directly return\n",
    "        return {\n",
    "            'attention_mask': attention_mask,\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def dynamic_padding_collate_fn(batch):\n",
    "        # Extract sequences from the batch\n",
    "        #print(batch)\n",
    "\n",
    "        attention_masks = [item['attention_mask'] for item in batch]\n",
    "        input_ids = [item['input_ids'] for item in batch]\n",
    "        labels = [item['labels'] for item in batch]\n",
    "        #print(attention_masks.size())\n",
    "        # Flatten the sequences and then pad them\n",
    "        attention_masks_flat = [sequence for batch_item in attention_masks for sequence in batch_item]\n",
    "        print([seq.shape for seq in attention_masks_flat])\n",
    "        print(attention_masks_flat)\n",
    "        input_ids_flat = [sequence for batch_item in input_ids for sequence in batch_item]\n",
    "        labels_flat = [sequence for batch_item in labels for sequence in batch_item]\n",
    "\n",
    "        # Pad sequences\n",
    "        attention_masks_padded = torch.cat(attention_masks_flat, dim=0)\n",
    "        input_ids_padded = torch.cat(input_ids_flat, dim=0)\n",
    "        labels_padded = torch.cat(labels_flat, dim=0)\n",
    "\n",
    "        attention_masks_padded = pad_sequence(attention_masks_flat, batch_first=True)\n",
    "        input_ids_padded = pad_sequence(input_ids_flat, batch_first=True)\n",
    "        labels_padded = pad_sequence(labels_flat, batch_first=True, padding_value=-100)\n",
    "\n",
    "        return {\n",
    "            'attention_mask': attention_masks_padded,\n",
    "            'input_ids': input_ids_padded,\n",
    "            'labels': labels_padded\n",
    "        }\n",
    "\n",
    "train_dataset = DynamicBatchingDataset(small_dataset_dict['train'], batch_indices_train)\n",
    "\n",
    "# Batch size is set to 1 because your dataset itself is returning batches\n",
    "#train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=DynamicBatchingDataset.custom_collate_fn)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=DynamicBatchingDataset.collate_fn, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 84])\n",
      "0 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  390,  817,  325,  881,  545, 4579, 2698, 3853,  400, 3222,  811,\n",
      "         5410,  757, 1580,  312, 2013, 1832,  689, 2295, 3041, 3967,  762, 5632,\n",
      "         2307, 4670, 3743,  300, 5307,  343, 2685, 3989, 5093, 4627, 4023,  771,\n",
      "         3396, 6661,  220,  379, 6834,  771, 3306, 1659, 4508, 5596, 2220, 2892,\n",
      "          461,    4, 2068, 1108, 1198, 2766, 2828, 1009,  585, 2566, 3824, 6189,\n",
      "          666, 1509, 5843, 1419,  172,  810, 4278,  931,  707, 4049,  470, 5006,\n",
      "         1181, 1208, 1271, 3306,  505, 3989, 4959, 3861,  356, 4102, 3154,  611],\n",
      "        [   1,  820, 1919, 4465, 1017, 1241, 4424, 2858, 1017,   53, 2874, 3400,\n",
      "         1248,  617,  737,   54,  409,  591,  924,   37, 4884, 6452, 1225, 3224,\n",
      "          378, 2301,  434, 6762,  663, 3534,   72, 4146,  464, 1098,   45, 1134,\n",
      "          348, 1982, 3944, 4862,  995,  485, 4882, 1472, 4226,   54,  995, 1209,\n",
      "         5196,  277, 1428,  582, 2211,  552,  784, 4702, 6476,  787, 3076,  236,\n",
      "          314, 5817, 1042, 1265,   61, 3873,  381, 2263, 5040,  330, 1234,  282,\n",
      "          742, 6747, 7776, 6029,  210, 4271, 5760,  907, 2704,  517, 5292, 1141],\n",
      "        [   1, 1171, 7708,   34, 4009, 1036, 3470,   74, 1039, 2396,  606, 2432,\n",
      "          337,  356,  402,  894, 1974,  212, 3452, 6420, 1611, 5894, 3857, 5713,\n",
      "         1353, 2464, 2909, 4248, 4887,   21, 5170, 2999, 5670, 3389,  729, 3524,\n",
      "         1726,  191,  337, 5388, 5772, 3095,  610,  946, 1610,  330,  339, 5085,\n",
      "         5794, 3690, 3926,  337, 1711, 7155, 6247,  306, 7910,    6,  845, 3122,\n",
      "         7642,  341,  846,  613,  416, 4251, 1209, 1946, 5173, 7705, 2679, 7705,\n",
      "          679, 1321, 4645, 1305,  716,  363,  790, 1968, 3273,  605,  101,  706],\n",
      "        [   1, 4052,   47,  516,   21, 1253, 1603, 1026, 1306, 4156, 4988,  661,\n",
      "         2514, 1590, 5005, 5831, 3966, 6830, 6751, 1786, 4531,  606, 2634, 1216,\n",
      "         1304, 4026, 4617,  383,  244,  412,  437,  947, 3502, 3457, 1408,  863,\n",
      "         2632, 1345,  383, 1905, 2024,  809, 1291, 5253, 2583, 1435,  903,   25,\n",
      "          804, 3076,  781, 2702,  137,   21,  500,  921,  891,  579, 1996, 3865,\n",
      "         1681, 1455,   22, 5327, 1399, 3981, 1424, 3171,   32, 2521, 1496,  838,\n",
      "         4514, 1324,  591, 2282,  483,  889, 7513,  276, 6409, 3009, 4022, 4962],\n",
      "        [   1,   28,  807, 6219,  114, 7396,  133, 4094, 2677,  791, 1501, 3151,\n",
      "         2209, 1532,  921,  867, 2447,  561, 2958, 7742, 1086, 5403, 3735, 4276,\n",
      "         5093,  998, 2591, 3703, 3297, 7128, 2520, 3234,  183, 2091, 2077,  970,\n",
      "          291,  519, 1742,  869, 2382,   33,  953, 2084, 2341,    3, 1365, 2507,\n",
      "         5127, 2217, 2430,  262, 3214, 4115, 3266,  381, 5441,  425, 5146, 4858,\n",
      "         1218,  426, 4543, 1727, 5532, 4994, 5937, 3778, 2912, 6576, 3879, 4238,\n",
      "         2751, 1493, 1522, 1090, 1214,  498, 6998,  137, 2846,  480,  366,  324],\n",
      "        [   1, 7322,  680,  648, 3056,  449,  634,  607, 1337, 3661, 1483,  599,\n",
      "          875, 1645, 3648,   47,  409, 3993, 2543, 1437,  317, 6480, 2885,  577,\n",
      "          478, 2763,  934, 1639, 4523, 1769, 7046, 3417, 1386,  620, 1788, 1711,\n",
      "         6623,  774, 6154, 1438, 3898,  505, 4123, 1321, 5935,   29, 1754,  878,\n",
      "         1755, 4279, 1447, 1102,  724, 1263, 5214,  618, 3792,  486,  342, 4051,\n",
      "         2855, 1510, 1531, 4306,  715,  136, 1182, 3362, 1651, 1342, 2957,  424,\n",
      "           65, 3007, 4999, 2133, 3529, 2606,  647, 1214, 3637, 2996, 5330, 6755]]), 'labels': tensor([[   1,  390,  817,  325,  881,  545, 4579, 2698, 3853,  400, 3222,  811,\n",
      "         5410,  757, 1580,  312, 2013, 1832,  689, 2295, 3041, 3967,  762, 5632,\n",
      "         2307, 4670, 3743,  300, 5307,  343, 2685, 3989, 5093, 4627, 4023,  771,\n",
      "         3396, 6661,  220,  379, 6834,  771, 3306, 1659, 4508, 5596, 2220, 2892,\n",
      "          461,    4, 2068, 1108, 1198, 2766, 2828, 1009,  585, 2566, 3824, 6189,\n",
      "          666, 1509, 5843, 1419,  172,  810, 4278,  931,  707, 4049,  470, 5006,\n",
      "         1181, 1208, 1271, 3306,  505, 3989, 4959, 3861,  356, 4102, 3154,  611],\n",
      "        [   1,  820, 1919, 4465, 1017, 1241, 4424, 2858, 1017,   53, 2874, 3400,\n",
      "         1248,  617,  737,   54,  409,  591,  924,   37, 4884, 6452, 1225, 3224,\n",
      "          378, 2301,  434, 6762,  663, 3534,   72, 4146,  464, 1098,   45, 1134,\n",
      "          348, 1982, 3944, 4862,  995,  485, 4882, 1472, 4226,   54,  995, 1209,\n",
      "         5196,  277, 1428,  582, 2211,  552,  784, 4702, 6476,  787, 3076,  236,\n",
      "          314, 5817, 1042, 1265,   61, 3873,  381, 2263, 5040,  330, 1234,  282,\n",
      "          742, 6747, 7776, 6029,  210, 4271, 5760,  907, 2704,  517, 5292, 1141],\n",
      "        [   1, 1171, 7708,   34, 4009, 1036, 3470,   74, 1039, 2396,  606, 2432,\n",
      "          337,  356,  402,  894, 1974,  212, 3452, 6420, 1611, 5894, 3857, 5713,\n",
      "         1353, 2464, 2909, 4248, 4887,   21, 5170, 2999, 5670, 3389,  729, 3524,\n",
      "         1726,  191,  337, 5388, 5772, 3095,  610,  946, 1610,  330,  339, 5085,\n",
      "         5794, 3690, 3926,  337, 1711, 7155, 6247,  306, 7910,    6,  845, 3122,\n",
      "         7642,  341,  846,  613,  416, 4251, 1209, 1946, 5173, 7705, 2679, 7705,\n",
      "          679, 1321, 4645, 1305,  716,  363,  790, 1968, 3273,  605,  101,  706],\n",
      "        [   1, 4052,   47,  516,   21, 1253, 1603, 1026, 1306, 4156, 4988,  661,\n",
      "         2514, 1590, 5005, 5831, 3966, 6830, 6751, 1786, 4531,  606, 2634, 1216,\n",
      "         1304, 4026, 4617,  383,  244,  412,  437,  947, 3502, 3457, 1408,  863,\n",
      "         2632, 1345,  383, 1905, 2024,  809, 1291, 5253, 2583, 1435,  903,   25,\n",
      "          804, 3076,  781, 2702,  137,   21,  500,  921,  891,  579, 1996, 3865,\n",
      "         1681, 1455,   22, 5327, 1399, 3981, 1424, 3171,   32, 2521, 1496,  838,\n",
      "         4514, 1324,  591, 2282,  483,  889, 7513,  276, 6409, 3009, 4022, 4962],\n",
      "        [   1,   28,  807, 6219,  114, 7396,  133, 4094, 2677,  791, 1501, 3151,\n",
      "         2209, 1532,  921,  867, 2447,  561, 2958, 7742, 1086, 5403, 3735, 4276,\n",
      "         5093,  998, 2591, 3703, 3297, 7128, 2520, 3234,  183, 2091, 2077,  970,\n",
      "          291,  519, 1742,  869, 2382,   33,  953, 2084, 2341,    3, 1365, 2507,\n",
      "         5127, 2217, 2430,  262, 3214, 4115, 3266,  381, 5441,  425, 5146, 4858,\n",
      "         1218,  426, 4543, 1727, 5532, 4994, 5937, 3778, 2912, 6576, 3879, 4238,\n",
      "         2751, 1493, 1522, 1090, 1214,  498, 6998,  137, 2846,  480,  366,  324],\n",
      "        [   1, 7322,  680,  648, 3056,  449,  634,  607, 1337, 3661, 1483,  599,\n",
      "          875, 1645, 3648,   47,  409, 3993, 2543, 1437,  317, 6480, 2885,  577,\n",
      "          478, 2763,  934, 1639, 4523, 1769, 7046, 3417, 1386,  620, 1788, 1711,\n",
      "         6623,  774, 6154, 1438, 3898,  505, 4123, 1321, 5935,   29, 1754,  878,\n",
      "         1755, 4279, 1447, 1102,  724, 1263, 5214,  618, 3792,  486,  342, 4051,\n",
      "         2855, 1510, 1531, 4306,  715,  136, 1182, 3362, 1651, 1342, 2957,  424,\n",
      "           65, 3007, 4999, 2133, 3529, 2606,  647, 1214, 3637, 2996, 5330, 6755]])}\n",
      "tensor([[   1,  390,  817,  325,  881,  545, 4579, 2698, 3853,  400, 3222,  811,\n",
      "         5410,  757, 1580,  312, 2013, 1832,  689, 2295, 3041, 3967,  762, 5632,\n",
      "         2307, 4670, 3743,  300, 5307,  343, 2685, 3989, 5093, 4627, 4023,  771,\n",
      "         3396, 6661,  220,  379, 6834,  771, 3306, 1659, 4508, 5596, 2220, 2892,\n",
      "          461,    4, 2068, 1108, 1198, 2766, 2828, 1009,  585, 2566, 3824, 6189,\n",
      "          666, 1509, 5843, 1419,  172,  810, 4278,  931,  707, 4049,  470, 5006,\n",
      "         1181, 1208, 1271, 3306,  505, 3989, 4959, 3861,  356, 4102, 3154,  611],\n",
      "        [   1,  820, 1919, 4465, 1017, 1241, 4424, 2858, 1017,   53, 2874, 3400,\n",
      "         1248,  617,  737,   54,  409,  591,  924,   37, 4884, 6452, 1225, 3224,\n",
      "          378, 2301,  434, 6762,  663, 3534,   72, 4146,  464, 1098,   45, 1134,\n",
      "          348, 1982, 3944, 4862,  995,  485, 4882, 1472, 4226,   54,  995, 1209,\n",
      "         5196,  277, 1428,  582, 2211,  552,  784, 4702, 6476,  787, 3076,  236,\n",
      "          314, 5817, 1042, 1265,   61, 3873,  381, 2263, 5040,  330, 1234,  282,\n",
      "          742, 6747, 7776, 6029,  210, 4271, 5760,  907, 2704,  517, 5292, 1141],\n",
      "        [   1, 1171, 7708,   34, 4009, 1036, 3470,   74, 1039, 2396,  606, 2432,\n",
      "          337,  356,  402,  894, 1974,  212, 3452, 6420, 1611, 5894, 3857, 5713,\n",
      "         1353, 2464, 2909, 4248, 4887,   21, 5170, 2999, 5670, 3389,  729, 3524,\n",
      "         1726,  191,  337, 5388, 5772, 3095,  610,  946, 1610,  330,  339, 5085,\n",
      "         5794, 3690, 3926,  337, 1711, 7155, 6247,  306, 7910,    6,  845, 3122,\n",
      "         7642,  341,  846,  613,  416, 4251, 1209, 1946, 5173, 7705, 2679, 7705,\n",
      "          679, 1321, 4645, 1305,  716,  363,  790, 1968, 3273,  605,  101,  706],\n",
      "        [   1, 4052,   47,  516,   21, 1253, 1603, 1026, 1306, 4156, 4988,  661,\n",
      "         2514, 1590, 5005, 5831, 3966, 6830, 6751, 1786, 4531,  606, 2634, 1216,\n",
      "         1304, 4026, 4617,  383,  244,  412,  437,  947, 3502, 3457, 1408,  863,\n",
      "         2632, 1345,  383, 1905, 2024,  809, 1291, 5253, 2583, 1435,  903,   25,\n",
      "          804, 3076,  781, 2702,  137,   21,  500,  921,  891,  579, 1996, 3865,\n",
      "         1681, 1455,   22, 5327, 1399, 3981, 1424, 3171,   32, 2521, 1496,  838,\n",
      "         4514, 1324,  591, 2282,  483,  889, 7513,  276, 6409, 3009, 4022, 4962],\n",
      "        [   1,   28,  807, 6219,  114, 7396,  133, 4094, 2677,  791, 1501, 3151,\n",
      "         2209, 1532,  921,  867, 2447,  561, 2958, 7742, 1086, 5403, 3735, 4276,\n",
      "         5093,  998, 2591, 3703, 3297, 7128, 2520, 3234,  183, 2091, 2077,  970,\n",
      "          291,  519, 1742,  869, 2382,   33,  953, 2084, 2341,    3, 1365, 2507,\n",
      "         5127, 2217, 2430,  262, 3214, 4115, 3266,  381, 5441,  425, 5146, 4858,\n",
      "         1218,  426, 4543, 1727, 5532, 4994, 5937, 3778, 2912, 6576, 3879, 4238,\n",
      "         2751, 1493, 1522, 1090, 1214,  498, 6998,  137, 2846,  480,  366,  324],\n",
      "        [   1, 7322,  680,  648, 3056,  449,  634,  607, 1337, 3661, 1483,  599,\n",
      "          875, 1645, 3648,   47,  409, 3993, 2543, 1437,  317, 6480, 2885,  577,\n",
      "          478, 2763,  934, 1639, 4523, 1769, 7046, 3417, 1386,  620, 1788, 1711,\n",
      "         6623,  774, 6154, 1438, 3898,  505, 4123, 1321, 5935,   29, 1754,  878,\n",
      "         1755, 4279, 1447, 1102,  724, 1263, 5214,  618, 3792,  486,  342, 4051,\n",
      "         2855, 1510, 1531, 4306,  715,  136, 1182, 3362, 1651, 1342, 2957,  424,\n",
      "           65, 3007, 4999, 2133, 3529, 2606,  647, 1214, 3637, 2996, 5330, 6755]])\n",
      "torch.Size([1, 331])\n",
      "1 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,   28, 3312, 4266, 2308, 1219, 2665, 1052, 6285,  164,  411,  763,\n",
      "          760, 1737, 6201, 3094, 2154, 2344, 5860, 7077,  374,  472, 7350, 4553,\n",
      "         1061, 1254, 2222, 2739, 2237, 2823, 7070, 2058, 1121, 2672, 5592,  987,\n",
      "         2171,  751, 4233,  696,   55,  908, 2149, 3049,  928, 2605, 2578,  370,\n",
      "         4472, 1064, 1291,  224,  162, 1482, 5744, 7558,  983, 1940,  691, 7570,\n",
      "         1567,  436, 2667, 2250, 1060,  625, 2229, 4668,  949,  140, 3011, 1959,\n",
      "         5673,  798, 1685, 2393,  452,  670,  759, 1558, 2864, 1041, 5518,  119,\n",
      "          889,  711, 3631, 2562, 1294, 2593, 1484, 4434, 3037, 4208, 3096,  613,\n",
      "         5596, 3820,  192, 2169, 4229,  825,  596, 3919,  141, 1549, 4692, 2247,\n",
      "         1919, 1012,  648, 1870, 6303, 1648,  422, 4305, 1114,    6, 3947, 4162,\n",
      "         4547, 5194, 2131, 4992, 5694, 3414, 2910, 4514, 3348,   86, 3929,  565,\n",
      "         3140,  827,   61, 4195,  282,  478, 3656,   51, 1107,  996, 3010,  970,\n",
      "           83, 1158, 1357, 4239,  226,  408, 2684, 3768, 2607, 6537,  924, 3098,\n",
      "          292,  752, 6317,   84,  242,  309, 5158,  284, 1909, 1277,  803, 5547,\n",
      "          440, 2414, 1458, 2629, 4801,  118,  690, 4322, 3482, 4563, 5003, 5452,\n",
      "         1920, 2468, 2046,  307, 4248, 7985,   44, 1574, 4310, 5485,   41, 3735,\n",
      "         6127, 3588,  327, 4205, 2239, 3828,   62, 3605, 2813, 2334, 2274, 1975,\n",
      "          857,  773,  629, 2038, 1005, 5770, 1608, 4084,  132,  736, 2318, 4522,\n",
      "          162, 3868,  590, 5828, 4519, 2570,  577, 1805,  613, 1529, 1296, 2199,\n",
      "         7640, 2486, 4636,  102, 4170, 4427,   16,   95, 1205, 1364, 6847,  511,\n",
      "         2281, 4215,  346, 1653,  150, 4343,  691,  852,  955,  957, 6160,  120,\n",
      "         4641,  544, 6930, 7429, 1180, 6074, 6856,   16, 3996, 1799, 7919, 1045,\n",
      "         2887, 1452,   47, 6844, 1522, 3440,   49, 2498, 4131, 3835,  584,  350,\n",
      "          688, 6349, 2712,  428,  815,  982, 2392, 1195, 1824, 4168, 1368,  305,\n",
      "         3075, 1524, 2150, 7203,  891, 1318, 1633, 2186,  971, 1067, 3896, 2725,\n",
      "         2910,  799,  502, 2769, 4050, 2588, 1138,  341, 3523,   79, 4255, 1454,\n",
      "         1770,  963,  814,  380, 1321,   80, 3036, 6044, 2327, 3429,   61, 3494,\n",
      "         1928,  114, 1426, 1803,  311, 7235, 1686]]), 'labels': tensor([[   1,   28, 3312, 4266, 2308, 1219, 2665, 1052, 6285,  164,  411,  763,\n",
      "          760, 1737, 6201, 3094, 2154, 2344, 5860, 7077,  374,  472, 7350, 4553,\n",
      "         1061, 1254, 2222, 2739, 2237, 2823, 7070, 2058, 1121, 2672, 5592,  987,\n",
      "         2171,  751, 4233,  696,   55,  908, 2149, 3049,  928, 2605, 2578,  370,\n",
      "         4472, 1064, 1291,  224,  162, 1482, 5744, 7558,  983, 1940,  691, 7570,\n",
      "         1567,  436, 2667, 2250, 1060,  625, 2229, 4668,  949,  140, 3011, 1959,\n",
      "         5673,  798, 1685, 2393,  452,  670,  759, 1558, 2864, 1041, 5518,  119,\n",
      "          889,  711, 3631, 2562, 1294, 2593, 1484, 4434, 3037, 4208, 3096,  613,\n",
      "         5596, 3820,  192, 2169, 4229,  825,  596, 3919,  141, 1549, 4692, 2247,\n",
      "         1919, 1012,  648, 1870, 6303, 1648,  422, 4305, 1114,    6, 3947, 4162,\n",
      "         4547, 5194, 2131, 4992, 5694, 3414, 2910, 4514, 3348,   86, 3929,  565,\n",
      "         3140,  827,   61, 4195,  282,  478, 3656,   51, 1107,  996, 3010,  970,\n",
      "           83, 1158, 1357, 4239,  226,  408, 2684, 3768, 2607, 6537,  924, 3098,\n",
      "          292,  752, 6317,   84,  242,  309, 5158,  284, 1909, 1277,  803, 5547,\n",
      "          440, 2414, 1458, 2629, 4801,  118,  690, 4322, 3482, 4563, 5003, 5452,\n",
      "         1920, 2468, 2046,  307, 4248, 7985,   44, 1574, 4310, 5485,   41, 3735,\n",
      "         6127, 3588,  327, 4205, 2239, 3828,   62, 3605, 2813, 2334, 2274, 1975,\n",
      "          857,  773,  629, 2038, 1005, 5770, 1608, 4084,  132,  736, 2318, 4522,\n",
      "          162, 3868,  590, 5828, 4519, 2570,  577, 1805,  613, 1529, 1296, 2199,\n",
      "         7640, 2486, 4636,  102, 4170, 4427,   16,   95, 1205, 1364, 6847,  511,\n",
      "         2281, 4215,  346, 1653,  150, 4343,  691,  852,  955,  957, 6160,  120,\n",
      "         4641,  544, 6930, 7429, 1180, 6074, 6856,   16, 3996, 1799, 7919, 1045,\n",
      "         2887, 1452,   47, 6844, 1522, 3440,   49, 2498, 4131, 3835,  584,  350,\n",
      "          688, 6349, 2712,  428,  815,  982, 2392, 1195, 1824, 4168, 1368,  305,\n",
      "         3075, 1524, 2150, 7203,  891, 1318, 1633, 2186,  971, 1067, 3896, 2725,\n",
      "         2910,  799,  502, 2769, 4050, 2588, 1138,  341, 3523,   79, 4255, 1454,\n",
      "         1770,  963,  814,  380, 1321,   80, 3036, 6044, 2327, 3429,   61, 3494,\n",
      "         1928,  114, 1426, 1803,  311, 7235, 1686]])}\n",
      "tensor([[   1,   28, 3312, 4266, 2308, 1219, 2665, 1052, 6285,  164,  411,  763,\n",
      "          760, 1737, 6201, 3094, 2154, 2344, 5860, 7077,  374,  472, 7350, 4553,\n",
      "         1061, 1254, 2222, 2739, 2237, 2823, 7070, 2058, 1121, 2672, 5592,  987,\n",
      "         2171,  751, 4233,  696,   55,  908, 2149, 3049,  928, 2605, 2578,  370,\n",
      "         4472, 1064, 1291,  224,  162, 1482, 5744, 7558,  983, 1940,  691, 7570,\n",
      "         1567,  436, 2667, 2250, 1060,  625, 2229, 4668,  949,  140, 3011, 1959,\n",
      "         5673,  798, 1685, 2393,  452,  670,  759, 1558, 2864, 1041, 5518,  119,\n",
      "          889,  711, 3631, 2562, 1294, 2593, 1484, 4434, 3037, 4208, 3096,  613,\n",
      "         5596, 3820,  192, 2169, 4229,  825,  596, 3919,  141, 1549, 4692, 2247,\n",
      "         1919, 1012,  648, 1870, 6303, 1648,  422, 4305, 1114,    6, 3947, 4162,\n",
      "         4547, 5194, 2131, 4992, 5694, 3414, 2910, 4514, 3348,   86, 3929,  565,\n",
      "         3140,  827,   61, 4195,  282,  478, 3656,   51, 1107,  996, 3010,  970,\n",
      "           83, 1158, 1357, 4239,  226,  408, 2684, 3768, 2607, 6537,  924, 3098,\n",
      "          292,  752, 6317,   84,  242,  309, 5158,  284, 1909, 1277,  803, 5547,\n",
      "          440, 2414, 1458, 2629, 4801,  118,  690, 4322, 3482, 4563, 5003, 5452,\n",
      "         1920, 2468, 2046,  307, 4248, 7985,   44, 1574, 4310, 5485,   41, 3735,\n",
      "         6127, 3588,  327, 4205, 2239, 3828,   62, 3605, 2813, 2334, 2274, 1975,\n",
      "          857,  773,  629, 2038, 1005, 5770, 1608, 4084,  132,  736, 2318, 4522,\n",
      "          162, 3868,  590, 5828, 4519, 2570,  577, 1805,  613, 1529, 1296, 2199,\n",
      "         7640, 2486, 4636,  102, 4170, 4427,   16,   95, 1205, 1364, 6847,  511,\n",
      "         2281, 4215,  346, 1653,  150, 4343,  691,  852,  955,  957, 6160,  120,\n",
      "         4641,  544, 6930, 7429, 1180, 6074, 6856,   16, 3996, 1799, 7919, 1045,\n",
      "         2887, 1452,   47, 6844, 1522, 3440,   49, 2498, 4131, 3835,  584,  350,\n",
      "          688, 6349, 2712,  428,  815,  982, 2392, 1195, 1824, 4168, 1368,  305,\n",
      "         3075, 1524, 2150, 7203,  891, 1318, 1633, 2186,  971, 1067, 3896, 2725,\n",
      "         2910,  799,  502, 2769, 4050, 2588, 1138,  341, 3523,   79, 4255, 1454,\n",
      "         1770,  963,  814,  380, 1321,   80, 3036, 6044, 2327, 3429,   61, 3494,\n",
      "         1928,  114, 1426, 1803,  311, 7235, 1686]])\n",
      "torch.Size([2, 191])\n",
      "2 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,   28,  425,  643,  481, 2329,  841,  144, 5480, 1528,  434,   98,\n",
      "          794, 3818, 4905,  435, 1665, 1354,  853, 1869, 5901, 1184, 7909,  664,\n",
      "         4766,   20,  357, 5219, 7122, 1484, 2861, 4958,  443, 7387, 1650, 1385,\n",
      "         2494, 1201, 3444, 1166, 3346, 2041, 1034,  302, 2817, 5065, 3014,  953,\n",
      "          864, 1296, 3378,  865,  589,  661, 3076, 1191, 6644, 2507,   86, 3464,\n",
      "          308, 1842,  672, 4501,   32, 5916, 3328,  862, 1782, 1561,   32, 1321,\n",
      "          680, 7365, 7170, 2108, 2438, 1479,  419, 4610,  762,   37, 3939, 2382,\n",
      "          159, 6184, 1541, 3693,  320, 3457,  346,  552, 2236, 4494, 2809, 2892,\n",
      "          817, 2169, 6473, 2224, 2074, 4095, 5720, 3350, 1689,  892, 4599, 3284,\n",
      "          850, 2144, 4824,  317, 1845, 4416, 1115, 3415, 1187, 3178, 1157, 6919,\n",
      "         3964, 3752,  932, 4710, 1584, 6405, 3557, 1531, 2983, 5914,  928, 6838,\n",
      "         7257,  263,  104, 1423, 1869, 1011,  778, 5890, 1412,  619,  403, 3467,\n",
      "         1016, 1475, 5699, 2724,   42,  792, 5948, 1623, 2916, 6502,  538,  912,\n",
      "         3671, 2882,  218,  145, 1034, 2768, 1014, 1369, 2761,    3, 2022, 3531,\n",
      "         2492, 1092, 1303, 5330, 3891, 2992,  766, 1939,  690, 4877, 1559, 2348,\n",
      "          197,   52, 2320,  806, 2137, 5183,  518, 6415,  824,  395,  529],\n",
      "        [   1,  667,  183,  427, 4931, 4515,  383,  127, 4004, 7008, 1099, 2971,\n",
      "         1460, 2081, 1614, 5265, 2630, 1079, 5505, 1199, 2008,   62, 1724, 6706,\n",
      "         1460, 1554, 2128,  742,  452, 7967, 1074, 3352,  862, 1342, 2072, 7917,\n",
      "          794,  380, 2052,  879, 1965, 1649, 5974, 1649, 2612, 3189, 5891, 1023,\n",
      "          416,  358, 2781,  145, 1723, 1659, 2938, 1906,  513,  957, 3266, 2834,\n",
      "         7124, 2112, 3046, 6730, 1717,  989, 7050, 1878, 2308,   25, 1936, 1154,\n",
      "         3612,  587, 4068, 7029,  169, 3412, 5170, 5163, 1640, 1213, 3753, 2472,\n",
      "         1213, 1044, 3035, 1113, 6615, 1063, 1472,  452,  197,  896, 3138,  439,\n",
      "          277,  711, 2035, 1217,   44, 1907, 5005, 1281, 1626,  441, 2954,  233,\n",
      "          210, 7176,  361,  961, 1119, 1437,  925, 3969, 3522, 1391, 1359,  718,\n",
      "         5415,  516, 2475, 5024,   42, 2188,  829,  269, 1249,  749, 4930, 2898,\n",
      "         1824, 1048, 2822,   74, 1585, 1227, 7317, 3419,  852,  600, 3209,  365,\n",
      "         4814, 2541, 1054, 5164, 1462, 1436,  401, 7612, 4203, 1383, 5827,  540,\n",
      "         6251,  913, 1212, 3902, 1081, 4888, 1622, 1322, 3445, 5657,  788, 1067,\n",
      "          475, 1615, 1710, 2788, 4594,  994,  603, 6322, 5661, 7699, 3936, 2681,\n",
      "         6660, 7329, 1575,  138,  296, 3051, 3906, 1483, 5301,    4, 1491]]), 'labels': tensor([[   1,   28,  425,  643,  481, 2329,  841,  144, 5480, 1528,  434,   98,\n",
      "          794, 3818, 4905,  435, 1665, 1354,  853, 1869, 5901, 1184, 7909,  664,\n",
      "         4766,   20,  357, 5219, 7122, 1484, 2861, 4958,  443, 7387, 1650, 1385,\n",
      "         2494, 1201, 3444, 1166, 3346, 2041, 1034,  302, 2817, 5065, 3014,  953,\n",
      "          864, 1296, 3378,  865,  589,  661, 3076, 1191, 6644, 2507,   86, 3464,\n",
      "          308, 1842,  672, 4501,   32, 5916, 3328,  862, 1782, 1561,   32, 1321,\n",
      "          680, 7365, 7170, 2108, 2438, 1479,  419, 4610,  762,   37, 3939, 2382,\n",
      "          159, 6184, 1541, 3693,  320, 3457,  346,  552, 2236, 4494, 2809, 2892,\n",
      "          817, 2169, 6473, 2224, 2074, 4095, 5720, 3350, 1689,  892, 4599, 3284,\n",
      "          850, 2144, 4824,  317, 1845, 4416, 1115, 3415, 1187, 3178, 1157, 6919,\n",
      "         3964, 3752,  932, 4710, 1584, 6405, 3557, 1531, 2983, 5914,  928, 6838,\n",
      "         7257,  263,  104, 1423, 1869, 1011,  778, 5890, 1412,  619,  403, 3467,\n",
      "         1016, 1475, 5699, 2724,   42,  792, 5948, 1623, 2916, 6502,  538,  912,\n",
      "         3671, 2882,  218,  145, 1034, 2768, 1014, 1369, 2761,    3, 2022, 3531,\n",
      "         2492, 1092, 1303, 5330, 3891, 2992,  766, 1939,  690, 4877, 1559, 2348,\n",
      "          197,   52, 2320,  806, 2137, 5183,  518, 6415,  824,  395,  529],\n",
      "        [   1,  667,  183,  427, 4931, 4515,  383,  127, 4004, 7008, 1099, 2971,\n",
      "         1460, 2081, 1614, 5265, 2630, 1079, 5505, 1199, 2008,   62, 1724, 6706,\n",
      "         1460, 1554, 2128,  742,  452, 7967, 1074, 3352,  862, 1342, 2072, 7917,\n",
      "          794,  380, 2052,  879, 1965, 1649, 5974, 1649, 2612, 3189, 5891, 1023,\n",
      "          416,  358, 2781,  145, 1723, 1659, 2938, 1906,  513,  957, 3266, 2834,\n",
      "         7124, 2112, 3046, 6730, 1717,  989, 7050, 1878, 2308,   25, 1936, 1154,\n",
      "         3612,  587, 4068, 7029,  169, 3412, 5170, 5163, 1640, 1213, 3753, 2472,\n",
      "         1213, 1044, 3035, 1113, 6615, 1063, 1472,  452,  197,  896, 3138,  439,\n",
      "          277,  711, 2035, 1217,   44, 1907, 5005, 1281, 1626,  441, 2954,  233,\n",
      "          210, 7176,  361,  961, 1119, 1437,  925, 3969, 3522, 1391, 1359,  718,\n",
      "         5415,  516, 2475, 5024,   42, 2188,  829,  269, 1249,  749, 4930, 2898,\n",
      "         1824, 1048, 2822,   74, 1585, 1227, 7317, 3419,  852,  600, 3209,  365,\n",
      "         4814, 2541, 1054, 5164, 1462, 1436,  401, 7612, 4203, 1383, 5827,  540,\n",
      "         6251,  913, 1212, 3902, 1081, 4888, 1622, 1322, 3445, 5657,  788, 1067,\n",
      "          475, 1615, 1710, 2788, 4594,  994,  603, 6322, 5661, 7699, 3936, 2681,\n",
      "         6660, 7329, 1575,  138,  296, 3051, 3906, 1483, 5301,    4, 1491]])}\n",
      "tensor([[   1,   28,  425,  643,  481, 2329,  841,  144, 5480, 1528,  434,   98,\n",
      "          794, 3818, 4905,  435, 1665, 1354,  853, 1869, 5901, 1184, 7909,  664,\n",
      "         4766,   20,  357, 5219, 7122, 1484, 2861, 4958,  443, 7387, 1650, 1385,\n",
      "         2494, 1201, 3444, 1166, 3346, 2041, 1034,  302, 2817, 5065, 3014,  953,\n",
      "          864, 1296, 3378,  865,  589,  661, 3076, 1191, 6644, 2507,   86, 3464,\n",
      "          308, 1842,  672, 4501,   32, 5916, 3328,  862, 1782, 1561,   32, 1321,\n",
      "          680, 7365, 7170, 2108, 2438, 1479,  419, 4610,  762,   37, 3939, 2382,\n",
      "          159, 6184, 1541, 3693,  320, 3457,  346,  552, 2236, 4494, 2809, 2892,\n",
      "          817, 2169, 6473, 2224, 2074, 4095, 5720, 3350, 1689,  892, 4599, 3284,\n",
      "          850, 2144, 4824,  317, 1845, 4416, 1115, 3415, 1187, 3178, 1157, 6919,\n",
      "         3964, 3752,  932, 4710, 1584, 6405, 3557, 1531, 2983, 5914,  928, 6838,\n",
      "         7257,  263,  104, 1423, 1869, 1011,  778, 5890, 1412,  619,  403, 3467,\n",
      "         1016, 1475, 5699, 2724,   42,  792, 5948, 1623, 2916, 6502,  538,  912,\n",
      "         3671, 2882,  218,  145, 1034, 2768, 1014, 1369, 2761,    3, 2022, 3531,\n",
      "         2492, 1092, 1303, 5330, 3891, 2992,  766, 1939,  690, 4877, 1559, 2348,\n",
      "          197,   52, 2320,  806, 2137, 5183,  518, 6415,  824,  395,  529],\n",
      "        [   1,  667,  183,  427, 4931, 4515,  383,  127, 4004, 7008, 1099, 2971,\n",
      "         1460, 2081, 1614, 5265, 2630, 1079, 5505, 1199, 2008,   62, 1724, 6706,\n",
      "         1460, 1554, 2128,  742,  452, 7967, 1074, 3352,  862, 1342, 2072, 7917,\n",
      "          794,  380, 2052,  879, 1965, 1649, 5974, 1649, 2612, 3189, 5891, 1023,\n",
      "          416,  358, 2781,  145, 1723, 1659, 2938, 1906,  513,  957, 3266, 2834,\n",
      "         7124, 2112, 3046, 6730, 1717,  989, 7050, 1878, 2308,   25, 1936, 1154,\n",
      "         3612,  587, 4068, 7029,  169, 3412, 5170, 5163, 1640, 1213, 3753, 2472,\n",
      "         1213, 1044, 3035, 1113, 6615, 1063, 1472,  452,  197,  896, 3138,  439,\n",
      "          277,  711, 2035, 1217,   44, 1907, 5005, 1281, 1626,  441, 2954,  233,\n",
      "          210, 7176,  361,  961, 1119, 1437,  925, 3969, 3522, 1391, 1359,  718,\n",
      "         5415,  516, 2475, 5024,   42, 2188,  829,  269, 1249,  749, 4930, 2898,\n",
      "         1824, 1048, 2822,   74, 1585, 1227, 7317, 3419,  852,  600, 3209,  365,\n",
      "         4814, 2541, 1054, 5164, 1462, 1436,  401, 7612, 4203, 1383, 5827,  540,\n",
      "         6251,  913, 1212, 3902, 1081, 4888, 1622, 1322, 3445, 5657,  788, 1067,\n",
      "          475, 1615, 1710, 2788, 4594,  994,  603, 6322, 5661, 7699, 3936, 2681,\n",
      "         6660, 7329, 1575,  138,  296, 3051, 3906, 1483, 5301,    4, 1491]])\n",
      "torch.Size([2, 224])\n",
      "3 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,   28, 2321,  514,  561, 1289,  702,  495, 2762, 3921,  171, 1652,\n",
      "           34,  802,  961,   29,  492, 2122, 1324, 2131, 1554, 5040, 3060, 2877,\n",
      "          685, 1848,  928,  937, 4941, 2739, 3690, 3425,  392, 7477, 2214, 2106,\n",
      "         1854, 1987, 5807,  450, 1493, 1241, 2941,  361,  691, 2028,  492, 6679,\n",
      "          748, 4544,  229, 3967, 2387, 4470,  710,  660,  933,  176,  364, 7410,\n",
      "         4649,  803, 2486, 2297, 2030,  466, 2385, 5254, 1512, 1418, 3248, 2483,\n",
      "          364, 1808, 1796,  336,  423, 6562, 6562, 2982,  748, 3082,  905,  333,\n",
      "         1603, 2641, 1201, 1547, 1302,  130, 5460, 1039, 2971, 3357, 2585, 2393,\n",
      "         4415,  414,  717,  583, 1665, 1951, 3141, 4942, 3326,  209,  633, 6186,\n",
      "           66, 2123, 2257, 1426, 2598, 2486, 1260, 1324, 5258,  638, 1340,  748,\n",
      "         3957,  679, 1295, 4726,  288, 2222, 3739,  911,  459,  612, 1710, 1632,\n",
      "         2828,  949, 1215, 2652, 2965, 1573, 6856, 2937, 1326,   87,  722,  435,\n",
      "          848, 1785, 1233,  963, 1420, 3744, 1063, 1119, 3127, 1074, 2519, 2656,\n",
      "          526, 1380, 5201, 3414,  188, 1113, 1189,  828, 3545, 2893, 6681, 2248,\n",
      "          371, 4564, 2406, 6303, 2284, 3239, 1202, 4872, 1472, 2391, 2500,  129,\n",
      "         4229,  508, 2102, 2412, 3412, 5404,  171, 1805, 2265, 7535, 1079, 4429,\n",
      "          828, 1684,  526, 6691, 3138,   55,  788, 6385,  106, 3485, 3224, 6521,\n",
      "         2532,  391, 6766, 2891, 2714, 1285, 7305, 3259,  635, 2264, 1091,  698,\n",
      "          672,  311, 2205, 6358, 5468, 5827,  466,    3],\n",
      "        [   1,  252, 1552, 2911, 1804, 2075, 2301, 1258, 3541, 1045, 2831, 1083,\n",
      "            4, 6965,   26,  409, 1454,  917, 1056, 7617, 1875,   25, 4803, 3459,\n",
      "         2299,  524, 7206, 2859,  288,  860, 3506, 1924, 2965,  135, 3522, 7150,\n",
      "         1462, 2088, 2459, 2424, 5513, 4322,  463, 2473,  917, 4142, 1440, 2963,\n",
      "         7425, 1275, 1534,  881,  729, 1667, 4075, 3266, 3058, 5300, 1033, 1439,\n",
      "         7491,  183, 2280,  791, 3697, 1089, 2727, 4464, 1048,  926, 4707,  631,\n",
      "         3240,  467,  625, 1286,  125, 6919,  101,  429, 3018, 1079,  560, 4836,\n",
      "         4751, 6779,  311, 2017, 3397,  543, 4050, 2506,  759, 3573, 3916, 1564,\n",
      "         4243, 3876, 3241, 3400, 6128, 6929, 2233, 3467,  933,  750, 3051,  763,\n",
      "         3381, 4541,  676, 2053,  187, 2168, 1227, 7313,  287,  261,  287,  206,\n",
      "          478, 3610,  919, 2107, 1256, 5619, 7815,   89, 5837,  594, 3941, 3819,\n",
      "          257, 3172, 2926, 2632, 1800, 2674, 4278, 6165, 1086,  582,  984, 2360,\n",
      "         3067, 3535,  537, 2426, 1352,  229, 2160,  937,  386, 1857, 1293,  927,\n",
      "         2340, 7991,  715, 2856, 3934,  316, 2116, 1414,    3, 4446, 2735, 4426,\n",
      "         1455, 5565, 1356, 2091,  835, 3261,  899, 2693, 1348, 1667, 1133, 2924,\n",
      "          978, 2827,  985, 2611,    3,  844, 1728,  772, 6497, 2186, 1200, 2114,\n",
      "         7998, 7875, 2376, 4065, 6116, 3666,  970,  841,  581,  171, 4678, 1021,\n",
      "         2776, 1872,   95, 1311, 6226,  486, 1872, 1070, 4842, 7622,  867, 1098,\n",
      "         3590, 3115, 4715, 2670,  372,  744, 4323,   15]]), 'labels': tensor([[   1,   28, 2321,  514,  561, 1289,  702,  495, 2762, 3921,  171, 1652,\n",
      "           34,  802,  961,   29,  492, 2122, 1324, 2131, 1554, 5040, 3060, 2877,\n",
      "          685, 1848,  928,  937, 4941, 2739, 3690, 3425,  392, 7477, 2214, 2106,\n",
      "         1854, 1987, 5807,  450, 1493, 1241, 2941,  361,  691, 2028,  492, 6679,\n",
      "          748, 4544,  229, 3967, 2387, 4470,  710,  660,  933,  176,  364, 7410,\n",
      "         4649,  803, 2486, 2297, 2030,  466, 2385, 5254, 1512, 1418, 3248, 2483,\n",
      "          364, 1808, 1796,  336,  423, 6562, 6562, 2982,  748, 3082,  905,  333,\n",
      "         1603, 2641, 1201, 1547, 1302,  130, 5460, 1039, 2971, 3357, 2585, 2393,\n",
      "         4415,  414,  717,  583, 1665, 1951, 3141, 4942, 3326,  209,  633, 6186,\n",
      "           66, 2123, 2257, 1426, 2598, 2486, 1260, 1324, 5258,  638, 1340,  748,\n",
      "         3957,  679, 1295, 4726,  288, 2222, 3739,  911,  459,  612, 1710, 1632,\n",
      "         2828,  949, 1215, 2652, 2965, 1573, 6856, 2937, 1326,   87,  722,  435,\n",
      "          848, 1785, 1233,  963, 1420, 3744, 1063, 1119, 3127, 1074, 2519, 2656,\n",
      "          526, 1380, 5201, 3414,  188, 1113, 1189,  828, 3545, 2893, 6681, 2248,\n",
      "          371, 4564, 2406, 6303, 2284, 3239, 1202, 4872, 1472, 2391, 2500,  129,\n",
      "         4229,  508, 2102, 2412, 3412, 5404,  171, 1805, 2265, 7535, 1079, 4429,\n",
      "          828, 1684,  526, 6691, 3138,   55,  788, 6385,  106, 3485, 3224, 6521,\n",
      "         2532,  391, 6766, 2891, 2714, 1285, 7305, 3259,  635, 2264, 1091,  698,\n",
      "          672,  311, 2205, 6358, 5468, 5827,  466,    3],\n",
      "        [   1,  252, 1552, 2911, 1804, 2075, 2301, 1258, 3541, 1045, 2831, 1083,\n",
      "            4, 6965,   26,  409, 1454,  917, 1056, 7617, 1875,   25, 4803, 3459,\n",
      "         2299,  524, 7206, 2859,  288,  860, 3506, 1924, 2965,  135, 3522, 7150,\n",
      "         1462, 2088, 2459, 2424, 5513, 4322,  463, 2473,  917, 4142, 1440, 2963,\n",
      "         7425, 1275, 1534,  881,  729, 1667, 4075, 3266, 3058, 5300, 1033, 1439,\n",
      "         7491,  183, 2280,  791, 3697, 1089, 2727, 4464, 1048,  926, 4707,  631,\n",
      "         3240,  467,  625, 1286,  125, 6919,  101,  429, 3018, 1079,  560, 4836,\n",
      "         4751, 6779,  311, 2017, 3397,  543, 4050, 2506,  759, 3573, 3916, 1564,\n",
      "         4243, 3876, 3241, 3400, 6128, 6929, 2233, 3467,  933,  750, 3051,  763,\n",
      "         3381, 4541,  676, 2053,  187, 2168, 1227, 7313,  287,  261,  287,  206,\n",
      "          478, 3610,  919, 2107, 1256, 5619, 7815,   89, 5837,  594, 3941, 3819,\n",
      "          257, 3172, 2926, 2632, 1800, 2674, 4278, 6165, 1086,  582,  984, 2360,\n",
      "         3067, 3535,  537, 2426, 1352,  229, 2160,  937,  386, 1857, 1293,  927,\n",
      "         2340, 7991,  715, 2856, 3934,  316, 2116, 1414,    3, 4446, 2735, 4426,\n",
      "         1455, 5565, 1356, 2091,  835, 3261,  899, 2693, 1348, 1667, 1133, 2924,\n",
      "          978, 2827,  985, 2611,    3,  844, 1728,  772, 6497, 2186, 1200, 2114,\n",
      "         7998, 7875, 2376, 4065, 6116, 3666,  970,  841,  581,  171, 4678, 1021,\n",
      "         2776, 1872,   95, 1311, 6226,  486, 1872, 1070, 4842, 7622,  867, 1098,\n",
      "         3590, 3115, 4715, 2670,  372,  744, 4323,   15]])}\n",
      "tensor([[   1,   28, 2321,  514,  561, 1289,  702,  495, 2762, 3921,  171, 1652,\n",
      "           34,  802,  961,   29,  492, 2122, 1324, 2131, 1554, 5040, 3060, 2877,\n",
      "          685, 1848,  928,  937, 4941, 2739, 3690, 3425,  392, 7477, 2214, 2106,\n",
      "         1854, 1987, 5807,  450, 1493, 1241, 2941,  361,  691, 2028,  492, 6679,\n",
      "          748, 4544,  229, 3967, 2387, 4470,  710,  660,  933,  176,  364, 7410,\n",
      "         4649,  803, 2486, 2297, 2030,  466, 2385, 5254, 1512, 1418, 3248, 2483,\n",
      "          364, 1808, 1796,  336,  423, 6562, 6562, 2982,  748, 3082,  905,  333,\n",
      "         1603, 2641, 1201, 1547, 1302,  130, 5460, 1039, 2971, 3357, 2585, 2393,\n",
      "         4415,  414,  717,  583, 1665, 1951, 3141, 4942, 3326,  209,  633, 6186,\n",
      "           66, 2123, 2257, 1426, 2598, 2486, 1260, 1324, 5258,  638, 1340,  748,\n",
      "         3957,  679, 1295, 4726,  288, 2222, 3739,  911,  459,  612, 1710, 1632,\n",
      "         2828,  949, 1215, 2652, 2965, 1573, 6856, 2937, 1326,   87,  722,  435,\n",
      "          848, 1785, 1233,  963, 1420, 3744, 1063, 1119, 3127, 1074, 2519, 2656,\n",
      "          526, 1380, 5201, 3414,  188, 1113, 1189,  828, 3545, 2893, 6681, 2248,\n",
      "          371, 4564, 2406, 6303, 2284, 3239, 1202, 4872, 1472, 2391, 2500,  129,\n",
      "         4229,  508, 2102, 2412, 3412, 5404,  171, 1805, 2265, 7535, 1079, 4429,\n",
      "          828, 1684,  526, 6691, 3138,   55,  788, 6385,  106, 3485, 3224, 6521,\n",
      "         2532,  391, 6766, 2891, 2714, 1285, 7305, 3259,  635, 2264, 1091,  698,\n",
      "          672,  311, 2205, 6358, 5468, 5827,  466,    3],\n",
      "        [   1,  252, 1552, 2911, 1804, 2075, 2301, 1258, 3541, 1045, 2831, 1083,\n",
      "            4, 6965,   26,  409, 1454,  917, 1056, 7617, 1875,   25, 4803, 3459,\n",
      "         2299,  524, 7206, 2859,  288,  860, 3506, 1924, 2965,  135, 3522, 7150,\n",
      "         1462, 2088, 2459, 2424, 5513, 4322,  463, 2473,  917, 4142, 1440, 2963,\n",
      "         7425, 1275, 1534,  881,  729, 1667, 4075, 3266, 3058, 5300, 1033, 1439,\n",
      "         7491,  183, 2280,  791, 3697, 1089, 2727, 4464, 1048,  926, 4707,  631,\n",
      "         3240,  467,  625, 1286,  125, 6919,  101,  429, 3018, 1079,  560, 4836,\n",
      "         4751, 6779,  311, 2017, 3397,  543, 4050, 2506,  759, 3573, 3916, 1564,\n",
      "         4243, 3876, 3241, 3400, 6128, 6929, 2233, 3467,  933,  750, 3051,  763,\n",
      "         3381, 4541,  676, 2053,  187, 2168, 1227, 7313,  287,  261,  287,  206,\n",
      "          478, 3610,  919, 2107, 1256, 5619, 7815,   89, 5837,  594, 3941, 3819,\n",
      "          257, 3172, 2926, 2632, 1800, 2674, 4278, 6165, 1086,  582,  984, 2360,\n",
      "         3067, 3535,  537, 2426, 1352,  229, 2160,  937,  386, 1857, 1293,  927,\n",
      "         2340, 7991,  715, 2856, 3934,  316, 2116, 1414,    3, 4446, 2735, 4426,\n",
      "         1455, 5565, 1356, 2091,  835, 3261,  899, 2693, 1348, 1667, 1133, 2924,\n",
      "          978, 2827,  985, 2611,    3,  844, 1728,  772, 6497, 2186, 1200, 2114,\n",
      "         7998, 7875, 2376, 4065, 6116, 3666,  970,  841,  581,  171, 4678, 1021,\n",
      "         2776, 1872,   95, 1311, 6226,  486, 1872, 1070, 4842, 7622,  867, 1098,\n",
      "         3590, 3115, 4715, 2670,  372,  744, 4323,   15]])\n",
      "torch.Size([11, 44])\n",
      "4 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  820,  913,  508,  398,  998, 5048, 7183, 4154,  359, 1084, 6002,\n",
      "         2395, 6218, 2849,  343,   60, 6066,  788, 5244, 3815,  641, 1205,   27,\n",
      "         1428, 5858, 6862,  884, 2088,  337,  570,  233, 7259, 6515, 6254, 1515,\n",
      "          343,  965,  362,  283, 4263, 1212,  123, 3569],\n",
      "        [   1,  820, 2303, 6106, 5525,  341,  168, 3634, 2631, 2993, 2178, 4621,\n",
      "         4678,  719,  743, 1207,  885,  343, 5187, 6536, 2521, 2934, 1929, 5842,\n",
      "          333,   33, 7059,  341,  550, 1973, 6494, 1453,  422, 2164, 5655, 2010,\n",
      "          708, 6512, 4200, 3976, 3115, 2070, 2635, 7548],\n",
      "        [   1,  667, 1265, 2223, 3870,  403,  555, 2655, 1510, 1315,  794,   98,\n",
      "         2059,  373,  489, 2248,  691,  509, 1327,  413, 2183, 3584, 4657, 4342,\n",
      "         1193, 1375,  753,  454, 1770, 1610, 1610,  683,  346, 1012,  698, 6129,\n",
      "         2301,  571, 6816,  488, 1375,  814,  866,  493],\n",
      "        [   1, 6550, 5506, 3160, 2745,   67,  928,  616, 5113,  132, 6687, 2497,\n",
      "         4918, 2684,   39,  892, 5317,  687, 6191, 3899, 1417, 3297, 3668, 1677,\n",
      "         4255, 1615, 1321, 1922, 3469, 1511,   97, 7122, 3122,  859,  919,  313,\n",
      "          201,  940,  947, 1897, 2002, 1184, 1033,   49],\n",
      "        [   1,   28,  651, 3282, 1713, 1247, 7217, 3463, 1254, 1474, 2146, 1657,\n",
      "         2706, 4474, 3480, 6580,   44, 4789, 2940, 1966, 2715, 6400, 2132, 7483,\n",
      "         1399,   63,  875, 2082,   66, 6981,  653, 1294, 1516, 3731, 2643, 3830,\n",
      "         1444,   40,   87, 4158, 2973,  570, 3838,  937],\n",
      "        [   1,   28, 6749, 6447,  535, 2132,  265, 3671, 1432,   85, 1912,  994,\n",
      "         1773, 4611, 4028,  980,  565, 3383,  164, 2992, 1883, 3733, 4009, 2965,\n",
      "          290, 7127,    6, 6862, 2378, 2157, 2247, 4021, 1551, 3434, 1011, 2341,\n",
      "         3880, 3735, 1347, 2911,  559, 2346,  393, 1233],\n",
      "        [   1,   28, 3653, 5485, 2150, 6396, 1365, 1611, 1321, 1676,  787, 6922,\n",
      "          900, 3706, 1124, 1543, 2467, 2135, 5709,  524, 2375, 1160, 3308,  708,\n",
      "         2272, 1094, 1296,  503,  242, 5581, 4763, 7507, 1418, 3498, 6407,  941,\n",
      "         1425, 2171, 3336, 4365,  683,  641,  163, 3654],\n",
      "        [   1,  252, 7988,  343,  503, 4885,  204,   37,  247, 3218,  432, 2717,\n",
      "         3715, 3087,  477, 2757, 1298, 3343,  281,  774, 6369, 1213,  453, 2083,\n",
      "          362, 4816, 3123, 3255, 5838, 6767,  618,  211, 6345,   15, 1707, 1130,\n",
      "         6674, 4743, 1341, 1877, 2033, 1020, 1589, 1553],\n",
      "        [   1,   28, 5290, 1259,  356, 4042, 1478,   70, 2403, 2553, 1964, 1036,\n",
      "          767,  262, 3424, 2422, 1259, 2299,  388,   47, 2576,  322,   15,  670,\n",
      "         5994, 1781, 3248, 1670, 2433, 1039, 7818, 4444, 2898, 1084,   43, 4253,\n",
      "         2126,  409,  286,  674,  383, 1340,  336, 3465],\n",
      "        [   1,  667, 1291, 2792,  158, 5780, 3501,  998, 3458, 1480, 1974, 1629,\n",
      "         3719, 1930,  695,  638, 2098, 2093,  177, 1909,  692, 1349,  875,  727,\n",
      "         1085, 1222, 4617,  905,  752, 2098,  838, 2857, 3288, 1703, 2038, 3635,\n",
      "         1004, 1641, 1693, 1202,  728,    6, 1025, 1149],\n",
      "        [   1, 3078, 1584, 2388,  733,  873, 3540, 4479, 7546, 4444,  555, 1737,\n",
      "          603,   21, 2033,  678, 2392,  722,  843, 1400, 2897, 1387, 1521,  774,\n",
      "         3762, 7458,  841, 1580, 1121, 4157,  613, 2171, 3109,  112, 6133, 1160,\n",
      "          461, 1800,  537,  423,   33, 2569,  364, 1204]]), 'labels': tensor([[   1,  820,  913,  508,  398,  998, 5048, 7183, 4154,  359, 1084, 6002,\n",
      "         2395, 6218, 2849,  343,   60, 6066,  788, 5244, 3815,  641, 1205,   27,\n",
      "         1428, 5858, 6862,  884, 2088,  337,  570,  233, 7259, 6515, 6254, 1515,\n",
      "          343,  965,  362,  283, 4263, 1212,  123, 3569],\n",
      "        [   1,  820, 2303, 6106, 5525,  341,  168, 3634, 2631, 2993, 2178, 4621,\n",
      "         4678,  719,  743, 1207,  885,  343, 5187, 6536, 2521, 2934, 1929, 5842,\n",
      "          333,   33, 7059,  341,  550, 1973, 6494, 1453,  422, 2164, 5655, 2010,\n",
      "          708, 6512, 4200, 3976, 3115, 2070, 2635, 7548],\n",
      "        [   1,  667, 1265, 2223, 3870,  403,  555, 2655, 1510, 1315,  794,   98,\n",
      "         2059,  373,  489, 2248,  691,  509, 1327,  413, 2183, 3584, 4657, 4342,\n",
      "         1193, 1375,  753,  454, 1770, 1610, 1610,  683,  346, 1012,  698, 6129,\n",
      "         2301,  571, 6816,  488, 1375,  814,  866,  493],\n",
      "        [   1, 6550, 5506, 3160, 2745,   67,  928,  616, 5113,  132, 6687, 2497,\n",
      "         4918, 2684,   39,  892, 5317,  687, 6191, 3899, 1417, 3297, 3668, 1677,\n",
      "         4255, 1615, 1321, 1922, 3469, 1511,   97, 7122, 3122,  859,  919,  313,\n",
      "          201,  940,  947, 1897, 2002, 1184, 1033,   49],\n",
      "        [   1,   28,  651, 3282, 1713, 1247, 7217, 3463, 1254, 1474, 2146, 1657,\n",
      "         2706, 4474, 3480, 6580,   44, 4789, 2940, 1966, 2715, 6400, 2132, 7483,\n",
      "         1399,   63,  875, 2082,   66, 6981,  653, 1294, 1516, 3731, 2643, 3830,\n",
      "         1444,   40,   87, 4158, 2973,  570, 3838,  937],\n",
      "        [   1,   28, 6749, 6447,  535, 2132,  265, 3671, 1432,   85, 1912,  994,\n",
      "         1773, 4611, 4028,  980,  565, 3383,  164, 2992, 1883, 3733, 4009, 2965,\n",
      "          290, 7127,    6, 6862, 2378, 2157, 2247, 4021, 1551, 3434, 1011, 2341,\n",
      "         3880, 3735, 1347, 2911,  559, 2346,  393, 1233],\n",
      "        [   1,   28, 3653, 5485, 2150, 6396, 1365, 1611, 1321, 1676,  787, 6922,\n",
      "          900, 3706, 1124, 1543, 2467, 2135, 5709,  524, 2375, 1160, 3308,  708,\n",
      "         2272, 1094, 1296,  503,  242, 5581, 4763, 7507, 1418, 3498, 6407,  941,\n",
      "         1425, 2171, 3336, 4365,  683,  641,  163, 3654],\n",
      "        [   1,  252, 7988,  343,  503, 4885,  204,   37,  247, 3218,  432, 2717,\n",
      "         3715, 3087,  477, 2757, 1298, 3343,  281,  774, 6369, 1213,  453, 2083,\n",
      "          362, 4816, 3123, 3255, 5838, 6767,  618,  211, 6345,   15, 1707, 1130,\n",
      "         6674, 4743, 1341, 1877, 2033, 1020, 1589, 1553],\n",
      "        [   1,   28, 5290, 1259,  356, 4042, 1478,   70, 2403, 2553, 1964, 1036,\n",
      "          767,  262, 3424, 2422, 1259, 2299,  388,   47, 2576,  322,   15,  670,\n",
      "         5994, 1781, 3248, 1670, 2433, 1039, 7818, 4444, 2898, 1084,   43, 4253,\n",
      "         2126,  409,  286,  674,  383, 1340,  336, 3465],\n",
      "        [   1,  667, 1291, 2792,  158, 5780, 3501,  998, 3458, 1480, 1974, 1629,\n",
      "         3719, 1930,  695,  638, 2098, 2093,  177, 1909,  692, 1349,  875,  727,\n",
      "         1085, 1222, 4617,  905,  752, 2098,  838, 2857, 3288, 1703, 2038, 3635,\n",
      "         1004, 1641, 1693, 1202,  728,    6, 1025, 1149],\n",
      "        [   1, 3078, 1584, 2388,  733,  873, 3540, 4479, 7546, 4444,  555, 1737,\n",
      "          603,   21, 2033,  678, 2392,  722,  843, 1400, 2897, 1387, 1521,  774,\n",
      "         3762, 7458,  841, 1580, 1121, 4157,  613, 2171, 3109,  112, 6133, 1160,\n",
      "          461, 1800,  537,  423,   33, 2569,  364, 1204]])}\n",
      "tensor([[   1,  820,  913,  508,  398,  998, 5048, 7183, 4154,  359, 1084, 6002,\n",
      "         2395, 6218, 2849,  343,   60, 6066,  788, 5244, 3815,  641, 1205,   27,\n",
      "         1428, 5858, 6862,  884, 2088,  337,  570,  233, 7259, 6515, 6254, 1515,\n",
      "          343,  965,  362,  283, 4263, 1212,  123, 3569],\n",
      "        [   1,  820, 2303, 6106, 5525,  341,  168, 3634, 2631, 2993, 2178, 4621,\n",
      "         4678,  719,  743, 1207,  885,  343, 5187, 6536, 2521, 2934, 1929, 5842,\n",
      "          333,   33, 7059,  341,  550, 1973, 6494, 1453,  422, 2164, 5655, 2010,\n",
      "          708, 6512, 4200, 3976, 3115, 2070, 2635, 7548],\n",
      "        [   1,  667, 1265, 2223, 3870,  403,  555, 2655, 1510, 1315,  794,   98,\n",
      "         2059,  373,  489, 2248,  691,  509, 1327,  413, 2183, 3584, 4657, 4342,\n",
      "         1193, 1375,  753,  454, 1770, 1610, 1610,  683,  346, 1012,  698, 6129,\n",
      "         2301,  571, 6816,  488, 1375,  814,  866,  493],\n",
      "        [   1, 6550, 5506, 3160, 2745,   67,  928,  616, 5113,  132, 6687, 2497,\n",
      "         4918, 2684,   39,  892, 5317,  687, 6191, 3899, 1417, 3297, 3668, 1677,\n",
      "         4255, 1615, 1321, 1922, 3469, 1511,   97, 7122, 3122,  859,  919,  313,\n",
      "          201,  940,  947, 1897, 2002, 1184, 1033,   49],\n",
      "        [   1,   28,  651, 3282, 1713, 1247, 7217, 3463, 1254, 1474, 2146, 1657,\n",
      "         2706, 4474, 3480, 6580,   44, 4789, 2940, 1966, 2715, 6400, 2132, 7483,\n",
      "         1399,   63,  875, 2082,   66, 6981,  653, 1294, 1516, 3731, 2643, 3830,\n",
      "         1444,   40,   87, 4158, 2973,  570, 3838,  937],\n",
      "        [   1,   28, 6749, 6447,  535, 2132,  265, 3671, 1432,   85, 1912,  994,\n",
      "         1773, 4611, 4028,  980,  565, 3383,  164, 2992, 1883, 3733, 4009, 2965,\n",
      "          290, 7127,    6, 6862, 2378, 2157, 2247, 4021, 1551, 3434, 1011, 2341,\n",
      "         3880, 3735, 1347, 2911,  559, 2346,  393, 1233],\n",
      "        [   1,   28, 3653, 5485, 2150, 6396, 1365, 1611, 1321, 1676,  787, 6922,\n",
      "          900, 3706, 1124, 1543, 2467, 2135, 5709,  524, 2375, 1160, 3308,  708,\n",
      "         2272, 1094, 1296,  503,  242, 5581, 4763, 7507, 1418, 3498, 6407,  941,\n",
      "         1425, 2171, 3336, 4365,  683,  641,  163, 3654],\n",
      "        [   1,  252, 7988,  343,  503, 4885,  204,   37,  247, 3218,  432, 2717,\n",
      "         3715, 3087,  477, 2757, 1298, 3343,  281,  774, 6369, 1213,  453, 2083,\n",
      "          362, 4816, 3123, 3255, 5838, 6767,  618,  211, 6345,   15, 1707, 1130,\n",
      "         6674, 4743, 1341, 1877, 2033, 1020, 1589, 1553],\n",
      "        [   1,   28, 5290, 1259,  356, 4042, 1478,   70, 2403, 2553, 1964, 1036,\n",
      "          767,  262, 3424, 2422, 1259, 2299,  388,   47, 2576,  322,   15,  670,\n",
      "         5994, 1781, 3248, 1670, 2433, 1039, 7818, 4444, 2898, 1084,   43, 4253,\n",
      "         2126,  409,  286,  674,  383, 1340,  336, 3465],\n",
      "        [   1,  667, 1291, 2792,  158, 5780, 3501,  998, 3458, 1480, 1974, 1629,\n",
      "         3719, 1930,  695,  638, 2098, 2093,  177, 1909,  692, 1349,  875,  727,\n",
      "         1085, 1222, 4617,  905,  752, 2098,  838, 2857, 3288, 1703, 2038, 3635,\n",
      "         1004, 1641, 1693, 1202,  728,    6, 1025, 1149],\n",
      "        [   1, 3078, 1584, 2388,  733,  873, 3540, 4479, 7546, 4444,  555, 1737,\n",
      "          603,   21, 2033,  678, 2392,  722,  843, 1400, 2897, 1387, 1521,  774,\n",
      "         3762, 7458,  841, 1580, 1121, 4157,  613, 2171, 3109,  112, 6133, 1160,\n",
      "          461, 1800,  537,  423,   33, 2569,  364, 1204]])\n",
      "torch.Size([3, 143])\n",
      "5 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  438, 3434, 2157, 7517, 1279, 2090, 6246, 3077, 1066,  734, 2369,\n",
      "         2968, 4480, 1765, 5634, 2336, 2158,  960, 6131, 1402, 1919,  832,  953,\n",
      "         3836,  118, 2473, 2620, 2030, 1643, 5503, 6367, 1704,   47, 4966,  217,\n",
      "         3400, 2003,  118,  551, 2775, 2989, 2625,  119, 1901, 7799, 6021, 2110,\n",
      "         3620, 2188, 4845,  708, 7906, 3629, 2224, 1609, 1045, 1085, 5331, 1965,\n",
      "          670, 1378,  793,  566, 1867, 7401, 5548,  756, 3251,  103,  573, 2087,\n",
      "           52,   65,  873, 6454, 1654, 3556,    6, 3612,  612, 2623,  734,  538,\n",
      "         3151, 1060, 1947, 1132, 1292, 7302, 1177, 7830, 2621,  300, 1277,  947,\n",
      "         3220,  717, 7890, 3009, 2149,   16, 3487, 2059, 5846, 1561,  254,  378,\n",
      "          343,  121, 1500, 2774, 1378, 2307,  214,  324, 1127,  727, 1523, 1728,\n",
      "         1023, 1651, 7608,  932,   58, 4432,  547,  977, 7821,  669, 5006,  591,\n",
      "         1281, 4381, 2660, 3579, 2295, 2741, 1459,  921,  379, 2691, 2267],\n",
      "        [   1,  438, 1867, 1244, 2359, 1522, 5144,  905,  154,  312, 6240,   73,\n",
      "         1663, 2386, 2153, 2497,  533, 3590,  796, 5269,   34, 2145,  724, 5354,\n",
      "         1880, 2062, 4266, 3815, 5771, 5101, 1345, 1121,  809, 7928,  993, 3713,\n",
      "          509, 2989, 2158, 2288, 1599, 7536,  118, 1264, 4516, 7255, 1330,  237,\n",
      "         3116, 3216,  285,  489,  737,  431, 1920, 3650, 1295,  603, 1633,  964,\n",
      "         3458, 1212,  804, 1110, 1771,   41,  982, 1035,  507, 1827, 1194, 4278,\n",
      "         5028, 3811, 1508, 4874, 1982, 6413, 3180, 3738, 1599,  444, 4613, 3484,\n",
      "         1495, 2205,  247, 1036, 3837, 1253, 3101, 2709, 1744,  414, 2075, 4174,\n",
      "         2226,  277,  623,  756, 1674, 2490,  793,  398, 2061,  163, 2190, 7165,\n",
      "          333,   25,  282,  951, 2892, 1572, 1893,  810,  171, 5957,  598, 4046,\n",
      "          790, 6026,  714, 2442, 4905, 1178, 2211, 1695, 6691, 3214, 4688,  815,\n",
      "          495, 1964, 5919, 6300, 2825, 2126, 2933, 3347, 4800, 7191,  104],\n",
      "        [   1,  438, 3162, 1295, 1032, 1700, 1603,  308, 3233,  691,  887,  628,\n",
      "         5681,  972, 1934, 3091,  608, 6753, 1105, 1569, 7193,  383,  375, 1616,\n",
      "         2731, 2386, 3722,  471, 3796, 6672, 6589,  530,  585,  453, 3991, 7498,\n",
      "          730, 3281,  774,  112, 3804,   56, 6230,  308,  739, 1122, 2425, 1982,\n",
      "          464,  757, 1612,  559, 1236, 6038, 7380, 4732, 7317,  760, 1740, 2057,\n",
      "         1199,  364,  654, 1945, 5722,  512, 5276,  684, 5320, 1357, 5955, 1941,\n",
      "         1464,  365, 2673, 6384, 6791, 1528,  971, 1073, 3583, 1396, 1467, 3295,\n",
      "         1642, 6389, 7020, 1534,  364, 2800, 4232,  612, 1823, 2240,  578, 1317,\n",
      "         6093,  726, 1472,  541,  142, 1100, 3991, 3711, 2391, 3876,  402, 2712,\n",
      "         1661,  870,   42, 1911,  495, 3359, 1393, 7668, 1224,  643, 1956,  403,\n",
      "         1535,  669, 2119, 2388,  357, 4679, 3272,  885,  623, 1621,  731, 5082,\n",
      "         7114,  640,  492,  804, 2464, 1395, 1628,  885,  790, 5236, 1330]]), 'labels': tensor([[   1,  438, 3434, 2157, 7517, 1279, 2090, 6246, 3077, 1066,  734, 2369,\n",
      "         2968, 4480, 1765, 5634, 2336, 2158,  960, 6131, 1402, 1919,  832,  953,\n",
      "         3836,  118, 2473, 2620, 2030, 1643, 5503, 6367, 1704,   47, 4966,  217,\n",
      "         3400, 2003,  118,  551, 2775, 2989, 2625,  119, 1901, 7799, 6021, 2110,\n",
      "         3620, 2188, 4845,  708, 7906, 3629, 2224, 1609, 1045, 1085, 5331, 1965,\n",
      "          670, 1378,  793,  566, 1867, 7401, 5548,  756, 3251,  103,  573, 2087,\n",
      "           52,   65,  873, 6454, 1654, 3556,    6, 3612,  612, 2623,  734,  538,\n",
      "         3151, 1060, 1947, 1132, 1292, 7302, 1177, 7830, 2621,  300, 1277,  947,\n",
      "         3220,  717, 7890, 3009, 2149,   16, 3487, 2059, 5846, 1561,  254,  378,\n",
      "          343,  121, 1500, 2774, 1378, 2307,  214,  324, 1127,  727, 1523, 1728,\n",
      "         1023, 1651, 7608,  932,   58, 4432,  547,  977, 7821,  669, 5006,  591,\n",
      "         1281, 4381, 2660, 3579, 2295, 2741, 1459,  921,  379, 2691, 2267],\n",
      "        [   1,  438, 1867, 1244, 2359, 1522, 5144,  905,  154,  312, 6240,   73,\n",
      "         1663, 2386, 2153, 2497,  533, 3590,  796, 5269,   34, 2145,  724, 5354,\n",
      "         1880, 2062, 4266, 3815, 5771, 5101, 1345, 1121,  809, 7928,  993, 3713,\n",
      "          509, 2989, 2158, 2288, 1599, 7536,  118, 1264, 4516, 7255, 1330,  237,\n",
      "         3116, 3216,  285,  489,  737,  431, 1920, 3650, 1295,  603, 1633,  964,\n",
      "         3458, 1212,  804, 1110, 1771,   41,  982, 1035,  507, 1827, 1194, 4278,\n",
      "         5028, 3811, 1508, 4874, 1982, 6413, 3180, 3738, 1599,  444, 4613, 3484,\n",
      "         1495, 2205,  247, 1036, 3837, 1253, 3101, 2709, 1744,  414, 2075, 4174,\n",
      "         2226,  277,  623,  756, 1674, 2490,  793,  398, 2061,  163, 2190, 7165,\n",
      "          333,   25,  282,  951, 2892, 1572, 1893,  810,  171, 5957,  598, 4046,\n",
      "          790, 6026,  714, 2442, 4905, 1178, 2211, 1695, 6691, 3214, 4688,  815,\n",
      "          495, 1964, 5919, 6300, 2825, 2126, 2933, 3347, 4800, 7191,  104],\n",
      "        [   1,  438, 3162, 1295, 1032, 1700, 1603,  308, 3233,  691,  887,  628,\n",
      "         5681,  972, 1934, 3091,  608, 6753, 1105, 1569, 7193,  383,  375, 1616,\n",
      "         2731, 2386, 3722,  471, 3796, 6672, 6589,  530,  585,  453, 3991, 7498,\n",
      "          730, 3281,  774,  112, 3804,   56, 6230,  308,  739, 1122, 2425, 1982,\n",
      "          464,  757, 1612,  559, 1236, 6038, 7380, 4732, 7317,  760, 1740, 2057,\n",
      "         1199,  364,  654, 1945, 5722,  512, 5276,  684, 5320, 1357, 5955, 1941,\n",
      "         1464,  365, 2673, 6384, 6791, 1528,  971, 1073, 3583, 1396, 1467, 3295,\n",
      "         1642, 6389, 7020, 1534,  364, 2800, 4232,  612, 1823, 2240,  578, 1317,\n",
      "         6093,  726, 1472,  541,  142, 1100, 3991, 3711, 2391, 3876,  402, 2712,\n",
      "         1661,  870,   42, 1911,  495, 3359, 1393, 7668, 1224,  643, 1956,  403,\n",
      "         1535,  669, 2119, 2388,  357, 4679, 3272,  885,  623, 1621,  731, 5082,\n",
      "         7114,  640,  492,  804, 2464, 1395, 1628,  885,  790, 5236, 1330]])}\n",
      "tensor([[   1,  438, 3434, 2157, 7517, 1279, 2090, 6246, 3077, 1066,  734, 2369,\n",
      "         2968, 4480, 1765, 5634, 2336, 2158,  960, 6131, 1402, 1919,  832,  953,\n",
      "         3836,  118, 2473, 2620, 2030, 1643, 5503, 6367, 1704,   47, 4966,  217,\n",
      "         3400, 2003,  118,  551, 2775, 2989, 2625,  119, 1901, 7799, 6021, 2110,\n",
      "         3620, 2188, 4845,  708, 7906, 3629, 2224, 1609, 1045, 1085, 5331, 1965,\n",
      "          670, 1378,  793,  566, 1867, 7401, 5548,  756, 3251,  103,  573, 2087,\n",
      "           52,   65,  873, 6454, 1654, 3556,    6, 3612,  612, 2623,  734,  538,\n",
      "         3151, 1060, 1947, 1132, 1292, 7302, 1177, 7830, 2621,  300, 1277,  947,\n",
      "         3220,  717, 7890, 3009, 2149,   16, 3487, 2059, 5846, 1561,  254,  378,\n",
      "          343,  121, 1500, 2774, 1378, 2307,  214,  324, 1127,  727, 1523, 1728,\n",
      "         1023, 1651, 7608,  932,   58, 4432,  547,  977, 7821,  669, 5006,  591,\n",
      "         1281, 4381, 2660, 3579, 2295, 2741, 1459,  921,  379, 2691, 2267],\n",
      "        [   1,  438, 1867, 1244, 2359, 1522, 5144,  905,  154,  312, 6240,   73,\n",
      "         1663, 2386, 2153, 2497,  533, 3590,  796, 5269,   34, 2145,  724, 5354,\n",
      "         1880, 2062, 4266, 3815, 5771, 5101, 1345, 1121,  809, 7928,  993, 3713,\n",
      "          509, 2989, 2158, 2288, 1599, 7536,  118, 1264, 4516, 7255, 1330,  237,\n",
      "         3116, 3216,  285,  489,  737,  431, 1920, 3650, 1295,  603, 1633,  964,\n",
      "         3458, 1212,  804, 1110, 1771,   41,  982, 1035,  507, 1827, 1194, 4278,\n",
      "         5028, 3811, 1508, 4874, 1982, 6413, 3180, 3738, 1599,  444, 4613, 3484,\n",
      "         1495, 2205,  247, 1036, 3837, 1253, 3101, 2709, 1744,  414, 2075, 4174,\n",
      "         2226,  277,  623,  756, 1674, 2490,  793,  398, 2061,  163, 2190, 7165,\n",
      "          333,   25,  282,  951, 2892, 1572, 1893,  810,  171, 5957,  598, 4046,\n",
      "          790, 6026,  714, 2442, 4905, 1178, 2211, 1695, 6691, 3214, 4688,  815,\n",
      "          495, 1964, 5919, 6300, 2825, 2126, 2933, 3347, 4800, 7191,  104],\n",
      "        [   1,  438, 3162, 1295, 1032, 1700, 1603,  308, 3233,  691,  887,  628,\n",
      "         5681,  972, 1934, 3091,  608, 6753, 1105, 1569, 7193,  383,  375, 1616,\n",
      "         2731, 2386, 3722,  471, 3796, 6672, 6589,  530,  585,  453, 3991, 7498,\n",
      "          730, 3281,  774,  112, 3804,   56, 6230,  308,  739, 1122, 2425, 1982,\n",
      "          464,  757, 1612,  559, 1236, 6038, 7380, 4732, 7317,  760, 1740, 2057,\n",
      "         1199,  364,  654, 1945, 5722,  512, 5276,  684, 5320, 1357, 5955, 1941,\n",
      "         1464,  365, 2673, 6384, 6791, 1528,  971, 1073, 3583, 1396, 1467, 3295,\n",
      "         1642, 6389, 7020, 1534,  364, 2800, 4232,  612, 1823, 2240,  578, 1317,\n",
      "         6093,  726, 1472,  541,  142, 1100, 3991, 3711, 2391, 3876,  402, 2712,\n",
      "         1661,  870,   42, 1911,  495, 3359, 1393, 7668, 1224,  643, 1956,  403,\n",
      "         1535,  669, 2119, 2388,  357, 4679, 3272,  885,  623, 1621,  731, 5082,\n",
      "         7114,  640,  492,  804, 2464, 1395, 1628,  885,  790, 5236, 1330]])\n",
      "torch.Size([2, 170])\n",
      "6 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]]), 'input_ids': tensor([[   1,  438, 3967, 3031, 2037,  644, 4525, 2853, 1595, 7655, 2122, 3882,\n",
      "         1948,  827, 3159,  233, 7655, 1388,  155,  402, 1702, 7473, 1425, 6283,\n",
      "           87, 2633, 7887, 1619, 5549, 1394, 4520, 2760, 1609,  776, 5306, 5830,\n",
      "         4472,  116, 1497,  700, 1339,  817, 2097, 1284, 3985, 1787,  453,  798,\n",
      "         1424,   16,  574,  373, 4954,  129,  352, 5230,  355,  322, 1892, 5268,\n",
      "          276,  462, 2340,  672, 2771, 2802,   83, 3842, 2067,  627, 2938,   91,\n",
      "          585,  262, 6913, 5515, 5746, 7924, 3154,  371, 2948,  581, 1380, 3107,\n",
      "         3767, 4351, 2564, 1598, 3932,   75,  831, 1049, 5327, 1058, 4681, 2163,\n",
      "         1704, 6553, 3401, 1015,  610,  572, 6446, 2597,  994, 5837, 5524,  415,\n",
      "         6872,  621,  735,  795, 3080, 6009, 3758, 1938, 6646,   51, 1397, 1023,\n",
      "         1676, 4256, 2426,  577, 1488, 1573, 1417,  885,  210,  626, 3796, 5908,\n",
      "         1104, 1312, 1971, 5161,  309, 6629, 5292, 2234,  799,  522, 7668, 4861,\n",
      "         3905,  117,  763, 6219,  183,  472, 6945, 4057, 6506,   39, 5424, 1354,\n",
      "         4799, 1052,  665,  641, 7602, 5994,  773, 4737, 3263,    3, 6532,  714,\n",
      "         7097, 4873],\n",
      "        [   1,   28,  730,  740, 1090, 1136,  456,  473,   53,   42, 1509, 1948,\n",
      "         1188, 1134, 1846, 3613, 2297,  724, 4365,  552,  285, 7945,   62,  763,\n",
      "          722, 2370, 1116, 4173,  262,  679, 1541, 1076, 2865, 4940, 1099,    3,\n",
      "          511, 4147,  871,  778, 3304, 7170, 5460,  127, 1553, 2108, 2105, 2914,\n",
      "          983,  650, 3314, 2623, 3387, 4530,  609,  524,  669,  271, 1657, 1808,\n",
      "           64, 6392, 7275,  829, 7329, 7441, 7915, 1197, 5498, 2501, 1270,  380,\n",
      "          691, 2264, 3666, 1374,  220, 7253, 4945, 2410,  567,  258,  269, 1990,\n",
      "         4138, 1195, 1421, 1126, 2807, 2976, 1573, 5702,  577,  483, 2485, 3873,\n",
      "         3253, 3953, 1706, 6510, 4490, 1884,  189, 5677, 2305, 2279, 1288, 3747,\n",
      "          676, 2067,  111, 1289, 3937, 3891,  855, 1626,  590,   86, 4889,  217,\n",
      "          177, 1776,  385, 1193, 5198, 4376, 4843, 2571, 1813,  968, 7224, 2886,\n",
      "         2930, 2786, 5226, 1809, 1753, 1953, 1456, 3478, 3170, 2104, 4041,  598,\n",
      "          850, 1919, 1419,  706, 2453,  384,  746,  871,   55,  381, 1433, 1942,\n",
      "         5937, 2755, 2674,   96, 1546,  830, 7247,   65, 3566, 5072, 1244, 4582,\n",
      "          519, 5604]]), 'labels': tensor([[   1,  438, 3967, 3031, 2037,  644, 4525, 2853, 1595, 7655, 2122, 3882,\n",
      "         1948,  827, 3159,  233, 7655, 1388,  155,  402, 1702, 7473, 1425, 6283,\n",
      "           87, 2633, 7887, 1619, 5549, 1394, 4520, 2760, 1609,  776, 5306, 5830,\n",
      "         4472,  116, 1497,  700, 1339,  817, 2097, 1284, 3985, 1787,  453,  798,\n",
      "         1424,   16,  574,  373, 4954,  129,  352, 5230,  355,  322, 1892, 5268,\n",
      "          276,  462, 2340,  672, 2771, 2802,   83, 3842, 2067,  627, 2938,   91,\n",
      "          585,  262, 6913, 5515, 5746, 7924, 3154,  371, 2948,  581, 1380, 3107,\n",
      "         3767, 4351, 2564, 1598, 3932,   75,  831, 1049, 5327, 1058, 4681, 2163,\n",
      "         1704, 6553, 3401, 1015,  610,  572, 6446, 2597,  994, 5837, 5524,  415,\n",
      "         6872,  621,  735,  795, 3080, 6009, 3758, 1938, 6646,   51, 1397, 1023,\n",
      "         1676, 4256, 2426,  577, 1488, 1573, 1417,  885,  210,  626, 3796, 5908,\n",
      "         1104, 1312, 1971, 5161,  309, 6629, 5292, 2234,  799,  522, 7668, 4861,\n",
      "         3905,  117,  763, 6219,  183,  472, 6945, 4057, 6506,   39, 5424, 1354,\n",
      "         4799, 1052,  665,  641, 7602, 5994,  773, 4737, 3263,    3, 6532,  714,\n",
      "         7097, 4873],\n",
      "        [   1,   28,  730,  740, 1090, 1136,  456,  473,   53,   42, 1509, 1948,\n",
      "         1188, 1134, 1846, 3613, 2297,  724, 4365,  552,  285, 7945,   62,  763,\n",
      "          722, 2370, 1116, 4173,  262,  679, 1541, 1076, 2865, 4940, 1099,    3,\n",
      "          511, 4147,  871,  778, 3304, 7170, 5460,  127, 1553, 2108, 2105, 2914,\n",
      "          983,  650, 3314, 2623, 3387, 4530,  609,  524,  669,  271, 1657, 1808,\n",
      "           64, 6392, 7275,  829, 7329, 7441, 7915, 1197, 5498, 2501, 1270,  380,\n",
      "          691, 2264, 3666, 1374,  220, 7253, 4945, 2410,  567,  258,  269, 1990,\n",
      "         4138, 1195, 1421, 1126, 2807, 2976, 1573, 5702,  577,  483, 2485, 3873,\n",
      "         3253, 3953, 1706, 6510, 4490, 1884,  189, 5677, 2305, 2279, 1288, 3747,\n",
      "          676, 2067,  111, 1289, 3937, 3891,  855, 1626,  590,   86, 4889,  217,\n",
      "          177, 1776,  385, 1193, 5198, 4376, 4843, 2571, 1813,  968, 7224, 2886,\n",
      "         2930, 2786, 5226, 1809, 1753, 1953, 1456, 3478, 3170, 2104, 4041,  598,\n",
      "          850, 1919, 1419,  706, 2453,  384,  746,  871,   55,  381, 1433, 1942,\n",
      "         5937, 2755, 2674,   96, 1546,  830, 7247,   65, 3566, 5072, 1244, 4582,\n",
      "          519, 5604]])}\n",
      "tensor([[   1,  438, 3967, 3031, 2037,  644, 4525, 2853, 1595, 7655, 2122, 3882,\n",
      "         1948,  827, 3159,  233, 7655, 1388,  155,  402, 1702, 7473, 1425, 6283,\n",
      "           87, 2633, 7887, 1619, 5549, 1394, 4520, 2760, 1609,  776, 5306, 5830,\n",
      "         4472,  116, 1497,  700, 1339,  817, 2097, 1284, 3985, 1787,  453,  798,\n",
      "         1424,   16,  574,  373, 4954,  129,  352, 5230,  355,  322, 1892, 5268,\n",
      "          276,  462, 2340,  672, 2771, 2802,   83, 3842, 2067,  627, 2938,   91,\n",
      "          585,  262, 6913, 5515, 5746, 7924, 3154,  371, 2948,  581, 1380, 3107,\n",
      "         3767, 4351, 2564, 1598, 3932,   75,  831, 1049, 5327, 1058, 4681, 2163,\n",
      "         1704, 6553, 3401, 1015,  610,  572, 6446, 2597,  994, 5837, 5524,  415,\n",
      "         6872,  621,  735,  795, 3080, 6009, 3758, 1938, 6646,   51, 1397, 1023,\n",
      "         1676, 4256, 2426,  577, 1488, 1573, 1417,  885,  210,  626, 3796, 5908,\n",
      "         1104, 1312, 1971, 5161,  309, 6629, 5292, 2234,  799,  522, 7668, 4861,\n",
      "         3905,  117,  763, 6219,  183,  472, 6945, 4057, 6506,   39, 5424, 1354,\n",
      "         4799, 1052,  665,  641, 7602, 5994,  773, 4737, 3263,    3, 6532,  714,\n",
      "         7097, 4873],\n",
      "        [   1,   28,  730,  740, 1090, 1136,  456,  473,   53,   42, 1509, 1948,\n",
      "         1188, 1134, 1846, 3613, 2297,  724, 4365,  552,  285, 7945,   62,  763,\n",
      "          722, 2370, 1116, 4173,  262,  679, 1541, 1076, 2865, 4940, 1099,    3,\n",
      "          511, 4147,  871,  778, 3304, 7170, 5460,  127, 1553, 2108, 2105, 2914,\n",
      "          983,  650, 3314, 2623, 3387, 4530,  609,  524,  669,  271, 1657, 1808,\n",
      "           64, 6392, 7275,  829, 7329, 7441, 7915, 1197, 5498, 2501, 1270,  380,\n",
      "          691, 2264, 3666, 1374,  220, 7253, 4945, 2410,  567,  258,  269, 1990,\n",
      "         4138, 1195, 1421, 1126, 2807, 2976, 1573, 5702,  577,  483, 2485, 3873,\n",
      "         3253, 3953, 1706, 6510, 4490, 1884,  189, 5677, 2305, 2279, 1288, 3747,\n",
      "          676, 2067,  111, 1289, 3937, 3891,  855, 1626,  590,   86, 4889,  217,\n",
      "          177, 1776,  385, 1193, 5198, 4376, 4843, 2571, 1813,  968, 7224, 2886,\n",
      "         2930, 2786, 5226, 1809, 1753, 1953, 1456, 3478, 3170, 2104, 4041,  598,\n",
      "          850, 1919, 1419,  706, 2453,  384,  746,  871,   55,  381, 1433, 1942,\n",
      "         5937, 2755, 2674,   96, 1546,  830, 7247,   65, 3566, 5072, 1244, 4582,\n",
      "          519, 5604]])\n",
      "torch.Size([1, 512])\n",
      "7 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  751,  855,  217, 2630, 1881, 3427, 4958, 1496, 1530, 2928, 1378,\n",
      "         2683, 1126, 4691,  996,  841, 2491, 4510, 1366, 3253, 5474,  482,  475,\n",
      "         5959, 2726,  325,  345, 4674,  828,  850, 2479, 6148, 4195,  209,  701,\n",
      "         6150, 1222,  905,  351,  840, 1552, 2412, 6531,  606, 5471, 4757, 1355,\n",
      "          224, 3629, 4623, 5882,  949, 7967, 1034,  607,  823,  386,   27,  652,\n",
      "         5514, 2947, 1477,  461, 4314, 3804,  249, 1781,  447, 3170,  869, 2308,\n",
      "         1755, 1936, 4467, 7093,  364, 1830,  819, 5489,  480, 2022, 1424,  905,\n",
      "          681,  861, 3684, 1439, 6446, 2226, 2442, 6190, 4745, 3887, 7257, 3268,\n",
      "          250, 2178,  485,  124, 7774, 1173,  923, 5284, 2786,  498, 1494,  360,\n",
      "          527, 2294, 4307, 6773, 7596,   57, 2367,  671,  881, 1322,  648, 2144,\n",
      "         3081, 2131, 1027,  518, 2447, 3157, 5483, 6527, 2761, 5259, 4470,   40,\n",
      "         1045,   53, 6417,   40,  739,  521, 1515, 2478, 2915, 2293,  800, 1060,\n",
      "         5948, 4110,   53, 1120, 1607, 2884,  514, 7507,  153, 3389, 2426,   37,\n",
      "          990, 1269, 3298, 4042, 3278, 3391,  859, 1865,  986, 4061,  485, 5034,\n",
      "            9,  345, 2148,  144, 1706, 1332,  851, 5272,  507, 4777,  639, 2370,\n",
      "         1376, 1706, 1165,  431, 5666,  313, 1321, 1907, 7629, 2438, 1018,  165,\n",
      "         1768, 1700, 3495, 6750, 4205, 1091, 1548, 2443,  669, 1556,  883,  818,\n",
      "         1932, 7387,  550,    5,  909, 3176, 6706,  235, 1705,  637, 2185, 3505,\n",
      "           54, 2521, 2384,  132, 3264, 1278,  749,  519, 5060, 3883,  223, 6629,\n",
      "         1891, 1830, 4373,  542,   16,  559,  701, 3037, 1932, 6282, 5494, 1290,\n",
      "         4589,  589, 1056, 4412, 7332, 4080,    6,  341, 1573, 6438, 1970, 4163,\n",
      "         3108, 3608, 1266, 7943, 1621,  970,   62, 1342,  240, 2371,  674, 1276,\n",
      "          823, 1589, 5783, 2204,  698, 4603,   39,  938, 2208, 2806, 1825, 7305,\n",
      "         6808, 6205, 1424,  251, 2016, 1878, 2263, 2319,  247,  925, 1174, 1656,\n",
      "         1884,  558, 4784,  213, 4277, 1109,  465,  788, 7230,  683,  736,  732,\n",
      "           16, 3608, 1619,  141, 2023,  596, 6075, 1348, 6035, 2641,  578,  268,\n",
      "           15,  524, 1585, 1789, 1229, 7187,  524,   91,  580, 7583, 3004,  298,\n",
      "          354, 6055,   88,  702, 6111,  409, 6372, 3162, 3259, 3791, 4687, 2395,\n",
      "         7882,   26, 7681,  149,   32, 6110, 1944, 1228, 2592,   41, 7666,  328,\n",
      "          389, 2593, 6585, 4728, 3908,  733, 2879, 1784, 2660, 5664,  707, 4646,\n",
      "         2328, 3114, 3534,  562,   67, 2532,  595, 7527,  364, 2903, 1064, 1160,\n",
      "         1622, 2042, 2608, 1622,  802,  440,  418, 6708,  411, 5478, 1390,  927,\n",
      "         2016,  482, 3820, 3447, 7464, 1931, 6325, 1859, 6760, 1506, 1780,  859,\n",
      "         7091,  493, 2693, 1726, 2747,   27,  796, 1993, 2616, 5090,  575, 1983,\n",
      "         7878, 6619, 2606,  564,   46, 6336, 4535, 4435, 2323, 2291, 1293,  846,\n",
      "         1737,  334,   42, 2115,  690, 1686,  690, 3573,  889, 2863, 2960, 5288,\n",
      "         6919, 1575,  466, 5678, 4465, 5072, 5180, 2209, 3739, 1062, 1561,  431,\n",
      "         1876,  702, 2039, 2216,  276, 4652,   96, 3176,  683, 3034,  684,  731,\n",
      "         7620, 3148, 2159, 1877,  516,  204, 1758, 1476, 1819, 2746, 1945, 2406,\n",
      "          853,  695, 1684,  795,  565, 1443, 1692, 1945, 5395, 5282,  855, 1223,\n",
      "         3511, 2982, 4654, 1677, 6411,  564, 4463, 5277, 2243, 4609, 4522, 1417,\n",
      "         4251,   25,  553,  841, 2736,  817, 5338,  856,  384, 4174, 3886,  681,\n",
      "           31, 5574, 6978, 3292, 4436, 2397, 5454, 2552]]), 'labels': tensor([[   1,  751,  855,  217, 2630, 1881, 3427, 4958, 1496, 1530, 2928, 1378,\n",
      "         2683, 1126, 4691,  996,  841, 2491, 4510, 1366, 3253, 5474,  482,  475,\n",
      "         5959, 2726,  325,  345, 4674,  828,  850, 2479, 6148, 4195,  209,  701,\n",
      "         6150, 1222,  905,  351,  840, 1552, 2412, 6531,  606, 5471, 4757, 1355,\n",
      "          224, 3629, 4623, 5882,  949, 7967, 1034,  607,  823,  386,   27,  652,\n",
      "         5514, 2947, 1477,  461, 4314, 3804,  249, 1781,  447, 3170,  869, 2308,\n",
      "         1755, 1936, 4467, 7093,  364, 1830,  819, 5489,  480, 2022, 1424,  905,\n",
      "          681,  861, 3684, 1439, 6446, 2226, 2442, 6190, 4745, 3887, 7257, 3268,\n",
      "          250, 2178,  485,  124, 7774, 1173,  923, 5284, 2786,  498, 1494,  360,\n",
      "          527, 2294, 4307, 6773, 7596,   57, 2367,  671,  881, 1322,  648, 2144,\n",
      "         3081, 2131, 1027,  518, 2447, 3157, 5483, 6527, 2761, 5259, 4470,   40,\n",
      "         1045,   53, 6417,   40,  739,  521, 1515, 2478, 2915, 2293,  800, 1060,\n",
      "         5948, 4110,   53, 1120, 1607, 2884,  514, 7507,  153, 3389, 2426,   37,\n",
      "          990, 1269, 3298, 4042, 3278, 3391,  859, 1865,  986, 4061,  485, 5034,\n",
      "            9,  345, 2148,  144, 1706, 1332,  851, 5272,  507, 4777,  639, 2370,\n",
      "         1376, 1706, 1165,  431, 5666,  313, 1321, 1907, 7629, 2438, 1018,  165,\n",
      "         1768, 1700, 3495, 6750, 4205, 1091, 1548, 2443,  669, 1556,  883,  818,\n",
      "         1932, 7387,  550,    5,  909, 3176, 6706,  235, 1705,  637, 2185, 3505,\n",
      "           54, 2521, 2384,  132, 3264, 1278,  749,  519, 5060, 3883,  223, 6629,\n",
      "         1891, 1830, 4373,  542,   16,  559,  701, 3037, 1932, 6282, 5494, 1290,\n",
      "         4589,  589, 1056, 4412, 7332, 4080,    6,  341, 1573, 6438, 1970, 4163,\n",
      "         3108, 3608, 1266, 7943, 1621,  970,   62, 1342,  240, 2371,  674, 1276,\n",
      "          823, 1589, 5783, 2204,  698, 4603,   39,  938, 2208, 2806, 1825, 7305,\n",
      "         6808, 6205, 1424,  251, 2016, 1878, 2263, 2319,  247,  925, 1174, 1656,\n",
      "         1884,  558, 4784,  213, 4277, 1109,  465,  788, 7230,  683,  736,  732,\n",
      "           16, 3608, 1619,  141, 2023,  596, 6075, 1348, 6035, 2641,  578,  268,\n",
      "           15,  524, 1585, 1789, 1229, 7187,  524,   91,  580, 7583, 3004,  298,\n",
      "          354, 6055,   88,  702, 6111,  409, 6372, 3162, 3259, 3791, 4687, 2395,\n",
      "         7882,   26, 7681,  149,   32, 6110, 1944, 1228, 2592,   41, 7666,  328,\n",
      "          389, 2593, 6585, 4728, 3908,  733, 2879, 1784, 2660, 5664,  707, 4646,\n",
      "         2328, 3114, 3534,  562,   67, 2532,  595, 7527,  364, 2903, 1064, 1160,\n",
      "         1622, 2042, 2608, 1622,  802,  440,  418, 6708,  411, 5478, 1390,  927,\n",
      "         2016,  482, 3820, 3447, 7464, 1931, 6325, 1859, 6760, 1506, 1780,  859,\n",
      "         7091,  493, 2693, 1726, 2747,   27,  796, 1993, 2616, 5090,  575, 1983,\n",
      "         7878, 6619, 2606,  564,   46, 6336, 4535, 4435, 2323, 2291, 1293,  846,\n",
      "         1737,  334,   42, 2115,  690, 1686,  690, 3573,  889, 2863, 2960, 5288,\n",
      "         6919, 1575,  466, 5678, 4465, 5072, 5180, 2209, 3739, 1062, 1561,  431,\n",
      "         1876,  702, 2039, 2216,  276, 4652,   96, 3176,  683, 3034,  684,  731,\n",
      "         7620, 3148, 2159, 1877,  516,  204, 1758, 1476, 1819, 2746, 1945, 2406,\n",
      "          853,  695, 1684,  795,  565, 1443, 1692, 1945, 5395, 5282,  855, 1223,\n",
      "         3511, 2982, 4654, 1677, 6411,  564, 4463, 5277, 2243, 4609, 4522, 1417,\n",
      "         4251,   25,  553,  841, 2736,  817, 5338,  856,  384, 4174, 3886,  681,\n",
      "           31, 5574, 6978, 3292, 4436, 2397, 5454, 2552]])}\n",
      "tensor([[   1,  751,  855,  217, 2630, 1881, 3427, 4958, 1496, 1530, 2928, 1378,\n",
      "         2683, 1126, 4691,  996,  841, 2491, 4510, 1366, 3253, 5474,  482,  475,\n",
      "         5959, 2726,  325,  345, 4674,  828,  850, 2479, 6148, 4195,  209,  701,\n",
      "         6150, 1222,  905,  351,  840, 1552, 2412, 6531,  606, 5471, 4757, 1355,\n",
      "          224, 3629, 4623, 5882,  949, 7967, 1034,  607,  823,  386,   27,  652,\n",
      "         5514, 2947, 1477,  461, 4314, 3804,  249, 1781,  447, 3170,  869, 2308,\n",
      "         1755, 1936, 4467, 7093,  364, 1830,  819, 5489,  480, 2022, 1424,  905,\n",
      "          681,  861, 3684, 1439, 6446, 2226, 2442, 6190, 4745, 3887, 7257, 3268,\n",
      "          250, 2178,  485,  124, 7774, 1173,  923, 5284, 2786,  498, 1494,  360,\n",
      "          527, 2294, 4307, 6773, 7596,   57, 2367,  671,  881, 1322,  648, 2144,\n",
      "         3081, 2131, 1027,  518, 2447, 3157, 5483, 6527, 2761, 5259, 4470,   40,\n",
      "         1045,   53, 6417,   40,  739,  521, 1515, 2478, 2915, 2293,  800, 1060,\n",
      "         5948, 4110,   53, 1120, 1607, 2884,  514, 7507,  153, 3389, 2426,   37,\n",
      "          990, 1269, 3298, 4042, 3278, 3391,  859, 1865,  986, 4061,  485, 5034,\n",
      "            9,  345, 2148,  144, 1706, 1332,  851, 5272,  507, 4777,  639, 2370,\n",
      "         1376, 1706, 1165,  431, 5666,  313, 1321, 1907, 7629, 2438, 1018,  165,\n",
      "         1768, 1700, 3495, 6750, 4205, 1091, 1548, 2443,  669, 1556,  883,  818,\n",
      "         1932, 7387,  550,    5,  909, 3176, 6706,  235, 1705,  637, 2185, 3505,\n",
      "           54, 2521, 2384,  132, 3264, 1278,  749,  519, 5060, 3883,  223, 6629,\n",
      "         1891, 1830, 4373,  542,   16,  559,  701, 3037, 1932, 6282, 5494, 1290,\n",
      "         4589,  589, 1056, 4412, 7332, 4080,    6,  341, 1573, 6438, 1970, 4163,\n",
      "         3108, 3608, 1266, 7943, 1621,  970,   62, 1342,  240, 2371,  674, 1276,\n",
      "          823, 1589, 5783, 2204,  698, 4603,   39,  938, 2208, 2806, 1825, 7305,\n",
      "         6808, 6205, 1424,  251, 2016, 1878, 2263, 2319,  247,  925, 1174, 1656,\n",
      "         1884,  558, 4784,  213, 4277, 1109,  465,  788, 7230,  683,  736,  732,\n",
      "           16, 3608, 1619,  141, 2023,  596, 6075, 1348, 6035, 2641,  578,  268,\n",
      "           15,  524, 1585, 1789, 1229, 7187,  524,   91,  580, 7583, 3004,  298,\n",
      "          354, 6055,   88,  702, 6111,  409, 6372, 3162, 3259, 3791, 4687, 2395,\n",
      "         7882,   26, 7681,  149,   32, 6110, 1944, 1228, 2592,   41, 7666,  328,\n",
      "          389, 2593, 6585, 4728, 3908,  733, 2879, 1784, 2660, 5664,  707, 4646,\n",
      "         2328, 3114, 3534,  562,   67, 2532,  595, 7527,  364, 2903, 1064, 1160,\n",
      "         1622, 2042, 2608, 1622,  802,  440,  418, 6708,  411, 5478, 1390,  927,\n",
      "         2016,  482, 3820, 3447, 7464, 1931, 6325, 1859, 6760, 1506, 1780,  859,\n",
      "         7091,  493, 2693, 1726, 2747,   27,  796, 1993, 2616, 5090,  575, 1983,\n",
      "         7878, 6619, 2606,  564,   46, 6336, 4535, 4435, 2323, 2291, 1293,  846,\n",
      "         1737,  334,   42, 2115,  690, 1686,  690, 3573,  889, 2863, 2960, 5288,\n",
      "         6919, 1575,  466, 5678, 4465, 5072, 5180, 2209, 3739, 1062, 1561,  431,\n",
      "         1876,  702, 2039, 2216,  276, 4652,   96, 3176,  683, 3034,  684,  731,\n",
      "         7620, 3148, 2159, 1877,  516,  204, 1758, 1476, 1819, 2746, 1945, 2406,\n",
      "          853,  695, 1684,  795,  565, 1443, 1692, 1945, 5395, 5282,  855, 1223,\n",
      "         3511, 2982, 4654, 1677, 6411,  564, 4463, 5277, 2243, 4609, 4522, 1417,\n",
      "         4251,   25,  553,  841, 2736,  817, 5338,  856,  384, 4174, 3886,  681,\n",
      "           31, 5574, 6978, 3292, 4436, 2397, 5454, 2552]])\n",
      "torch.Size([10, 49])\n",
      "8 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), 'input_ids': tensor([[   1,   28, 6453,  680,   22, 1880, 1565, 7397,   21,  467,  172, 4011,\n",
      "         2840,   65, 1716, 4144, 5341, 7153,   95, 1302, 3134, 1218,   40,  569,\n",
      "         3901, 4377, 7080,  671,  839, 3562, 5169, 1489,  788, 3453, 1937, 2937,\n",
      "          917, 2994, 5936, 3429,   61, 2597,  192, 4080, 1778, 3501, 7105, 1284,\n",
      "         6087],\n",
      "        [   1,  820,   80, 7064, 3923, 4372,  320, 6875, 7776, 4440,  271,  367,\n",
      "          262, 2421, 1530, 1618, 1060,  618, 1038, 2575, 4182, 1162, 2899,  595,\n",
      "          253, 4150, 4739, 5450, 7959, 5157, 6346, 3391,  978, 1253, 6479, 1141,\n",
      "          569, 3869, 1097, 1741, 5074, 6452, 7739,  334, 4875, 6081, 4308, 1212,\n",
      "         1167],\n",
      "        [   1,  390,  446,  476, 2412,  329, 1170, 2164, 2501, 5297, 2520, 3721,\n",
      "         5549, 2832,  770, 7088, 2869, 4413,  621, 1395,  780, 1160, 1486,  258,\n",
      "         3808, 1937,  959, 3733, 2714,  889, 1910, 4976,  650,  310,  871, 2465,\n",
      "         2343, 1210,  546,  480,  467, 3437, 7975,  650, 4941,   47,  970, 7840,\n",
      "           69],\n",
      "        [   1, 3078, 3020, 2102, 3616, 4687, 3915, 4859,   61, 7021,  973, 2545,\n",
      "         2532, 6420, 5078,  174,  992, 1651, 2104, 4456, 4350,  785, 1979,   85,\n",
      "         1077, 1995, 5383, 6986, 5160, 5274,  429,  863, 3349, 1607,  383,  596,\n",
      "         1077,  933, 1515,    6, 2183, 3906, 3372, 4913,  644, 2185, 6256, 6112,\n",
      "          796],\n",
      "        [   1,  886, 2741, 3274,   58,  412,  588,   47, 6804, 2403,  145, 4424,\n",
      "         2965, 3697, 1187, 5727, 4186, 1941, 7871, 4077, 3459, 2420, 4931, 1487,\n",
      "         7903, 5315, 1220, 1653, 4119,  309,  726, 1356, 2087, 2357,  533,  361,\n",
      "         5701,  689,  378, 4889, 3398, 1445, 3697, 3574, 7881, 5323,  333, 2548,\n",
      "          395],\n",
      "        [   1,  260, 2607,  834,  349, 5409, 6418,  888,   21, 1247, 2745,  682,\n",
      "          224, 2038,  884, 3371, 2836,   39, 4109, 4946, 2359,   50,  498,   32,\n",
      "          892, 1241,   57, 2351, 2164,    6, 5959, 2300, 2991, 2220,  650, 5385,\n",
      "         1463,  337, 1816, 4961, 2861,  444,  516,  787, 2535,   59, 1015,  705,\n",
      "          395],\n",
      "        [   1,   28,  253,  986, 4484, 1477, 1451, 3395,  442, 2673, 1135, 1387,\n",
      "         1753, 3334,  811,  607, 1813,  624, 3739, 5673, 2284, 1481,  325,   88,\n",
      "          276, 1423,  837,  798,   61, 1717, 3282, 7161, 4641,  466,  503, 1295,\n",
      "         2178, 7566, 3086,  565, 2620,   43, 3166, 1253, 6649, 7219, 2632, 5411,\n",
      "         2761],\n",
      "        [   1,  390, 4496,  701,  465, 3589,  389,  816,  377, 1051, 3079,  360,\n",
      "         2144, 2073, 2852, 4445, 1770,  209,  526, 2056, 1546, 4386,  553, 1767,\n",
      "         3784, 1017, 2394, 1127, 4836,  888, 1310, 3268, 1428, 7126, 2287,  107,\n",
      "          636, 2194, 1620, 2763, 1211, 6391,  620, 4312, 2536,  730, 1136, 4439,\n",
      "         4809],\n",
      "        [   1,  260, 6524,  351,  579, 4149, 1110,  169, 5018,  519, 1225, 2944,\n",
      "         1034, 2241,  573, 1788,  101,  339,  348,  913, 1823, 2956,  217, 3258,\n",
      "          368, 6056,  869, 3740,  297, 2320, 6386,  955,  761,  360, 1719, 3396,\n",
      "         5062,  123, 5822, 1873,  223,  788, 4514,  836,  437, 1157, 5403,  467,\n",
      "         2695],\n",
      "        [   1,  252, 1057, 4695, 7152, 2314,   31,  597, 1678,  739, 5682, 1810,\n",
      "          191,  612,   66, 7621, 1708, 7091, 6328,   27,   25, 1133,  741, 5691,\n",
      "         2227, 3296, 4949,    3, 1633,  625, 7528, 3659, 7814, 1689,  586, 3808,\n",
      "         1996, 3191, 1745,  427, 2256,  427,   52,  324, 5150,  816, 1547, 1520,\n",
      "          453]]), 'labels': tensor([[   1,   28, 6453,  680,   22, 1880, 1565, 7397,   21,  467,  172, 4011,\n",
      "         2840,   65, 1716, 4144, 5341, 7153,   95, 1302, 3134, 1218,   40,  569,\n",
      "         3901, 4377, 7080,  671,  839, 3562, 5169, 1489,  788, 3453, 1937, 2937,\n",
      "          917, 2994, 5936, 3429,   61, 2597,  192, 4080, 1778, 3501, 7105, 1284,\n",
      "         6087],\n",
      "        [   1,  820,   80, 7064, 3923, 4372,  320, 6875, 7776, 4440,  271,  367,\n",
      "          262, 2421, 1530, 1618, 1060,  618, 1038, 2575, 4182, 1162, 2899,  595,\n",
      "          253, 4150, 4739, 5450, 7959, 5157, 6346, 3391,  978, 1253, 6479, 1141,\n",
      "          569, 3869, 1097, 1741, 5074, 6452, 7739,  334, 4875, 6081, 4308, 1212,\n",
      "         1167],\n",
      "        [   1,  390,  446,  476, 2412,  329, 1170, 2164, 2501, 5297, 2520, 3721,\n",
      "         5549, 2832,  770, 7088, 2869, 4413,  621, 1395,  780, 1160, 1486,  258,\n",
      "         3808, 1937,  959, 3733, 2714,  889, 1910, 4976,  650,  310,  871, 2465,\n",
      "         2343, 1210,  546,  480,  467, 3437, 7975,  650, 4941,   47,  970, 7840,\n",
      "           69],\n",
      "        [   1, 3078, 3020, 2102, 3616, 4687, 3915, 4859,   61, 7021,  973, 2545,\n",
      "         2532, 6420, 5078,  174,  992, 1651, 2104, 4456, 4350,  785, 1979,   85,\n",
      "         1077, 1995, 5383, 6986, 5160, 5274,  429,  863, 3349, 1607,  383,  596,\n",
      "         1077,  933, 1515,    6, 2183, 3906, 3372, 4913,  644, 2185, 6256, 6112,\n",
      "          796],\n",
      "        [   1,  886, 2741, 3274,   58,  412,  588,   47, 6804, 2403,  145, 4424,\n",
      "         2965, 3697, 1187, 5727, 4186, 1941, 7871, 4077, 3459, 2420, 4931, 1487,\n",
      "         7903, 5315, 1220, 1653, 4119,  309,  726, 1356, 2087, 2357,  533,  361,\n",
      "         5701,  689,  378, 4889, 3398, 1445, 3697, 3574, 7881, 5323,  333, 2548,\n",
      "          395],\n",
      "        [   1,  260, 2607,  834,  349, 5409, 6418,  888,   21, 1247, 2745,  682,\n",
      "          224, 2038,  884, 3371, 2836,   39, 4109, 4946, 2359,   50,  498,   32,\n",
      "          892, 1241,   57, 2351, 2164,    6, 5959, 2300, 2991, 2220,  650, 5385,\n",
      "         1463,  337, 1816, 4961, 2861,  444,  516,  787, 2535,   59, 1015,  705,\n",
      "          395],\n",
      "        [   1,   28,  253,  986, 4484, 1477, 1451, 3395,  442, 2673, 1135, 1387,\n",
      "         1753, 3334,  811,  607, 1813,  624, 3739, 5673, 2284, 1481,  325,   88,\n",
      "          276, 1423,  837,  798,   61, 1717, 3282, 7161, 4641,  466,  503, 1295,\n",
      "         2178, 7566, 3086,  565, 2620,   43, 3166, 1253, 6649, 7219, 2632, 5411,\n",
      "         2761],\n",
      "        [   1,  390, 4496,  701,  465, 3589,  389,  816,  377, 1051, 3079,  360,\n",
      "         2144, 2073, 2852, 4445, 1770,  209,  526, 2056, 1546, 4386,  553, 1767,\n",
      "         3784, 1017, 2394, 1127, 4836,  888, 1310, 3268, 1428, 7126, 2287,  107,\n",
      "          636, 2194, 1620, 2763, 1211, 6391,  620, 4312, 2536,  730, 1136, 4439,\n",
      "         4809],\n",
      "        [   1,  260, 6524,  351,  579, 4149, 1110,  169, 5018,  519, 1225, 2944,\n",
      "         1034, 2241,  573, 1788,  101,  339,  348,  913, 1823, 2956,  217, 3258,\n",
      "          368, 6056,  869, 3740,  297, 2320, 6386,  955,  761,  360, 1719, 3396,\n",
      "         5062,  123, 5822, 1873,  223,  788, 4514,  836,  437, 1157, 5403,  467,\n",
      "         2695],\n",
      "        [   1,  252, 1057, 4695, 7152, 2314,   31,  597, 1678,  739, 5682, 1810,\n",
      "          191,  612,   66, 7621, 1708, 7091, 6328,   27,   25, 1133,  741, 5691,\n",
      "         2227, 3296, 4949,    3, 1633,  625, 7528, 3659, 7814, 1689,  586, 3808,\n",
      "         1996, 3191, 1745,  427, 2256,  427,   52,  324, 5150,  816, 1547, 1520,\n",
      "          453]])}\n",
      "tensor([[   1,   28, 6453,  680,   22, 1880, 1565, 7397,   21,  467,  172, 4011,\n",
      "         2840,   65, 1716, 4144, 5341, 7153,   95, 1302, 3134, 1218,   40,  569,\n",
      "         3901, 4377, 7080,  671,  839, 3562, 5169, 1489,  788, 3453, 1937, 2937,\n",
      "          917, 2994, 5936, 3429,   61, 2597,  192, 4080, 1778, 3501, 7105, 1284,\n",
      "         6087],\n",
      "        [   1,  820,   80, 7064, 3923, 4372,  320, 6875, 7776, 4440,  271,  367,\n",
      "          262, 2421, 1530, 1618, 1060,  618, 1038, 2575, 4182, 1162, 2899,  595,\n",
      "          253, 4150, 4739, 5450, 7959, 5157, 6346, 3391,  978, 1253, 6479, 1141,\n",
      "          569, 3869, 1097, 1741, 5074, 6452, 7739,  334, 4875, 6081, 4308, 1212,\n",
      "         1167],\n",
      "        [   1,  390,  446,  476, 2412,  329, 1170, 2164, 2501, 5297, 2520, 3721,\n",
      "         5549, 2832,  770, 7088, 2869, 4413,  621, 1395,  780, 1160, 1486,  258,\n",
      "         3808, 1937,  959, 3733, 2714,  889, 1910, 4976,  650,  310,  871, 2465,\n",
      "         2343, 1210,  546,  480,  467, 3437, 7975,  650, 4941,   47,  970, 7840,\n",
      "           69],\n",
      "        [   1, 3078, 3020, 2102, 3616, 4687, 3915, 4859,   61, 7021,  973, 2545,\n",
      "         2532, 6420, 5078,  174,  992, 1651, 2104, 4456, 4350,  785, 1979,   85,\n",
      "         1077, 1995, 5383, 6986, 5160, 5274,  429,  863, 3349, 1607,  383,  596,\n",
      "         1077,  933, 1515,    6, 2183, 3906, 3372, 4913,  644, 2185, 6256, 6112,\n",
      "          796],\n",
      "        [   1,  886, 2741, 3274,   58,  412,  588,   47, 6804, 2403,  145, 4424,\n",
      "         2965, 3697, 1187, 5727, 4186, 1941, 7871, 4077, 3459, 2420, 4931, 1487,\n",
      "         7903, 5315, 1220, 1653, 4119,  309,  726, 1356, 2087, 2357,  533,  361,\n",
      "         5701,  689,  378, 4889, 3398, 1445, 3697, 3574, 7881, 5323,  333, 2548,\n",
      "          395],\n",
      "        [   1,  260, 2607,  834,  349, 5409, 6418,  888,   21, 1247, 2745,  682,\n",
      "          224, 2038,  884, 3371, 2836,   39, 4109, 4946, 2359,   50,  498,   32,\n",
      "          892, 1241,   57, 2351, 2164,    6, 5959, 2300, 2991, 2220,  650, 5385,\n",
      "         1463,  337, 1816, 4961, 2861,  444,  516,  787, 2535,   59, 1015,  705,\n",
      "          395],\n",
      "        [   1,   28,  253,  986, 4484, 1477, 1451, 3395,  442, 2673, 1135, 1387,\n",
      "         1753, 3334,  811,  607, 1813,  624, 3739, 5673, 2284, 1481,  325,   88,\n",
      "          276, 1423,  837,  798,   61, 1717, 3282, 7161, 4641,  466,  503, 1295,\n",
      "         2178, 7566, 3086,  565, 2620,   43, 3166, 1253, 6649, 7219, 2632, 5411,\n",
      "         2761],\n",
      "        [   1,  390, 4496,  701,  465, 3589,  389,  816,  377, 1051, 3079,  360,\n",
      "         2144, 2073, 2852, 4445, 1770,  209,  526, 2056, 1546, 4386,  553, 1767,\n",
      "         3784, 1017, 2394, 1127, 4836,  888, 1310, 3268, 1428, 7126, 2287,  107,\n",
      "          636, 2194, 1620, 2763, 1211, 6391,  620, 4312, 2536,  730, 1136, 4439,\n",
      "         4809],\n",
      "        [   1,  260, 6524,  351,  579, 4149, 1110,  169, 5018,  519, 1225, 2944,\n",
      "         1034, 2241,  573, 1788,  101,  339,  348,  913, 1823, 2956,  217, 3258,\n",
      "          368, 6056,  869, 3740,  297, 2320, 6386,  955,  761,  360, 1719, 3396,\n",
      "         5062,  123, 5822, 1873,  223,  788, 4514,  836,  437, 1157, 5403,  467,\n",
      "         2695],\n",
      "        [   1,  252, 1057, 4695, 7152, 2314,   31,  597, 1678,  739, 5682, 1810,\n",
      "          191,  612,   66, 7621, 1708, 7091, 6328,   27,   25, 1133,  741, 5691,\n",
      "         2227, 3296, 4949,    3, 1633,  625, 7528, 3659, 7814, 1689,  586, 3808,\n",
      "         1996, 3191, 1745,  427, 2256,  427,   52,  324, 5150,  816, 1547, 1520,\n",
      "          453]])\n",
      "torch.Size([2, 228])\n",
      "9 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  252, 2448,  322, 2548, 1447,  700,  393,  756, 3601, 5972, 1739,\n",
      "          901, 2215, 1292,  287, 1219,  989, 6094,  928,  322, 1984, 1839,   83,\n",
      "         3678, 2752, 4697, 5776, 3200,   47, 1802, 2047, 1309,   82, 5076,  552,\n",
      "         3502, 1864,  871, 4538, 2236, 1689, 7283, 2391,  914, 6851,  971, 3847,\n",
      "         1658,  808,  871, 1714, 1048, 3512, 1542, 2340, 1923, 7950, 1234, 1068,\n",
      "         2594, 2250, 2353, 4228, 6540,  679, 1352, 2474, 1637,   22, 2467, 2880,\n",
      "         1039, 3372, 5574, 2538, 1451, 3265, 2146, 3724, 1284, 1356, 3160,  107,\n",
      "          763, 1109, 3183, 1116, 2139,  785, 2500, 1214, 2184, 1128, 4757, 4125,\n",
      "         1131,   26, 4087,  428, 2951, 2347, 1161,  388,  647, 7583,  625, 1762,\n",
      "         1708, 7135, 4529, 4424, 2968, 3529,  374, 2581,  191, 3397, 2882, 1950,\n",
      "         7919,  499, 4320, 3517, 5354, 2955, 3494,  903, 3280,  539, 7703, 6277,\n",
      "         1053,  373, 2033, 2482,  947, 3198, 1631, 1206, 1732, 5663,   25,  380,\n",
      "         1994,  492, 5350,  595,  443,  922, 7953, 4667,  217,  346, 3140, 3193,\n",
      "           30, 2567, 1698, 3900, 6880,  933, 1848,  793,  317, 3810,   54,  232,\n",
      "         3791, 2670, 1954, 1659, 2566, 5826, 2670, 1118, 2674, 2903, 3955, 1075,\n",
      "         1317,  406, 2158, 1380,   24, 3685, 5946,  721,  362,  793, 1872, 1511,\n",
      "         3632,  416, 5327, 2389,    3, 3779,  125, 1380, 3066, 5993,  183, 3026,\n",
      "         1761, 1670, 5368,  784, 1036, 6462, 1827, 2817,  555, 1256, 4201, 3995,\n",
      "          842, 1666,  726, 2282, 7013, 1358, 1296,  383, 2810, 1050, 1942, 2412],\n",
      "        [   1,  252, 2281,  326,  883, 1261, 2581, 1143,  776, 2936, 2467, 4494,\n",
      "         1906, 4745,   87,  258, 1200, 4555, 4555, 5092,  768, 3331,  803, 1861,\n",
      "         2185,  189, 1952, 6817, 7962, 1877, 3331,  239,  519, 6137,  572, 1823,\n",
      "         1189, 1581, 2070, 3031, 1881, 2176, 2072, 5513,   80, 1321, 3990,  976,\n",
      "         2781,  581,  578,  514, 2427,  794, 4555, 1105,  829, 2282, 1790,  566,\n",
      "         4466,  496, 2220, 5306, 2116, 1352, 2029, 2807, 1606, 3385,  863,  107,\n",
      "          961, 1043, 2648, 6007, 2215,  793, 4637,  741, 4849, 1719, 4524, 2460,\n",
      "         1067, 1794, 1461, 3585, 1510, 6820,  509, 5268, 2930,  409, 3769, 2208,\n",
      "         1577, 7240,  739, 4279, 6148, 1297,  136, 1909, 2914, 7211, 4755, 3313,\n",
      "         2928, 4053, 7194, 4905, 3081, 3916, 1912, 1668,  885, 3066,  997, 1565,\n",
      "         2357, 5253, 3166, 1354,  742, 4306,   61, 4070, 2430,  976,  256,  453,\n",
      "         1836, 2291, 2223,  575,  900, 1091, 3218, 2611, 4611,  557, 3357, 1526,\n",
      "         1176,  109, 1894, 4384, 3352,  494, 4340,  310, 2022, 3627, 1291, 1700,\n",
      "          614, 2568, 2124, 1929, 1969, 3437, 3467, 2700, 3259, 1599, 2302,  686,\n",
      "         4573,  509,  725, 5244, 6126, 2647, 1877,  845, 1877, 1552, 4880, 2263,\n",
      "         3073, 1253, 1156, 6368,  395, 4171, 3397, 4554,  282, 5591, 1345,  644,\n",
      "          802, 3805, 3792, 3434, 3953,  776, 3234, 1009, 1403, 6756, 2083, 3791,\n",
      "         1361,  129, 1877, 2419, 3050, 3004, 1553, 4552, 1239, 1716, 1477, 4238,\n",
      "         3125, 5266, 7945, 5489, 1684,  827, 3156, 3558,    6, 3485, 1589, 3212]]), 'labels': tensor([[   1,  252, 2448,  322, 2548, 1447,  700,  393,  756, 3601, 5972, 1739,\n",
      "          901, 2215, 1292,  287, 1219,  989, 6094,  928,  322, 1984, 1839,   83,\n",
      "         3678, 2752, 4697, 5776, 3200,   47, 1802, 2047, 1309,   82, 5076,  552,\n",
      "         3502, 1864,  871, 4538, 2236, 1689, 7283, 2391,  914, 6851,  971, 3847,\n",
      "         1658,  808,  871, 1714, 1048, 3512, 1542, 2340, 1923, 7950, 1234, 1068,\n",
      "         2594, 2250, 2353, 4228, 6540,  679, 1352, 2474, 1637,   22, 2467, 2880,\n",
      "         1039, 3372, 5574, 2538, 1451, 3265, 2146, 3724, 1284, 1356, 3160,  107,\n",
      "          763, 1109, 3183, 1116, 2139,  785, 2500, 1214, 2184, 1128, 4757, 4125,\n",
      "         1131,   26, 4087,  428, 2951, 2347, 1161,  388,  647, 7583,  625, 1762,\n",
      "         1708, 7135, 4529, 4424, 2968, 3529,  374, 2581,  191, 3397, 2882, 1950,\n",
      "         7919,  499, 4320, 3517, 5354, 2955, 3494,  903, 3280,  539, 7703, 6277,\n",
      "         1053,  373, 2033, 2482,  947, 3198, 1631, 1206, 1732, 5663,   25,  380,\n",
      "         1994,  492, 5350,  595,  443,  922, 7953, 4667,  217,  346, 3140, 3193,\n",
      "           30, 2567, 1698, 3900, 6880,  933, 1848,  793,  317, 3810,   54,  232,\n",
      "         3791, 2670, 1954, 1659, 2566, 5826, 2670, 1118, 2674, 2903, 3955, 1075,\n",
      "         1317,  406, 2158, 1380,   24, 3685, 5946,  721,  362,  793, 1872, 1511,\n",
      "         3632,  416, 5327, 2389,    3, 3779,  125, 1380, 3066, 5993,  183, 3026,\n",
      "         1761, 1670, 5368,  784, 1036, 6462, 1827, 2817,  555, 1256, 4201, 3995,\n",
      "          842, 1666,  726, 2282, 7013, 1358, 1296,  383, 2810, 1050, 1942, 2412],\n",
      "        [   1,  252, 2281,  326,  883, 1261, 2581, 1143,  776, 2936, 2467, 4494,\n",
      "         1906, 4745,   87,  258, 1200, 4555, 4555, 5092,  768, 3331,  803, 1861,\n",
      "         2185,  189, 1952, 6817, 7962, 1877, 3331,  239,  519, 6137,  572, 1823,\n",
      "         1189, 1581, 2070, 3031, 1881, 2176, 2072, 5513,   80, 1321, 3990,  976,\n",
      "         2781,  581,  578,  514, 2427,  794, 4555, 1105,  829, 2282, 1790,  566,\n",
      "         4466,  496, 2220, 5306, 2116, 1352, 2029, 2807, 1606, 3385,  863,  107,\n",
      "          961, 1043, 2648, 6007, 2215,  793, 4637,  741, 4849, 1719, 4524, 2460,\n",
      "         1067, 1794, 1461, 3585, 1510, 6820,  509, 5268, 2930,  409, 3769, 2208,\n",
      "         1577, 7240,  739, 4279, 6148, 1297,  136, 1909, 2914, 7211, 4755, 3313,\n",
      "         2928, 4053, 7194, 4905, 3081, 3916, 1912, 1668,  885, 3066,  997, 1565,\n",
      "         2357, 5253, 3166, 1354,  742, 4306,   61, 4070, 2430,  976,  256,  453,\n",
      "         1836, 2291, 2223,  575,  900, 1091, 3218, 2611, 4611,  557, 3357, 1526,\n",
      "         1176,  109, 1894, 4384, 3352,  494, 4340,  310, 2022, 3627, 1291, 1700,\n",
      "          614, 2568, 2124, 1929, 1969, 3437, 3467, 2700, 3259, 1599, 2302,  686,\n",
      "         4573,  509,  725, 5244, 6126, 2647, 1877,  845, 1877, 1552, 4880, 2263,\n",
      "         3073, 1253, 1156, 6368,  395, 4171, 3397, 4554,  282, 5591, 1345,  644,\n",
      "          802, 3805, 3792, 3434, 3953,  776, 3234, 1009, 1403, 6756, 2083, 3791,\n",
      "         1361,  129, 1877, 2419, 3050, 3004, 1553, 4552, 1239, 1716, 1477, 4238,\n",
      "         3125, 5266, 7945, 5489, 1684,  827, 3156, 3558,    6, 3485, 1589, 3212]])}\n",
      "tensor([[   1,  252, 2448,  322, 2548, 1447,  700,  393,  756, 3601, 5972, 1739,\n",
      "          901, 2215, 1292,  287, 1219,  989, 6094,  928,  322, 1984, 1839,   83,\n",
      "         3678, 2752, 4697, 5776, 3200,   47, 1802, 2047, 1309,   82, 5076,  552,\n",
      "         3502, 1864,  871, 4538, 2236, 1689, 7283, 2391,  914, 6851,  971, 3847,\n",
      "         1658,  808,  871, 1714, 1048, 3512, 1542, 2340, 1923, 7950, 1234, 1068,\n",
      "         2594, 2250, 2353, 4228, 6540,  679, 1352, 2474, 1637,   22, 2467, 2880,\n",
      "         1039, 3372, 5574, 2538, 1451, 3265, 2146, 3724, 1284, 1356, 3160,  107,\n",
      "          763, 1109, 3183, 1116, 2139,  785, 2500, 1214, 2184, 1128, 4757, 4125,\n",
      "         1131,   26, 4087,  428, 2951, 2347, 1161,  388,  647, 7583,  625, 1762,\n",
      "         1708, 7135, 4529, 4424, 2968, 3529,  374, 2581,  191, 3397, 2882, 1950,\n",
      "         7919,  499, 4320, 3517, 5354, 2955, 3494,  903, 3280,  539, 7703, 6277,\n",
      "         1053,  373, 2033, 2482,  947, 3198, 1631, 1206, 1732, 5663,   25,  380,\n",
      "         1994,  492, 5350,  595,  443,  922, 7953, 4667,  217,  346, 3140, 3193,\n",
      "           30, 2567, 1698, 3900, 6880,  933, 1848,  793,  317, 3810,   54,  232,\n",
      "         3791, 2670, 1954, 1659, 2566, 5826, 2670, 1118, 2674, 2903, 3955, 1075,\n",
      "         1317,  406, 2158, 1380,   24, 3685, 5946,  721,  362,  793, 1872, 1511,\n",
      "         3632,  416, 5327, 2389,    3, 3779,  125, 1380, 3066, 5993,  183, 3026,\n",
      "         1761, 1670, 5368,  784, 1036, 6462, 1827, 2817,  555, 1256, 4201, 3995,\n",
      "          842, 1666,  726, 2282, 7013, 1358, 1296,  383, 2810, 1050, 1942, 2412],\n",
      "        [   1,  252, 2281,  326,  883, 1261, 2581, 1143,  776, 2936, 2467, 4494,\n",
      "         1906, 4745,   87,  258, 1200, 4555, 4555, 5092,  768, 3331,  803, 1861,\n",
      "         2185,  189, 1952, 6817, 7962, 1877, 3331,  239,  519, 6137,  572, 1823,\n",
      "         1189, 1581, 2070, 3031, 1881, 2176, 2072, 5513,   80, 1321, 3990,  976,\n",
      "         2781,  581,  578,  514, 2427,  794, 4555, 1105,  829, 2282, 1790,  566,\n",
      "         4466,  496, 2220, 5306, 2116, 1352, 2029, 2807, 1606, 3385,  863,  107,\n",
      "          961, 1043, 2648, 6007, 2215,  793, 4637,  741, 4849, 1719, 4524, 2460,\n",
      "         1067, 1794, 1461, 3585, 1510, 6820,  509, 5268, 2930,  409, 3769, 2208,\n",
      "         1577, 7240,  739, 4279, 6148, 1297,  136, 1909, 2914, 7211, 4755, 3313,\n",
      "         2928, 4053, 7194, 4905, 3081, 3916, 1912, 1668,  885, 3066,  997, 1565,\n",
      "         2357, 5253, 3166, 1354,  742, 4306,   61, 4070, 2430,  976,  256,  453,\n",
      "         1836, 2291, 2223,  575,  900, 1091, 3218, 2611, 4611,  557, 3357, 1526,\n",
      "         1176,  109, 1894, 4384, 3352,  494, 4340,  310, 2022, 3627, 1291, 1700,\n",
      "          614, 2568, 2124, 1929, 1969, 3437, 3467, 2700, 3259, 1599, 2302,  686,\n",
      "         4573,  509,  725, 5244, 6126, 2647, 1877,  845, 1877, 1552, 4880, 2263,\n",
      "         3073, 1253, 1156, 6368,  395, 4171, 3397, 4554,  282, 5591, 1345,  644,\n",
      "          802, 3805, 3792, 3434, 3953,  776, 3234, 1009, 1403, 6756, 2083, 3791,\n",
      "         1361,  129, 1877, 2419, 3050, 3004, 1553, 4552, 1239, 1716, 1477, 4238,\n",
      "         3125, 5266, 7945, 5489, 1684,  827, 3156, 3558,    6, 3485, 1589, 3212]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    print(batch['input_ids'].shape)\n",
    "    print(idx, batch)\n",
    "    print(batch['input_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 228])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(batch['attention_mask'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    " def __getitem__(self, idx):\n",
    "        #batch_idx = self.batch_indices[idx]\n",
    "        # Directly retrieve the batch using the index\n",
    "        print(idx, type(idx))\n",
    "        print(len(self.dataset_dict['attention_mask']))\n",
    "        #print(self.dataset_dict['attention_mask'])\n",
    "        print(np.shape(self.dataset_dict['attention_mask'][idx]))\n",
    "        if torch.distributed.is_initialized():\n",
    "            if torch.distributed.get_rank() == 0:\n",
    "                print(f\"Process 0 is fetching index: {idx}\")\n",
    "            elif torch.distributed.get_rank() == 1:\n",
    "                print(f\"Process 1 is fetching index: {idx}\")\n",
    "        \"\"\"returns [seq_number, token_length], return one batch at a time\"\"\"\n",
    "        attention_mask = torch.tensor(self.dataset_dict['attention_mask'][idx])\n",
    "        input_ids = torch.tensor(self.dataset_dict['input_ids'][idx])\n",
    "        label = torch.tensor(self.dataset_dict['labels'][idx])\n",
    "\n",
    "        return {\n",
    "            'attention_mask': attention_mask,\n",
    "            'input_ids': input_ids,\n",
    "            'labels': label\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/rh-python38/root/usr/local/lib64/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "2023-10-16 10:22:22.895647: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from transformers.models.llama.configuration_llama import LlamaConfig\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "import sentencepiece as spm\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset_dict, batch_indices_train, batch_indices_val, batch_size=1):\n",
    "        super().__init__()\n",
    "        self.dataset_dict = dataset_dict\n",
    "        self.batch_indices_train = batch_indices_train\n",
    "        self.batch_indices_val = batch_indices_val\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.tokenizer = self.tokenizer_generation('protein', '8k')\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_generation(target, vocab_size):\n",
    "        if target == 'original':\n",
    "            tokenizer = LlamaTokenizer.from_pretrained('hf-internal-testing/llama-tokenizer')\n",
    "            tokenizer.pad_token = tokenizer.unk_token\n",
    "            return tokenizer\n",
    "        elif target == 'protein':\n",
    "            tokenizer_path = '/data/rozen/home/e0833634/lama/protllama/batch_script/'\n",
    "            tokenizer = spm.SentencePieceProcessor(model_file=tokenizer_path + \"protein_%s.model\" % (vocab_size))\n",
    "            return tokenizer\n",
    "        else:\n",
    "            raise ValueError('Have not prepared tokenizer for this target')\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Possibly download data, set transforms, etc.\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        self.train_dataset = DynamicBatchingDataset(self.dataset_dict['train'], self.batch_indices_train)\n",
    "        # Repeat similar steps for validation and test datasets if needed\n",
    "        self.val_dataset = DynamicBatchingDataset(self.dataset_dict['valid'], self.batch_indices_val)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        print(\"dataloader created...\")\n",
    "        d = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, collate_fn=DynamicBatchingDataset.collate_fn)\n",
    "        if self.trainer.global_rank == 0:\n",
    "            for idx, batch in enumerate(d):\n",
    "                print(idx, batch)\n",
    "        return d\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, collate_fn=DynamicBatchingDataset.collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import transformers\n",
    "from transformers.models.llama.configuration_llama import LlamaConfig\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import os\n",
    "import logging as log\n",
    "import glob\n",
    "from argparse import ArgumentParser\n",
    "from protllama.bin.data import PretrainDataset\n",
    "import torch\n",
    "class pretrainLlama(pl.LightningModule):\n",
    "    def __init__(self, hparam) -> None:\n",
    "        super(pretrainLlama, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.hparam = hparam  # need to contain epoch, target, date, learning rate, batch_size, num_frozen_epochs\n",
    "        self.MODEL_CONFIGS = self.retrieve_config()\n",
    "        self.__build_model()\n",
    "        self.tokenizer = self.tokenizer_generation('protein', '8k')\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_generation(target, vocab_size):\n",
    "        if target == 'original':\n",
    "            tokenizer = LlamaTokenizer.from_pretrained('hf-internal-testing/llama-tokenizer')\n",
    "            tokenizer.pad_token = tokenizer.unk_token\n",
    "            return tokenizer\n",
    "        elif target == 'protein':\n",
    "            tokenizer_path = '/data/rozen/home/e0833634/lama/protllama/batch_script/'\n",
    "            tokenizer = spm.SentencePieceProcessor(model_file=tokenizer_path + \"protein_%s.model\" % (vocab_size))\n",
    "            return tokenizer\n",
    "        else:\n",
    "            raise ValueError('Have not prepared tokenizer for this target')\n",
    "\n",
    "    def retrieve_config(self):\n",
    "        \"\"\" return transformers DATASET object\"\"\"\n",
    "        if self.hparam.target == 'original':\n",
    "            config_dict = {'7b': LlamaConfig(max_position_embeddings=self.hparam.max_position_embeddings,\n",
    "                                             hidden_size=self.hparam.hidden_size,\n",
    "                                             intermediate_size=self.hparam.intermediate_size)}\n",
    "            return config_dict['7b']\n",
    "        elif self.hparam.target == 'protein':\n",
    "            config_dict = {\n",
    "                'protllama2': LlamaConfig(max_position_embeddings=self.hparam.max_position_embeddings,  # maximum length\n",
    "                                          hidden_size=self.hparam.hidden_size,\n",
    "                                          transformers_version=transformers.__version__,\n",
    "                                          intermediate_size=self.hparam.intermediate_size,\n",
    "                                          vocab_size=int(self.hparam.vocab_size.rstrip('k')) * 1000)}\n",
    "            #print(config_dict['protllama2'])\n",
    "            return config_dict['protllama2']\n",
    "        else:\n",
    "            raise ValueError('Have not prepared dataset for this target')\n",
    "\n",
    "    def __build_model(self) -> None:\n",
    "        \"\"\"start model building, can add customized classification head\"\"\"\n",
    "        self.model = LlamaForCausalLM(self.MODEL_CONFIGS)\n",
    "        #print(self.model.lm_head.weight)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"set learning rates\"\"\"\n",
    "        if self.hparam.scheduler == 'linear':\n",
    "            parameters = self.model.parameters()\n",
    "            optimizer = AdamW(parameters, lr=self.hparam.learning_rate, betas=(0.9, 0.95), weight_decay=0.1)\n",
    "            lr_schedulers = {\n",
    "                \"scheduler\": get_linear_schedule_with_warmup(optimizer,\n",
    "                                                            num_warmup_steps=100,\n",
    "                                                            num_training_steps=self.hparam.epoch * self.hparam.train_dataset_length),\n",
    "                \"name\": 'learning_rate_logs'\n",
    "            }\n",
    "            return [optimizer], [lr_schedulers]\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        \"\"\" Pytorch forward function\n",
    "        Returns:\n",
    "        dict with model outputs (loss, logits, hidden layer, attention)\n",
    "        \"\"\"\n",
    "        return self.model(**inputs)\n",
    "\n",
    "    def training_step(self, batch, batch_nb: int, verbose=False):\n",
    "        print(batch.keys())\n",
    "        if torch.distributed.is_initialized():\n",
    "            print(f\"Process {torch.distributed.get_rank()} starting training step\")\n",
    "        print(batch)\n",
    "        print(batch['input_ids'].shape)\n",
    "        outputs = self.forward(**batch)\n",
    "        loss_train = outputs[0]\n",
    "\n",
    "        # Compute the perplexity\n",
    "        perplexity = torch.exp(outputs[0].cpu())  # Ensure outputs are on CPU\n",
    "\n",
    "        # Accuracy computation\n",
    "        # Shifting\n",
    "        shift_logits = outputs[1][..., :-1, :].contiguous().argmax(\n",
    "            dim=-1).cpu()  # Ensure outputs and argmax result are on CPU\n",
    "\n",
    "        # Assuming 'labels' is a key in batch containing true token IDs\n",
    "        shift_labels = batch['labels'][..., 1:].contiguous().cpu()  # Move labels to CPU\n",
    "\n",
    "        non_padding_mask = shift_labels != -100\n",
    "        # Compare predictions to true labels, but only for non-padding tokens\n",
    "        acc_train = ((shift_logits == shift_labels) & non_padding_mask).sum().item() / non_padding_mask.sum().item()\n",
    "\n",
    "        print('train', loss_train, perplexity, acc_train)\n",
    "\n",
    "        # Log\n",
    "        self.log('train_loss', loss_train, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log('train_perplexity', perplexity, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log('train_accuracy', acc_train, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "\n",
    "        return loss_train\n",
    "\n",
    "    def validation_step(self, batch, batch_nb: int, verbose=False):\n",
    "        \"\"\" Similar to the training step but with the model in eval mode.\n",
    "        Returns:\n",
    "            - dictionary passed to the validation_end function.\n",
    "        \"\"\"\n",
    "        outputs = self.forward(**batch)\n",
    "        loss_val = outputs[0].cpu()\n",
    "\n",
    "        # Compute the perplexity\n",
    "        perplexity = torch.exp(loss_val)  # Ensure outputs are on CPU\n",
    "\n",
    "        # Accuracy computation\n",
    "        # Shifting\n",
    "        shift_logits = outputs[1][..., :-1, :].contiguous().argmax(\n",
    "            dim=-1).cpu()  # Ensure outputs and argmax result are on CPU\n",
    "\n",
    "        # Assuming 'labels' is a key in batch containing true token IDs\n",
    "        shift_labels = batch['labels'][..., 1:].contiguous().cpu()  # Move labels to CPU\n",
    "\n",
    "        non_padding_mask = shift_labels != -100\n",
    "\n",
    "        # Compare predictions to true labels, but only for non-padding tokens\n",
    "        acc_val = ((shift_logits == shift_labels) & non_padding_mask).sum().item() / non_padding_mask.sum().item()\n",
    "\n",
    "        print('val', loss_val, perplexity, acc_val)\n",
    "        # Log\n",
    "        self.log('val_loss', loss_val, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log('val_perplexity', perplexity, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log('val_accuracy', acc_val, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss_val\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/rozen/home/e0833634/.local/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:398: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to initialize the Trainer...\n",
      "Trainer initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | LlamaForCausalLM | 168 M \n",
      "-------------------------------------------\n",
      "168 M     Trainable params\n",
      "0         Non-trainable params\n",
      "168 M     Total params\n",
      "673.549   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Initializing dataset...\n",
      "dataloader created...\n",
      "0 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  390,  817,  325,  881,  545, 4579, 2698, 3853,  400, 3222,  811,\n",
      "         5410,  757, 1580,  312, 2013, 1832,  689, 2295, 3041, 3967,  762, 5632,\n",
      "         2307, 4670, 3743,  300, 5307,  343, 2685, 3989, 5093, 4627, 4023,  771,\n",
      "         3396, 6661,  220,  379, 6834,  771, 3306, 1659, 4508, 5596, 2220, 2892,\n",
      "          461,    4, 2068, 1108, 1198, 2766, 2828, 1009,  585, 2566, 3824, 6189,\n",
      "          666, 1509, 5843, 1419,  172,  810, 4278,  931,  707, 4049,  470, 5006,\n",
      "         1181, 1208, 1271, 3306,  505, 3989, 4959, 3861,  356, 4102, 3154,  611],\n",
      "        [   1,  820, 1919, 4465, 1017, 1241, 4424, 2858, 1017,   53, 2874, 3400,\n",
      "         1248,  617,  737,   54,  409,  591,  924,   37, 4884, 6452, 1225, 3224,\n",
      "          378, 2301,  434, 6762,  663, 3534,   72, 4146,  464, 1098,   45, 1134,\n",
      "          348, 1982, 3944, 4862,  995,  485, 4882, 1472, 4226,   54,  995, 1209,\n",
      "         5196,  277, 1428,  582, 2211,  552,  784, 4702, 6476,  787, 3076,  236,\n",
      "          314, 5817, 1042, 1265,   61, 3873,  381, 2263, 5040,  330, 1234,  282,\n",
      "          742, 6747, 7776, 6029,  210, 4271, 5760,  907, 2704,  517, 5292, 1141],\n",
      "        [   1, 1171, 7708,   34, 4009, 1036, 3470,   74, 1039, 2396,  606, 2432,\n",
      "          337,  356,  402,  894, 1974,  212, 3452, 6420, 1611, 5894, 3857, 5713,\n",
      "         1353, 2464, 2909, 4248, 4887,   21, 5170, 2999, 5670, 3389,  729, 3524,\n",
      "         1726,  191,  337, 5388, 5772, 3095,  610,  946, 1610,  330,  339, 5085,\n",
      "         5794, 3690, 3926,  337, 1711, 7155, 6247,  306, 7910,    6,  845, 3122,\n",
      "         7642,  341,  846,  613,  416, 4251, 1209, 1946, 5173, 7705, 2679, 7705,\n",
      "          679, 1321, 4645, 1305,  716,  363,  790, 1968, 3273,  605,  101,  706],\n",
      "        [   1, 4052,   47,  516,   21, 1253, 1603, 1026, 1306, 4156, 4988,  661,\n",
      "         2514, 1590, 5005, 5831, 3966, 6830, 6751, 1786, 4531,  606, 2634, 1216,\n",
      "         1304, 4026, 4617,  383,  244,  412,  437,  947, 3502, 3457, 1408,  863,\n",
      "         2632, 1345,  383, 1905, 2024,  809, 1291, 5253, 2583, 1435,  903,   25,\n",
      "          804, 3076,  781, 2702,  137,   21,  500,  921,  891,  579, 1996, 3865,\n",
      "         1681, 1455,   22, 5327, 1399, 3981, 1424, 3171,   32, 2521, 1496,  838,\n",
      "         4514, 1324,  591, 2282,  483,  889, 7513,  276, 6409, 3009, 4022, 4962],\n",
      "        [   1,   28,  807, 6219,  114, 7396,  133, 4094, 2677,  791, 1501, 3151,\n",
      "         2209, 1532,  921,  867, 2447,  561, 2958, 7742, 1086, 5403, 3735, 4276,\n",
      "         5093,  998, 2591, 3703, 3297, 7128, 2520, 3234,  183, 2091, 2077,  970,\n",
      "          291,  519, 1742,  869, 2382,   33,  953, 2084, 2341,    3, 1365, 2507,\n",
      "         5127, 2217, 2430,  262, 3214, 4115, 3266,  381, 5441,  425, 5146, 4858,\n",
      "         1218,  426, 4543, 1727, 5532, 4994, 5937, 3778, 2912, 6576, 3879, 4238,\n",
      "         2751, 1493, 1522, 1090, 1214,  498, 6998,  137, 2846,  480,  366,  324],\n",
      "        [   1, 7322,  680,  648, 3056,  449,  634,  607, 1337, 3661, 1483,  599,\n",
      "          875, 1645, 3648,   47,  409, 3993, 2543, 1437,  317, 6480, 2885,  577,\n",
      "          478, 2763,  934, 1639, 4523, 1769, 7046, 3417, 1386,  620, 1788, 1711,\n",
      "         6623,  774, 6154, 1438, 3898,  505, 4123, 1321, 5935,   29, 1754,  878,\n",
      "         1755, 4279, 1447, 1102,  724, 1263, 5214,  618, 3792,  486,  342, 4051,\n",
      "         2855, 1510, 1531, 4306,  715,  136, 1182, 3362, 1651, 1342, 2957,  424,\n",
      "           65, 3007, 4999, 2133, 3529, 2606,  647, 1214, 3637, 2996, 5330, 6755]]), 'labels': tensor([[   1,  390,  817,  325,  881,  545, 4579, 2698, 3853,  400, 3222,  811,\n",
      "         5410,  757, 1580,  312, 2013, 1832,  689, 2295, 3041, 3967,  762, 5632,\n",
      "         2307, 4670, 3743,  300, 5307,  343, 2685, 3989, 5093, 4627, 4023,  771,\n",
      "         3396, 6661,  220,  379, 6834,  771, 3306, 1659, 4508, 5596, 2220, 2892,\n",
      "          461,    4, 2068, 1108, 1198, 2766, 2828, 1009,  585, 2566, 3824, 6189,\n",
      "          666, 1509, 5843, 1419,  172,  810, 4278,  931,  707, 4049,  470, 5006,\n",
      "         1181, 1208, 1271, 3306,  505, 3989, 4959, 3861,  356, 4102, 3154,  611],\n",
      "        [   1,  820, 1919, 4465, 1017, 1241, 4424, 2858, 1017,   53, 2874, 3400,\n",
      "         1248,  617,  737,   54,  409,  591,  924,   37, 4884, 6452, 1225, 3224,\n",
      "          378, 2301,  434, 6762,  663, 3534,   72, 4146,  464, 1098,   45, 1134,\n",
      "          348, 1982, 3944, 4862,  995,  485, 4882, 1472, 4226,   54,  995, 1209,\n",
      "         5196,  277, 1428,  582, 2211,  552,  784, 4702, 6476,  787, 3076,  236,\n",
      "          314, 5817, 1042, 1265,   61, 3873,  381, 2263, 5040,  330, 1234,  282,\n",
      "          742, 6747, 7776, 6029,  210, 4271, 5760,  907, 2704,  517, 5292, 1141],\n",
      "        [   1, 1171, 7708,   34, 4009, 1036, 3470,   74, 1039, 2396,  606, 2432,\n",
      "          337,  356,  402,  894, 1974,  212, 3452, 6420, 1611, 5894, 3857, 5713,\n",
      "         1353, 2464, 2909, 4248, 4887,   21, 5170, 2999, 5670, 3389,  729, 3524,\n",
      "         1726,  191,  337, 5388, 5772, 3095,  610,  946, 1610,  330,  339, 5085,\n",
      "         5794, 3690, 3926,  337, 1711, 7155, 6247,  306, 7910,    6,  845, 3122,\n",
      "         7642,  341,  846,  613,  416, 4251, 1209, 1946, 5173, 7705, 2679, 7705,\n",
      "          679, 1321, 4645, 1305,  716,  363,  790, 1968, 3273,  605,  101,  706],\n",
      "        [   1, 4052,   47,  516,   21, 1253, 1603, 1026, 1306, 4156, 4988,  661,\n",
      "         2514, 1590, 5005, 5831, 3966, 6830, 6751, 1786, 4531,  606, 2634, 1216,\n",
      "         1304, 4026, 4617,  383,  244,  412,  437,  947, 3502, 3457, 1408,  863,\n",
      "         2632, 1345,  383, 1905, 2024,  809, 1291, 5253, 2583, 1435,  903,   25,\n",
      "          804, 3076,  781, 2702,  137,   21,  500,  921,  891,  579, 1996, 3865,\n",
      "         1681, 1455,   22, 5327, 1399, 3981, 1424, 3171,   32, 2521, 1496,  838,\n",
      "         4514, 1324,  591, 2282,  483,  889, 7513,  276, 6409, 3009, 4022, 4962],\n",
      "        [   1,   28,  807, 6219,  114, 7396,  133, 4094, 2677,  791, 1501, 3151,\n",
      "         2209, 1532,  921,  867, 2447,  561, 2958, 7742, 1086, 5403, 3735, 4276,\n",
      "         5093,  998, 2591, 3703, 3297, 7128, 2520, 3234,  183, 2091, 2077,  970,\n",
      "          291,  519, 1742,  869, 2382,   33,  953, 2084, 2341,    3, 1365, 2507,\n",
      "         5127, 2217, 2430,  262, 3214, 4115, 3266,  381, 5441,  425, 5146, 4858,\n",
      "         1218,  426, 4543, 1727, 5532, 4994, 5937, 3778, 2912, 6576, 3879, 4238,\n",
      "         2751, 1493, 1522, 1090, 1214,  498, 6998,  137, 2846,  480,  366,  324],\n",
      "        [   1, 7322,  680,  648, 3056,  449,  634,  607, 1337, 3661, 1483,  599,\n",
      "          875, 1645, 3648,   47,  409, 3993, 2543, 1437,  317, 6480, 2885,  577,\n",
      "          478, 2763,  934, 1639, 4523, 1769, 7046, 3417, 1386,  620, 1788, 1711,\n",
      "         6623,  774, 6154, 1438, 3898,  505, 4123, 1321, 5935,   29, 1754,  878,\n",
      "         1755, 4279, 1447, 1102,  724, 1263, 5214,  618, 3792,  486,  342, 4051,\n",
      "         2855, 1510, 1531, 4306,  715,  136, 1182, 3362, 1651, 1342, 2957,  424,\n",
      "           65, 3007, 4999, 2133, 3529, 2606,  647, 1214, 3637, 2996, 5330, 6755]])}\n",
      "1 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,   28, 3312, 4266, 2308, 1219, 2665, 1052, 6285,  164,  411,  763,\n",
      "          760, 1737, 6201, 3094, 2154, 2344, 5860, 7077,  374,  472, 7350, 4553,\n",
      "         1061, 1254, 2222, 2739, 2237, 2823, 7070, 2058, 1121, 2672, 5592,  987,\n",
      "         2171,  751, 4233,  696,   55,  908, 2149, 3049,  928, 2605, 2578,  370,\n",
      "         4472, 1064, 1291,  224,  162, 1482, 5744, 7558,  983, 1940,  691, 7570,\n",
      "         1567,  436, 2667, 2250, 1060,  625, 2229, 4668,  949,  140, 3011, 1959,\n",
      "         5673,  798, 1685, 2393,  452,  670,  759, 1558, 2864, 1041, 5518,  119,\n",
      "          889,  711, 3631, 2562, 1294, 2593, 1484, 4434, 3037, 4208, 3096,  613,\n",
      "         5596, 3820,  192, 2169, 4229,  825,  596, 3919,  141, 1549, 4692, 2247,\n",
      "         1919, 1012,  648, 1870, 6303, 1648,  422, 4305, 1114,    6, 3947, 4162,\n",
      "         4547, 5194, 2131, 4992, 5694, 3414, 2910, 4514, 3348,   86, 3929,  565,\n",
      "         3140,  827,   61, 4195,  282,  478, 3656,   51, 1107,  996, 3010,  970,\n",
      "           83, 1158, 1357, 4239,  226,  408, 2684, 3768, 2607, 6537,  924, 3098,\n",
      "          292,  752, 6317,   84,  242,  309, 5158,  284, 1909, 1277,  803, 5547,\n",
      "          440, 2414, 1458, 2629, 4801,  118,  690, 4322, 3482, 4563, 5003, 5452,\n",
      "         1920, 2468, 2046,  307, 4248, 7985,   44, 1574, 4310, 5485,   41, 3735,\n",
      "         6127, 3588,  327, 4205, 2239, 3828,   62, 3605, 2813, 2334, 2274, 1975,\n",
      "          857,  773,  629, 2038, 1005, 5770, 1608, 4084,  132,  736, 2318, 4522,\n",
      "          162, 3868,  590, 5828, 4519, 2570,  577, 1805,  613, 1529, 1296, 2199,\n",
      "         7640, 2486, 4636,  102, 4170, 4427,   16,   95, 1205, 1364, 6847,  511,\n",
      "         2281, 4215,  346, 1653,  150, 4343,  691,  852,  955,  957, 6160,  120,\n",
      "         4641,  544, 6930, 7429, 1180, 6074, 6856,   16, 3996, 1799, 7919, 1045,\n",
      "         2887, 1452,   47, 6844, 1522, 3440,   49, 2498, 4131, 3835,  584,  350,\n",
      "          688, 6349, 2712,  428,  815,  982, 2392, 1195, 1824, 4168, 1368,  305,\n",
      "         3075, 1524, 2150, 7203,  891, 1318, 1633, 2186,  971, 1067, 3896, 2725,\n",
      "         2910,  799,  502, 2769, 4050, 2588, 1138,  341, 3523,   79, 4255, 1454,\n",
      "         1770,  963,  814,  380, 1321,   80, 3036, 6044, 2327, 3429,   61, 3494,\n",
      "         1928,  114, 1426, 1803,  311, 7235, 1686]]), 'labels': tensor([[   1,   28, 3312, 4266, 2308, 1219, 2665, 1052, 6285,  164,  411,  763,\n",
      "          760, 1737, 6201, 3094, 2154, 2344, 5860, 7077,  374,  472, 7350, 4553,\n",
      "         1061, 1254, 2222, 2739, 2237, 2823, 7070, 2058, 1121, 2672, 5592,  987,\n",
      "         2171,  751, 4233,  696,   55,  908, 2149, 3049,  928, 2605, 2578,  370,\n",
      "         4472, 1064, 1291,  224,  162, 1482, 5744, 7558,  983, 1940,  691, 7570,\n",
      "         1567,  436, 2667, 2250, 1060,  625, 2229, 4668,  949,  140, 3011, 1959,\n",
      "         5673,  798, 1685, 2393,  452,  670,  759, 1558, 2864, 1041, 5518,  119,\n",
      "          889,  711, 3631, 2562, 1294, 2593, 1484, 4434, 3037, 4208, 3096,  613,\n",
      "         5596, 3820,  192, 2169, 4229,  825,  596, 3919,  141, 1549, 4692, 2247,\n",
      "         1919, 1012,  648, 1870, 6303, 1648,  422, 4305, 1114,    6, 3947, 4162,\n",
      "         4547, 5194, 2131, 4992, 5694, 3414, 2910, 4514, 3348,   86, 3929,  565,\n",
      "         3140,  827,   61, 4195,  282,  478, 3656,   51, 1107,  996, 3010,  970,\n",
      "           83, 1158, 1357, 4239,  226,  408, 2684, 3768, 2607, 6537,  924, 3098,\n",
      "          292,  752, 6317,   84,  242,  309, 5158,  284, 1909, 1277,  803, 5547,\n",
      "          440, 2414, 1458, 2629, 4801,  118,  690, 4322, 3482, 4563, 5003, 5452,\n",
      "         1920, 2468, 2046,  307, 4248, 7985,   44, 1574, 4310, 5485,   41, 3735,\n",
      "         6127, 3588,  327, 4205, 2239, 3828,   62, 3605, 2813, 2334, 2274, 1975,\n",
      "          857,  773,  629, 2038, 1005, 5770, 1608, 4084,  132,  736, 2318, 4522,\n",
      "          162, 3868,  590, 5828, 4519, 2570,  577, 1805,  613, 1529, 1296, 2199,\n",
      "         7640, 2486, 4636,  102, 4170, 4427,   16,   95, 1205, 1364, 6847,  511,\n",
      "         2281, 4215,  346, 1653,  150, 4343,  691,  852,  955,  957, 6160,  120,\n",
      "         4641,  544, 6930, 7429, 1180, 6074, 6856,   16, 3996, 1799, 7919, 1045,\n",
      "         2887, 1452,   47, 6844, 1522, 3440,   49, 2498, 4131, 3835,  584,  350,\n",
      "          688, 6349, 2712,  428,  815,  982, 2392, 1195, 1824, 4168, 1368,  305,\n",
      "         3075, 1524, 2150, 7203,  891, 1318, 1633, 2186,  971, 1067, 3896, 2725,\n",
      "         2910,  799,  502, 2769, 4050, 2588, 1138,  341, 3523,   79, 4255, 1454,\n",
      "         1770,  963,  814,  380, 1321,   80, 3036, 6044, 2327, 3429,   61, 3494,\n",
      "         1928,  114, 1426, 1803,  311, 7235, 1686]])}\n",
      "2 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,   28,  425,  643,  481, 2329,  841,  144, 5480, 1528,  434,   98,\n",
      "          794, 3818, 4905,  435, 1665, 1354,  853, 1869, 5901, 1184, 7909,  664,\n",
      "         4766,   20,  357, 5219, 7122, 1484, 2861, 4958,  443, 7387, 1650, 1385,\n",
      "         2494, 1201, 3444, 1166, 3346, 2041, 1034,  302, 2817, 5065, 3014,  953,\n",
      "          864, 1296, 3378,  865,  589,  661, 3076, 1191, 6644, 2507,   86, 3464,\n",
      "          308, 1842,  672, 4501,   32, 5916, 3328,  862, 1782, 1561,   32, 1321,\n",
      "          680, 7365, 7170, 2108, 2438, 1479,  419, 4610,  762,   37, 3939, 2382,\n",
      "          159, 6184, 1541, 3693,  320, 3457,  346,  552, 2236, 4494, 2809, 2892,\n",
      "          817, 2169, 6473, 2224, 2074, 4095, 5720, 3350, 1689,  892, 4599, 3284,\n",
      "          850, 2144, 4824,  317, 1845, 4416, 1115, 3415, 1187, 3178, 1157, 6919,\n",
      "         3964, 3752,  932, 4710, 1584, 6405, 3557, 1531, 2983, 5914,  928, 6838,\n",
      "         7257,  263,  104, 1423, 1869, 1011,  778, 5890, 1412,  619,  403, 3467,\n",
      "         1016, 1475, 5699, 2724,   42,  792, 5948, 1623, 2916, 6502,  538,  912,\n",
      "         3671, 2882,  218,  145, 1034, 2768, 1014, 1369, 2761,    3, 2022, 3531,\n",
      "         2492, 1092, 1303, 5330, 3891, 2992,  766, 1939,  690, 4877, 1559, 2348,\n",
      "          197,   52, 2320,  806, 2137, 5183,  518, 6415,  824,  395,  529],\n",
      "        [   1,  667,  183,  427, 4931, 4515,  383,  127, 4004, 7008, 1099, 2971,\n",
      "         1460, 2081, 1614, 5265, 2630, 1079, 5505, 1199, 2008,   62, 1724, 6706,\n",
      "         1460, 1554, 2128,  742,  452, 7967, 1074, 3352,  862, 1342, 2072, 7917,\n",
      "          794,  380, 2052,  879, 1965, 1649, 5974, 1649, 2612, 3189, 5891, 1023,\n",
      "          416,  358, 2781,  145, 1723, 1659, 2938, 1906,  513,  957, 3266, 2834,\n",
      "         7124, 2112, 3046, 6730, 1717,  989, 7050, 1878, 2308,   25, 1936, 1154,\n",
      "         3612,  587, 4068, 7029,  169, 3412, 5170, 5163, 1640, 1213, 3753, 2472,\n",
      "         1213, 1044, 3035, 1113, 6615, 1063, 1472,  452,  197,  896, 3138,  439,\n",
      "          277,  711, 2035, 1217,   44, 1907, 5005, 1281, 1626,  441, 2954,  233,\n",
      "          210, 7176,  361,  961, 1119, 1437,  925, 3969, 3522, 1391, 1359,  718,\n",
      "         5415,  516, 2475, 5024,   42, 2188,  829,  269, 1249,  749, 4930, 2898,\n",
      "         1824, 1048, 2822,   74, 1585, 1227, 7317, 3419,  852,  600, 3209,  365,\n",
      "         4814, 2541, 1054, 5164, 1462, 1436,  401, 7612, 4203, 1383, 5827,  540,\n",
      "         6251,  913, 1212, 3902, 1081, 4888, 1622, 1322, 3445, 5657,  788, 1067,\n",
      "          475, 1615, 1710, 2788, 4594,  994,  603, 6322, 5661, 7699, 3936, 2681,\n",
      "         6660, 7329, 1575,  138,  296, 3051, 3906, 1483, 5301,    4, 1491]]), 'labels': tensor([[   1,   28,  425,  643,  481, 2329,  841,  144, 5480, 1528,  434,   98,\n",
      "          794, 3818, 4905,  435, 1665, 1354,  853, 1869, 5901, 1184, 7909,  664,\n",
      "         4766,   20,  357, 5219, 7122, 1484, 2861, 4958,  443, 7387, 1650, 1385,\n",
      "         2494, 1201, 3444, 1166, 3346, 2041, 1034,  302, 2817, 5065, 3014,  953,\n",
      "          864, 1296, 3378,  865,  589,  661, 3076, 1191, 6644, 2507,   86, 3464,\n",
      "          308, 1842,  672, 4501,   32, 5916, 3328,  862, 1782, 1561,   32, 1321,\n",
      "          680, 7365, 7170, 2108, 2438, 1479,  419, 4610,  762,   37, 3939, 2382,\n",
      "          159, 6184, 1541, 3693,  320, 3457,  346,  552, 2236, 4494, 2809, 2892,\n",
      "          817, 2169, 6473, 2224, 2074, 4095, 5720, 3350, 1689,  892, 4599, 3284,\n",
      "          850, 2144, 4824,  317, 1845, 4416, 1115, 3415, 1187, 3178, 1157, 6919,\n",
      "         3964, 3752,  932, 4710, 1584, 6405, 3557, 1531, 2983, 5914,  928, 6838,\n",
      "         7257,  263,  104, 1423, 1869, 1011,  778, 5890, 1412,  619,  403, 3467,\n",
      "         1016, 1475, 5699, 2724,   42,  792, 5948, 1623, 2916, 6502,  538,  912,\n",
      "         3671, 2882,  218,  145, 1034, 2768, 1014, 1369, 2761,    3, 2022, 3531,\n",
      "         2492, 1092, 1303, 5330, 3891, 2992,  766, 1939,  690, 4877, 1559, 2348,\n",
      "          197,   52, 2320,  806, 2137, 5183,  518, 6415,  824,  395,  529],\n",
      "        [   1,  667,  183,  427, 4931, 4515,  383,  127, 4004, 7008, 1099, 2971,\n",
      "         1460, 2081, 1614, 5265, 2630, 1079, 5505, 1199, 2008,   62, 1724, 6706,\n",
      "         1460, 1554, 2128,  742,  452, 7967, 1074, 3352,  862, 1342, 2072, 7917,\n",
      "          794,  380, 2052,  879, 1965, 1649, 5974, 1649, 2612, 3189, 5891, 1023,\n",
      "          416,  358, 2781,  145, 1723, 1659, 2938, 1906,  513,  957, 3266, 2834,\n",
      "         7124, 2112, 3046, 6730, 1717,  989, 7050, 1878, 2308,   25, 1936, 1154,\n",
      "         3612,  587, 4068, 7029,  169, 3412, 5170, 5163, 1640, 1213, 3753, 2472,\n",
      "         1213, 1044, 3035, 1113, 6615, 1063, 1472,  452,  197,  896, 3138,  439,\n",
      "          277,  711, 2035, 1217,   44, 1907, 5005, 1281, 1626,  441, 2954,  233,\n",
      "          210, 7176,  361,  961, 1119, 1437,  925, 3969, 3522, 1391, 1359,  718,\n",
      "         5415,  516, 2475, 5024,   42, 2188,  829,  269, 1249,  749, 4930, 2898,\n",
      "         1824, 1048, 2822,   74, 1585, 1227, 7317, 3419,  852,  600, 3209,  365,\n",
      "         4814, 2541, 1054, 5164, 1462, 1436,  401, 7612, 4203, 1383, 5827,  540,\n",
      "         6251,  913, 1212, 3902, 1081, 4888, 1622, 1322, 3445, 5657,  788, 1067,\n",
      "          475, 1615, 1710, 2788, 4594,  994,  603, 6322, 5661, 7699, 3936, 2681,\n",
      "         6660, 7329, 1575,  138,  296, 3051, 3906, 1483, 5301,    4, 1491]])}\n",
      "3 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,   28, 2321,  514,  561, 1289,  702,  495, 2762, 3921,  171, 1652,\n",
      "           34,  802,  961,   29,  492, 2122, 1324, 2131, 1554, 5040, 3060, 2877,\n",
      "          685, 1848,  928,  937, 4941, 2739, 3690, 3425,  392, 7477, 2214, 2106,\n",
      "         1854, 1987, 5807,  450, 1493, 1241, 2941,  361,  691, 2028,  492, 6679,\n",
      "          748, 4544,  229, 3967, 2387, 4470,  710,  660,  933,  176,  364, 7410,\n",
      "         4649,  803, 2486, 2297, 2030,  466, 2385, 5254, 1512, 1418, 3248, 2483,\n",
      "          364, 1808, 1796,  336,  423, 6562, 6562, 2982,  748, 3082,  905,  333,\n",
      "         1603, 2641, 1201, 1547, 1302,  130, 5460, 1039, 2971, 3357, 2585, 2393,\n",
      "         4415,  414,  717,  583, 1665, 1951, 3141, 4942, 3326,  209,  633, 6186,\n",
      "           66, 2123, 2257, 1426, 2598, 2486, 1260, 1324, 5258,  638, 1340,  748,\n",
      "         3957,  679, 1295, 4726,  288, 2222, 3739,  911,  459,  612, 1710, 1632,\n",
      "         2828,  949, 1215, 2652, 2965, 1573, 6856, 2937, 1326,   87,  722,  435,\n",
      "          848, 1785, 1233,  963, 1420, 3744, 1063, 1119, 3127, 1074, 2519, 2656,\n",
      "          526, 1380, 5201, 3414,  188, 1113, 1189,  828, 3545, 2893, 6681, 2248,\n",
      "          371, 4564, 2406, 6303, 2284, 3239, 1202, 4872, 1472, 2391, 2500,  129,\n",
      "         4229,  508, 2102, 2412, 3412, 5404,  171, 1805, 2265, 7535, 1079, 4429,\n",
      "          828, 1684,  526, 6691, 3138,   55,  788, 6385,  106, 3485, 3224, 6521,\n",
      "         2532,  391, 6766, 2891, 2714, 1285, 7305, 3259,  635, 2264, 1091,  698,\n",
      "          672,  311, 2205, 6358, 5468, 5827,  466,    3],\n",
      "        [   1,  252, 1552, 2911, 1804, 2075, 2301, 1258, 3541, 1045, 2831, 1083,\n",
      "            4, 6965,   26,  409, 1454,  917, 1056, 7617, 1875,   25, 4803, 3459,\n",
      "         2299,  524, 7206, 2859,  288,  860, 3506, 1924, 2965,  135, 3522, 7150,\n",
      "         1462, 2088, 2459, 2424, 5513, 4322,  463, 2473,  917, 4142, 1440, 2963,\n",
      "         7425, 1275, 1534,  881,  729, 1667, 4075, 3266, 3058, 5300, 1033, 1439,\n",
      "         7491,  183, 2280,  791, 3697, 1089, 2727, 4464, 1048,  926, 4707,  631,\n",
      "         3240,  467,  625, 1286,  125, 6919,  101,  429, 3018, 1079,  560, 4836,\n",
      "         4751, 6779,  311, 2017, 3397,  543, 4050, 2506,  759, 3573, 3916, 1564,\n",
      "         4243, 3876, 3241, 3400, 6128, 6929, 2233, 3467,  933,  750, 3051,  763,\n",
      "         3381, 4541,  676, 2053,  187, 2168, 1227, 7313,  287,  261,  287,  206,\n",
      "          478, 3610,  919, 2107, 1256, 5619, 7815,   89, 5837,  594, 3941, 3819,\n",
      "          257, 3172, 2926, 2632, 1800, 2674, 4278, 6165, 1086,  582,  984, 2360,\n",
      "         3067, 3535,  537, 2426, 1352,  229, 2160,  937,  386, 1857, 1293,  927,\n",
      "         2340, 7991,  715, 2856, 3934,  316, 2116, 1414,    3, 4446, 2735, 4426,\n",
      "         1455, 5565, 1356, 2091,  835, 3261,  899, 2693, 1348, 1667, 1133, 2924,\n",
      "          978, 2827,  985, 2611,    3,  844, 1728,  772, 6497, 2186, 1200, 2114,\n",
      "         7998, 7875, 2376, 4065, 6116, 3666,  970,  841,  581,  171, 4678, 1021,\n",
      "         2776, 1872,   95, 1311, 6226,  486, 1872, 1070, 4842, 7622,  867, 1098,\n",
      "         3590, 3115, 4715, 2670,  372,  744, 4323,   15]]), 'labels': tensor([[   1,   28, 2321,  514,  561, 1289,  702,  495, 2762, 3921,  171, 1652,\n",
      "           34,  802,  961,   29,  492, 2122, 1324, 2131, 1554, 5040, 3060, 2877,\n",
      "          685, 1848,  928,  937, 4941, 2739, 3690, 3425,  392, 7477, 2214, 2106,\n",
      "         1854, 1987, 5807,  450, 1493, 1241, 2941,  361,  691, 2028,  492, 6679,\n",
      "          748, 4544,  229, 3967, 2387, 4470,  710,  660,  933,  176,  364, 7410,\n",
      "         4649,  803, 2486, 2297, 2030,  466, 2385, 5254, 1512, 1418, 3248, 2483,\n",
      "          364, 1808, 1796,  336,  423, 6562, 6562, 2982,  748, 3082,  905,  333,\n",
      "         1603, 2641, 1201, 1547, 1302,  130, 5460, 1039, 2971, 3357, 2585, 2393,\n",
      "         4415,  414,  717,  583, 1665, 1951, 3141, 4942, 3326,  209,  633, 6186,\n",
      "           66, 2123, 2257, 1426, 2598, 2486, 1260, 1324, 5258,  638, 1340,  748,\n",
      "         3957,  679, 1295, 4726,  288, 2222, 3739,  911,  459,  612, 1710, 1632,\n",
      "         2828,  949, 1215, 2652, 2965, 1573, 6856, 2937, 1326,   87,  722,  435,\n",
      "          848, 1785, 1233,  963, 1420, 3744, 1063, 1119, 3127, 1074, 2519, 2656,\n",
      "          526, 1380, 5201, 3414,  188, 1113, 1189,  828, 3545, 2893, 6681, 2248,\n",
      "          371, 4564, 2406, 6303, 2284, 3239, 1202, 4872, 1472, 2391, 2500,  129,\n",
      "         4229,  508, 2102, 2412, 3412, 5404,  171, 1805, 2265, 7535, 1079, 4429,\n",
      "          828, 1684,  526, 6691, 3138,   55,  788, 6385,  106, 3485, 3224, 6521,\n",
      "         2532,  391, 6766, 2891, 2714, 1285, 7305, 3259,  635, 2264, 1091,  698,\n",
      "          672,  311, 2205, 6358, 5468, 5827,  466,    3],\n",
      "        [   1,  252, 1552, 2911, 1804, 2075, 2301, 1258, 3541, 1045, 2831, 1083,\n",
      "            4, 6965,   26,  409, 1454,  917, 1056, 7617, 1875,   25, 4803, 3459,\n",
      "         2299,  524, 7206, 2859,  288,  860, 3506, 1924, 2965,  135, 3522, 7150,\n",
      "         1462, 2088, 2459, 2424, 5513, 4322,  463, 2473,  917, 4142, 1440, 2963,\n",
      "         7425, 1275, 1534,  881,  729, 1667, 4075, 3266, 3058, 5300, 1033, 1439,\n",
      "         7491,  183, 2280,  791, 3697, 1089, 2727, 4464, 1048,  926, 4707,  631,\n",
      "         3240,  467,  625, 1286,  125, 6919,  101,  429, 3018, 1079,  560, 4836,\n",
      "         4751, 6779,  311, 2017, 3397,  543, 4050, 2506,  759, 3573, 3916, 1564,\n",
      "         4243, 3876, 3241, 3400, 6128, 6929, 2233, 3467,  933,  750, 3051,  763,\n",
      "         3381, 4541,  676, 2053,  187, 2168, 1227, 7313,  287,  261,  287,  206,\n",
      "          478, 3610,  919, 2107, 1256, 5619, 7815,   89, 5837,  594, 3941, 3819,\n",
      "          257, 3172, 2926, 2632, 1800, 2674, 4278, 6165, 1086,  582,  984, 2360,\n",
      "         3067, 3535,  537, 2426, 1352,  229, 2160,  937,  386, 1857, 1293,  927,\n",
      "         2340, 7991,  715, 2856, 3934,  316, 2116, 1414,    3, 4446, 2735, 4426,\n",
      "         1455, 5565, 1356, 2091,  835, 3261,  899, 2693, 1348, 1667, 1133, 2924,\n",
      "          978, 2827,  985, 2611,    3,  844, 1728,  772, 6497, 2186, 1200, 2114,\n",
      "         7998, 7875, 2376, 4065, 6116, 3666,  970,  841,  581,  171, 4678, 1021,\n",
      "         2776, 1872,   95, 1311, 6226,  486, 1872, 1070, 4842, 7622,  867, 1098,\n",
      "         3590, 3115, 4715, 2670,  372,  744, 4323,   15]])}\n",
      "4 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  820,  913,  508,  398,  998, 5048, 7183, 4154,  359, 1084, 6002,\n",
      "         2395, 6218, 2849,  343,   60, 6066,  788, 5244, 3815,  641, 1205,   27,\n",
      "         1428, 5858, 6862,  884, 2088,  337,  570,  233, 7259, 6515, 6254, 1515,\n",
      "          343,  965,  362,  283, 4263, 1212,  123, 3569],\n",
      "        [   1,  820, 2303, 6106, 5525,  341,  168, 3634, 2631, 2993, 2178, 4621,\n",
      "         4678,  719,  743, 1207,  885,  343, 5187, 6536, 2521, 2934, 1929, 5842,\n",
      "          333,   33, 7059,  341,  550, 1973, 6494, 1453,  422, 2164, 5655, 2010,\n",
      "          708, 6512, 4200, 3976, 3115, 2070, 2635, 7548],\n",
      "        [   1,  667, 1265, 2223, 3870,  403,  555, 2655, 1510, 1315,  794,   98,\n",
      "         2059,  373,  489, 2248,  691,  509, 1327,  413, 2183, 3584, 4657, 4342,\n",
      "         1193, 1375,  753,  454, 1770, 1610, 1610,  683,  346, 1012,  698, 6129,\n",
      "         2301,  571, 6816,  488, 1375,  814,  866,  493],\n",
      "        [   1, 6550, 5506, 3160, 2745,   67,  928,  616, 5113,  132, 6687, 2497,\n",
      "         4918, 2684,   39,  892, 5317,  687, 6191, 3899, 1417, 3297, 3668, 1677,\n",
      "         4255, 1615, 1321, 1922, 3469, 1511,   97, 7122, 3122,  859,  919,  313,\n",
      "          201,  940,  947, 1897, 2002, 1184, 1033,   49],\n",
      "        [   1,   28,  651, 3282, 1713, 1247, 7217, 3463, 1254, 1474, 2146, 1657,\n",
      "         2706, 4474, 3480, 6580,   44, 4789, 2940, 1966, 2715, 6400, 2132, 7483,\n",
      "         1399,   63,  875, 2082,   66, 6981,  653, 1294, 1516, 3731, 2643, 3830,\n",
      "         1444,   40,   87, 4158, 2973,  570, 3838,  937],\n",
      "        [   1,   28, 6749, 6447,  535, 2132,  265, 3671, 1432,   85, 1912,  994,\n",
      "         1773, 4611, 4028,  980,  565, 3383,  164, 2992, 1883, 3733, 4009, 2965,\n",
      "          290, 7127,    6, 6862, 2378, 2157, 2247, 4021, 1551, 3434, 1011, 2341,\n",
      "         3880, 3735, 1347, 2911,  559, 2346,  393, 1233],\n",
      "        [   1,   28, 3653, 5485, 2150, 6396, 1365, 1611, 1321, 1676,  787, 6922,\n",
      "          900, 3706, 1124, 1543, 2467, 2135, 5709,  524, 2375, 1160, 3308,  708,\n",
      "         2272, 1094, 1296,  503,  242, 5581, 4763, 7507, 1418, 3498, 6407,  941,\n",
      "         1425, 2171, 3336, 4365,  683,  641,  163, 3654],\n",
      "        [   1,  252, 7988,  343,  503, 4885,  204,   37,  247, 3218,  432, 2717,\n",
      "         3715, 3087,  477, 2757, 1298, 3343,  281,  774, 6369, 1213,  453, 2083,\n",
      "          362, 4816, 3123, 3255, 5838, 6767,  618,  211, 6345,   15, 1707, 1130,\n",
      "         6674, 4743, 1341, 1877, 2033, 1020, 1589, 1553],\n",
      "        [   1,   28, 5290, 1259,  356, 4042, 1478,   70, 2403, 2553, 1964, 1036,\n",
      "          767,  262, 3424, 2422, 1259, 2299,  388,   47, 2576,  322,   15,  670,\n",
      "         5994, 1781, 3248, 1670, 2433, 1039, 7818, 4444, 2898, 1084,   43, 4253,\n",
      "         2126,  409,  286,  674,  383, 1340,  336, 3465],\n",
      "        [   1,  667, 1291, 2792,  158, 5780, 3501,  998, 3458, 1480, 1974, 1629,\n",
      "         3719, 1930,  695,  638, 2098, 2093,  177, 1909,  692, 1349,  875,  727,\n",
      "         1085, 1222, 4617,  905,  752, 2098,  838, 2857, 3288, 1703, 2038, 3635,\n",
      "         1004, 1641, 1693, 1202,  728,    6, 1025, 1149],\n",
      "        [   1, 3078, 1584, 2388,  733,  873, 3540, 4479, 7546, 4444,  555, 1737,\n",
      "          603,   21, 2033,  678, 2392,  722,  843, 1400, 2897, 1387, 1521,  774,\n",
      "         3762, 7458,  841, 1580, 1121, 4157,  613, 2171, 3109,  112, 6133, 1160,\n",
      "          461, 1800,  537,  423,   33, 2569,  364, 1204]]), 'labels': tensor([[   1,  820,  913,  508,  398,  998, 5048, 7183, 4154,  359, 1084, 6002,\n",
      "         2395, 6218, 2849,  343,   60, 6066,  788, 5244, 3815,  641, 1205,   27,\n",
      "         1428, 5858, 6862,  884, 2088,  337,  570,  233, 7259, 6515, 6254, 1515,\n",
      "          343,  965,  362,  283, 4263, 1212,  123, 3569],\n",
      "        [   1,  820, 2303, 6106, 5525,  341,  168, 3634, 2631, 2993, 2178, 4621,\n",
      "         4678,  719,  743, 1207,  885,  343, 5187, 6536, 2521, 2934, 1929, 5842,\n",
      "          333,   33, 7059,  341,  550, 1973, 6494, 1453,  422, 2164, 5655, 2010,\n",
      "          708, 6512, 4200, 3976, 3115, 2070, 2635, 7548],\n",
      "        [   1,  667, 1265, 2223, 3870,  403,  555, 2655, 1510, 1315,  794,   98,\n",
      "         2059,  373,  489, 2248,  691,  509, 1327,  413, 2183, 3584, 4657, 4342,\n",
      "         1193, 1375,  753,  454, 1770, 1610, 1610,  683,  346, 1012,  698, 6129,\n",
      "         2301,  571, 6816,  488, 1375,  814,  866,  493],\n",
      "        [   1, 6550, 5506, 3160, 2745,   67,  928,  616, 5113,  132, 6687, 2497,\n",
      "         4918, 2684,   39,  892, 5317,  687, 6191, 3899, 1417, 3297, 3668, 1677,\n",
      "         4255, 1615, 1321, 1922, 3469, 1511,   97, 7122, 3122,  859,  919,  313,\n",
      "          201,  940,  947, 1897, 2002, 1184, 1033,   49],\n",
      "        [   1,   28,  651, 3282, 1713, 1247, 7217, 3463, 1254, 1474, 2146, 1657,\n",
      "         2706, 4474, 3480, 6580,   44, 4789, 2940, 1966, 2715, 6400, 2132, 7483,\n",
      "         1399,   63,  875, 2082,   66, 6981,  653, 1294, 1516, 3731, 2643, 3830,\n",
      "         1444,   40,   87, 4158, 2973,  570, 3838,  937],\n",
      "        [   1,   28, 6749, 6447,  535, 2132,  265, 3671, 1432,   85, 1912,  994,\n",
      "         1773, 4611, 4028,  980,  565, 3383,  164, 2992, 1883, 3733, 4009, 2965,\n",
      "          290, 7127,    6, 6862, 2378, 2157, 2247, 4021, 1551, 3434, 1011, 2341,\n",
      "         3880, 3735, 1347, 2911,  559, 2346,  393, 1233],\n",
      "        [   1,   28, 3653, 5485, 2150, 6396, 1365, 1611, 1321, 1676,  787, 6922,\n",
      "          900, 3706, 1124, 1543, 2467, 2135, 5709,  524, 2375, 1160, 3308,  708,\n",
      "         2272, 1094, 1296,  503,  242, 5581, 4763, 7507, 1418, 3498, 6407,  941,\n",
      "         1425, 2171, 3336, 4365,  683,  641,  163, 3654],\n",
      "        [   1,  252, 7988,  343,  503, 4885,  204,   37,  247, 3218,  432, 2717,\n",
      "         3715, 3087,  477, 2757, 1298, 3343,  281,  774, 6369, 1213,  453, 2083,\n",
      "          362, 4816, 3123, 3255, 5838, 6767,  618,  211, 6345,   15, 1707, 1130,\n",
      "         6674, 4743, 1341, 1877, 2033, 1020, 1589, 1553],\n",
      "        [   1,   28, 5290, 1259,  356, 4042, 1478,   70, 2403, 2553, 1964, 1036,\n",
      "          767,  262, 3424, 2422, 1259, 2299,  388,   47, 2576,  322,   15,  670,\n",
      "         5994, 1781, 3248, 1670, 2433, 1039, 7818, 4444, 2898, 1084,   43, 4253,\n",
      "         2126,  409,  286,  674,  383, 1340,  336, 3465],\n",
      "        [   1,  667, 1291, 2792,  158, 5780, 3501,  998, 3458, 1480, 1974, 1629,\n",
      "         3719, 1930,  695,  638, 2098, 2093,  177, 1909,  692, 1349,  875,  727,\n",
      "         1085, 1222, 4617,  905,  752, 2098,  838, 2857, 3288, 1703, 2038, 3635,\n",
      "         1004, 1641, 1693, 1202,  728,    6, 1025, 1149],\n",
      "        [   1, 3078, 1584, 2388,  733,  873, 3540, 4479, 7546, 4444,  555, 1737,\n",
      "          603,   21, 2033,  678, 2392,  722,  843, 1400, 2897, 1387, 1521,  774,\n",
      "         3762, 7458,  841, 1580, 1121, 4157,  613, 2171, 3109,  112, 6133, 1160,\n",
      "          461, 1800,  537,  423,   33, 2569,  364, 1204]])}\n",
      "5 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  438, 3434, 2157, 7517, 1279, 2090, 6246, 3077, 1066,  734, 2369,\n",
      "         2968, 4480, 1765, 5634, 2336, 2158,  960, 6131, 1402, 1919,  832,  953,\n",
      "         3836,  118, 2473, 2620, 2030, 1643, 5503, 6367, 1704,   47, 4966,  217,\n",
      "         3400, 2003,  118,  551, 2775, 2989, 2625,  119, 1901, 7799, 6021, 2110,\n",
      "         3620, 2188, 4845,  708, 7906, 3629, 2224, 1609, 1045, 1085, 5331, 1965,\n",
      "          670, 1378,  793,  566, 1867, 7401, 5548,  756, 3251,  103,  573, 2087,\n",
      "           52,   65,  873, 6454, 1654, 3556,    6, 3612,  612, 2623,  734,  538,\n",
      "         3151, 1060, 1947, 1132, 1292, 7302, 1177, 7830, 2621,  300, 1277,  947,\n",
      "         3220,  717, 7890, 3009, 2149,   16, 3487, 2059, 5846, 1561,  254,  378,\n",
      "          343,  121, 1500, 2774, 1378, 2307,  214,  324, 1127,  727, 1523, 1728,\n",
      "         1023, 1651, 7608,  932,   58, 4432,  547,  977, 7821,  669, 5006,  591,\n",
      "         1281, 4381, 2660, 3579, 2295, 2741, 1459,  921,  379, 2691, 2267],\n",
      "        [   1,  438, 1867, 1244, 2359, 1522, 5144,  905,  154,  312, 6240,   73,\n",
      "         1663, 2386, 2153, 2497,  533, 3590,  796, 5269,   34, 2145,  724, 5354,\n",
      "         1880, 2062, 4266, 3815, 5771, 5101, 1345, 1121,  809, 7928,  993, 3713,\n",
      "          509, 2989, 2158, 2288, 1599, 7536,  118, 1264, 4516, 7255, 1330,  237,\n",
      "         3116, 3216,  285,  489,  737,  431, 1920, 3650, 1295,  603, 1633,  964,\n",
      "         3458, 1212,  804, 1110, 1771,   41,  982, 1035,  507, 1827, 1194, 4278,\n",
      "         5028, 3811, 1508, 4874, 1982, 6413, 3180, 3738, 1599,  444, 4613, 3484,\n",
      "         1495, 2205,  247, 1036, 3837, 1253, 3101, 2709, 1744,  414, 2075, 4174,\n",
      "         2226,  277,  623,  756, 1674, 2490,  793,  398, 2061,  163, 2190, 7165,\n",
      "          333,   25,  282,  951, 2892, 1572, 1893,  810,  171, 5957,  598, 4046,\n",
      "          790, 6026,  714, 2442, 4905, 1178, 2211, 1695, 6691, 3214, 4688,  815,\n",
      "          495, 1964, 5919, 6300, 2825, 2126, 2933, 3347, 4800, 7191,  104],\n",
      "        [   1,  438, 3162, 1295, 1032, 1700, 1603,  308, 3233,  691,  887,  628,\n",
      "         5681,  972, 1934, 3091,  608, 6753, 1105, 1569, 7193,  383,  375, 1616,\n",
      "         2731, 2386, 3722,  471, 3796, 6672, 6589,  530,  585,  453, 3991, 7498,\n",
      "          730, 3281,  774,  112, 3804,   56, 6230,  308,  739, 1122, 2425, 1982,\n",
      "          464,  757, 1612,  559, 1236, 6038, 7380, 4732, 7317,  760, 1740, 2057,\n",
      "         1199,  364,  654, 1945, 5722,  512, 5276,  684, 5320, 1357, 5955, 1941,\n",
      "         1464,  365, 2673, 6384, 6791, 1528,  971, 1073, 3583, 1396, 1467, 3295,\n",
      "         1642, 6389, 7020, 1534,  364, 2800, 4232,  612, 1823, 2240,  578, 1317,\n",
      "         6093,  726, 1472,  541,  142, 1100, 3991, 3711, 2391, 3876,  402, 2712,\n",
      "         1661,  870,   42, 1911,  495, 3359, 1393, 7668, 1224,  643, 1956,  403,\n",
      "         1535,  669, 2119, 2388,  357, 4679, 3272,  885,  623, 1621,  731, 5082,\n",
      "         7114,  640,  492,  804, 2464, 1395, 1628,  885,  790, 5236, 1330]]), 'labels': tensor([[   1,  438, 3434, 2157, 7517, 1279, 2090, 6246, 3077, 1066,  734, 2369,\n",
      "         2968, 4480, 1765, 5634, 2336, 2158,  960, 6131, 1402, 1919,  832,  953,\n",
      "         3836,  118, 2473, 2620, 2030, 1643, 5503, 6367, 1704,   47, 4966,  217,\n",
      "         3400, 2003,  118,  551, 2775, 2989, 2625,  119, 1901, 7799, 6021, 2110,\n",
      "         3620, 2188, 4845,  708, 7906, 3629, 2224, 1609, 1045, 1085, 5331, 1965,\n",
      "          670, 1378,  793,  566, 1867, 7401, 5548,  756, 3251,  103,  573, 2087,\n",
      "           52,   65,  873, 6454, 1654, 3556,    6, 3612,  612, 2623,  734,  538,\n",
      "         3151, 1060, 1947, 1132, 1292, 7302, 1177, 7830, 2621,  300, 1277,  947,\n",
      "         3220,  717, 7890, 3009, 2149,   16, 3487, 2059, 5846, 1561,  254,  378,\n",
      "          343,  121, 1500, 2774, 1378, 2307,  214,  324, 1127,  727, 1523, 1728,\n",
      "         1023, 1651, 7608,  932,   58, 4432,  547,  977, 7821,  669, 5006,  591,\n",
      "         1281, 4381, 2660, 3579, 2295, 2741, 1459,  921,  379, 2691, 2267],\n",
      "        [   1,  438, 1867, 1244, 2359, 1522, 5144,  905,  154,  312, 6240,   73,\n",
      "         1663, 2386, 2153, 2497,  533, 3590,  796, 5269,   34, 2145,  724, 5354,\n",
      "         1880, 2062, 4266, 3815, 5771, 5101, 1345, 1121,  809, 7928,  993, 3713,\n",
      "          509, 2989, 2158, 2288, 1599, 7536,  118, 1264, 4516, 7255, 1330,  237,\n",
      "         3116, 3216,  285,  489,  737,  431, 1920, 3650, 1295,  603, 1633,  964,\n",
      "         3458, 1212,  804, 1110, 1771,   41,  982, 1035,  507, 1827, 1194, 4278,\n",
      "         5028, 3811, 1508, 4874, 1982, 6413, 3180, 3738, 1599,  444, 4613, 3484,\n",
      "         1495, 2205,  247, 1036, 3837, 1253, 3101, 2709, 1744,  414, 2075, 4174,\n",
      "         2226,  277,  623,  756, 1674, 2490,  793,  398, 2061,  163, 2190, 7165,\n",
      "          333,   25,  282,  951, 2892, 1572, 1893,  810,  171, 5957,  598, 4046,\n",
      "          790, 6026,  714, 2442, 4905, 1178, 2211, 1695, 6691, 3214, 4688,  815,\n",
      "          495, 1964, 5919, 6300, 2825, 2126, 2933, 3347, 4800, 7191,  104],\n",
      "        [   1,  438, 3162, 1295, 1032, 1700, 1603,  308, 3233,  691,  887,  628,\n",
      "         5681,  972, 1934, 3091,  608, 6753, 1105, 1569, 7193,  383,  375, 1616,\n",
      "         2731, 2386, 3722,  471, 3796, 6672, 6589,  530,  585,  453, 3991, 7498,\n",
      "          730, 3281,  774,  112, 3804,   56, 6230,  308,  739, 1122, 2425, 1982,\n",
      "          464,  757, 1612,  559, 1236, 6038, 7380, 4732, 7317,  760, 1740, 2057,\n",
      "         1199,  364,  654, 1945, 5722,  512, 5276,  684, 5320, 1357, 5955, 1941,\n",
      "         1464,  365, 2673, 6384, 6791, 1528,  971, 1073, 3583, 1396, 1467, 3295,\n",
      "         1642, 6389, 7020, 1534,  364, 2800, 4232,  612, 1823, 2240,  578, 1317,\n",
      "         6093,  726, 1472,  541,  142, 1100, 3991, 3711, 2391, 3876,  402, 2712,\n",
      "         1661,  870,   42, 1911,  495, 3359, 1393, 7668, 1224,  643, 1956,  403,\n",
      "         1535,  669, 2119, 2388,  357, 4679, 3272,  885,  623, 1621,  731, 5082,\n",
      "         7114,  640,  492,  804, 2464, 1395, 1628,  885,  790, 5236, 1330]])}\n",
      "6 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]]), 'input_ids': tensor([[   1,  438, 3967, 3031, 2037,  644, 4525, 2853, 1595, 7655, 2122, 3882,\n",
      "         1948,  827, 3159,  233, 7655, 1388,  155,  402, 1702, 7473, 1425, 6283,\n",
      "           87, 2633, 7887, 1619, 5549, 1394, 4520, 2760, 1609,  776, 5306, 5830,\n",
      "         4472,  116, 1497,  700, 1339,  817, 2097, 1284, 3985, 1787,  453,  798,\n",
      "         1424,   16,  574,  373, 4954,  129,  352, 5230,  355,  322, 1892, 5268,\n",
      "          276,  462, 2340,  672, 2771, 2802,   83, 3842, 2067,  627, 2938,   91,\n",
      "          585,  262, 6913, 5515, 5746, 7924, 3154,  371, 2948,  581, 1380, 3107,\n",
      "         3767, 4351, 2564, 1598, 3932,   75,  831, 1049, 5327, 1058, 4681, 2163,\n",
      "         1704, 6553, 3401, 1015,  610,  572, 6446, 2597,  994, 5837, 5524,  415,\n",
      "         6872,  621,  735,  795, 3080, 6009, 3758, 1938, 6646,   51, 1397, 1023,\n",
      "         1676, 4256, 2426,  577, 1488, 1573, 1417,  885,  210,  626, 3796, 5908,\n",
      "         1104, 1312, 1971, 5161,  309, 6629, 5292, 2234,  799,  522, 7668, 4861,\n",
      "         3905,  117,  763, 6219,  183,  472, 6945, 4057, 6506,   39, 5424, 1354,\n",
      "         4799, 1052,  665,  641, 7602, 5994,  773, 4737, 3263,    3, 6532,  714,\n",
      "         7097, 4873],\n",
      "        [   1,   28,  730,  740, 1090, 1136,  456,  473,   53,   42, 1509, 1948,\n",
      "         1188, 1134, 1846, 3613, 2297,  724, 4365,  552,  285, 7945,   62,  763,\n",
      "          722, 2370, 1116, 4173,  262,  679, 1541, 1076, 2865, 4940, 1099,    3,\n",
      "          511, 4147,  871,  778, 3304, 7170, 5460,  127, 1553, 2108, 2105, 2914,\n",
      "          983,  650, 3314, 2623, 3387, 4530,  609,  524,  669,  271, 1657, 1808,\n",
      "           64, 6392, 7275,  829, 7329, 7441, 7915, 1197, 5498, 2501, 1270,  380,\n",
      "          691, 2264, 3666, 1374,  220, 7253, 4945, 2410,  567,  258,  269, 1990,\n",
      "         4138, 1195, 1421, 1126, 2807, 2976, 1573, 5702,  577,  483, 2485, 3873,\n",
      "         3253, 3953, 1706, 6510, 4490, 1884,  189, 5677, 2305, 2279, 1288, 3747,\n",
      "          676, 2067,  111, 1289, 3937, 3891,  855, 1626,  590,   86, 4889,  217,\n",
      "          177, 1776,  385, 1193, 5198, 4376, 4843, 2571, 1813,  968, 7224, 2886,\n",
      "         2930, 2786, 5226, 1809, 1753, 1953, 1456, 3478, 3170, 2104, 4041,  598,\n",
      "          850, 1919, 1419,  706, 2453,  384,  746,  871,   55,  381, 1433, 1942,\n",
      "         5937, 2755, 2674,   96, 1546,  830, 7247,   65, 3566, 5072, 1244, 4582,\n",
      "          519, 5604]]), 'labels': tensor([[   1,  438, 3967, 3031, 2037,  644, 4525, 2853, 1595, 7655, 2122, 3882,\n",
      "         1948,  827, 3159,  233, 7655, 1388,  155,  402, 1702, 7473, 1425, 6283,\n",
      "           87, 2633, 7887, 1619, 5549, 1394, 4520, 2760, 1609,  776, 5306, 5830,\n",
      "         4472,  116, 1497,  700, 1339,  817, 2097, 1284, 3985, 1787,  453,  798,\n",
      "         1424,   16,  574,  373, 4954,  129,  352, 5230,  355,  322, 1892, 5268,\n",
      "          276,  462, 2340,  672, 2771, 2802,   83, 3842, 2067,  627, 2938,   91,\n",
      "          585,  262, 6913, 5515, 5746, 7924, 3154,  371, 2948,  581, 1380, 3107,\n",
      "         3767, 4351, 2564, 1598, 3932,   75,  831, 1049, 5327, 1058, 4681, 2163,\n",
      "         1704, 6553, 3401, 1015,  610,  572, 6446, 2597,  994, 5837, 5524,  415,\n",
      "         6872,  621,  735,  795, 3080, 6009, 3758, 1938, 6646,   51, 1397, 1023,\n",
      "         1676, 4256, 2426,  577, 1488, 1573, 1417,  885,  210,  626, 3796, 5908,\n",
      "         1104, 1312, 1971, 5161,  309, 6629, 5292, 2234,  799,  522, 7668, 4861,\n",
      "         3905,  117,  763, 6219,  183,  472, 6945, 4057, 6506,   39, 5424, 1354,\n",
      "         4799, 1052,  665,  641, 7602, 5994,  773, 4737, 3263,    3, 6532,  714,\n",
      "         7097, 4873],\n",
      "        [   1,   28,  730,  740, 1090, 1136,  456,  473,   53,   42, 1509, 1948,\n",
      "         1188, 1134, 1846, 3613, 2297,  724, 4365,  552,  285, 7945,   62,  763,\n",
      "          722, 2370, 1116, 4173,  262,  679, 1541, 1076, 2865, 4940, 1099,    3,\n",
      "          511, 4147,  871,  778, 3304, 7170, 5460,  127, 1553, 2108, 2105, 2914,\n",
      "          983,  650, 3314, 2623, 3387, 4530,  609,  524,  669,  271, 1657, 1808,\n",
      "           64, 6392, 7275,  829, 7329, 7441, 7915, 1197, 5498, 2501, 1270,  380,\n",
      "          691, 2264, 3666, 1374,  220, 7253, 4945, 2410,  567,  258,  269, 1990,\n",
      "         4138, 1195, 1421, 1126, 2807, 2976, 1573, 5702,  577,  483, 2485, 3873,\n",
      "         3253, 3953, 1706, 6510, 4490, 1884,  189, 5677, 2305, 2279, 1288, 3747,\n",
      "          676, 2067,  111, 1289, 3937, 3891,  855, 1626,  590,   86, 4889,  217,\n",
      "          177, 1776,  385, 1193, 5198, 4376, 4843, 2571, 1813,  968, 7224, 2886,\n",
      "         2930, 2786, 5226, 1809, 1753, 1953, 1456, 3478, 3170, 2104, 4041,  598,\n",
      "          850, 1919, 1419,  706, 2453,  384,  746,  871,   55,  381, 1433, 1942,\n",
      "         5937, 2755, 2674,   96, 1546,  830, 7247,   65, 3566, 5072, 1244, 4582,\n",
      "          519, 5604]])}\n",
      "7 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  751,  855,  217, 2630, 1881, 3427, 4958, 1496, 1530, 2928, 1378,\n",
      "         2683, 1126, 4691,  996,  841, 2491, 4510, 1366, 3253, 5474,  482,  475,\n",
      "         5959, 2726,  325,  345, 4674,  828,  850, 2479, 6148, 4195,  209,  701,\n",
      "         6150, 1222,  905,  351,  840, 1552, 2412, 6531,  606, 5471, 4757, 1355,\n",
      "          224, 3629, 4623, 5882,  949, 7967, 1034,  607,  823,  386,   27,  652,\n",
      "         5514, 2947, 1477,  461, 4314, 3804,  249, 1781,  447, 3170,  869, 2308,\n",
      "         1755, 1936, 4467, 7093,  364, 1830,  819, 5489,  480, 2022, 1424,  905,\n",
      "          681,  861, 3684, 1439, 6446, 2226, 2442, 6190, 4745, 3887, 7257, 3268,\n",
      "          250, 2178,  485,  124, 7774, 1173,  923, 5284, 2786,  498, 1494,  360,\n",
      "          527, 2294, 4307, 6773, 7596,   57, 2367,  671,  881, 1322,  648, 2144,\n",
      "         3081, 2131, 1027,  518, 2447, 3157, 5483, 6527, 2761, 5259, 4470,   40,\n",
      "         1045,   53, 6417,   40,  739,  521, 1515, 2478, 2915, 2293,  800, 1060,\n",
      "         5948, 4110,   53, 1120, 1607, 2884,  514, 7507,  153, 3389, 2426,   37,\n",
      "          990, 1269, 3298, 4042, 3278, 3391,  859, 1865,  986, 4061,  485, 5034,\n",
      "            9,  345, 2148,  144, 1706, 1332,  851, 5272,  507, 4777,  639, 2370,\n",
      "         1376, 1706, 1165,  431, 5666,  313, 1321, 1907, 7629, 2438, 1018,  165,\n",
      "         1768, 1700, 3495, 6750, 4205, 1091, 1548, 2443,  669, 1556,  883,  818,\n",
      "         1932, 7387,  550,    5,  909, 3176, 6706,  235, 1705,  637, 2185, 3505,\n",
      "           54, 2521, 2384,  132, 3264, 1278,  749,  519, 5060, 3883,  223, 6629,\n",
      "         1891, 1830, 4373,  542,   16,  559,  701, 3037, 1932, 6282, 5494, 1290,\n",
      "         4589,  589, 1056, 4412, 7332, 4080,    6,  341, 1573, 6438, 1970, 4163,\n",
      "         3108, 3608, 1266, 7943, 1621,  970,   62, 1342,  240, 2371,  674, 1276,\n",
      "          823, 1589, 5783, 2204,  698, 4603,   39,  938, 2208, 2806, 1825, 7305,\n",
      "         6808, 6205, 1424,  251, 2016, 1878, 2263, 2319,  247,  925, 1174, 1656,\n",
      "         1884,  558, 4784,  213, 4277, 1109,  465,  788, 7230,  683,  736,  732,\n",
      "           16, 3608, 1619,  141, 2023,  596, 6075, 1348, 6035, 2641,  578,  268,\n",
      "           15,  524, 1585, 1789, 1229, 7187,  524,   91,  580, 7583, 3004,  298,\n",
      "          354, 6055,   88,  702, 6111,  409, 6372, 3162, 3259, 3791, 4687, 2395,\n",
      "         7882,   26, 7681,  149,   32, 6110, 1944, 1228, 2592,   41, 7666,  328,\n",
      "          389, 2593, 6585, 4728, 3908,  733, 2879, 1784, 2660, 5664,  707, 4646,\n",
      "         2328, 3114, 3534,  562,   67, 2532,  595, 7527,  364, 2903, 1064, 1160,\n",
      "         1622, 2042, 2608, 1622,  802,  440,  418, 6708,  411, 5478, 1390,  927,\n",
      "         2016,  482, 3820, 3447, 7464, 1931, 6325, 1859, 6760, 1506, 1780,  859,\n",
      "         7091,  493, 2693, 1726, 2747,   27,  796, 1993, 2616, 5090,  575, 1983,\n",
      "         7878, 6619, 2606,  564,   46, 6336, 4535, 4435, 2323, 2291, 1293,  846,\n",
      "         1737,  334,   42, 2115,  690, 1686,  690, 3573,  889, 2863, 2960, 5288,\n",
      "         6919, 1575,  466, 5678, 4465, 5072, 5180, 2209, 3739, 1062, 1561,  431,\n",
      "         1876,  702, 2039, 2216,  276, 4652,   96, 3176,  683, 3034,  684,  731,\n",
      "         7620, 3148, 2159, 1877,  516,  204, 1758, 1476, 1819, 2746, 1945, 2406,\n",
      "          853,  695, 1684,  795,  565, 1443, 1692, 1945, 5395, 5282,  855, 1223,\n",
      "         3511, 2982, 4654, 1677, 6411,  564, 4463, 5277, 2243, 4609, 4522, 1417,\n",
      "         4251,   25,  553,  841, 2736,  817, 5338,  856,  384, 4174, 3886,  681,\n",
      "           31, 5574, 6978, 3292, 4436, 2397, 5454, 2552]]), 'labels': tensor([[   1,  751,  855,  217, 2630, 1881, 3427, 4958, 1496, 1530, 2928, 1378,\n",
      "         2683, 1126, 4691,  996,  841, 2491, 4510, 1366, 3253, 5474,  482,  475,\n",
      "         5959, 2726,  325,  345, 4674,  828,  850, 2479, 6148, 4195,  209,  701,\n",
      "         6150, 1222,  905,  351,  840, 1552, 2412, 6531,  606, 5471, 4757, 1355,\n",
      "          224, 3629, 4623, 5882,  949, 7967, 1034,  607,  823,  386,   27,  652,\n",
      "         5514, 2947, 1477,  461, 4314, 3804,  249, 1781,  447, 3170,  869, 2308,\n",
      "         1755, 1936, 4467, 7093,  364, 1830,  819, 5489,  480, 2022, 1424,  905,\n",
      "          681,  861, 3684, 1439, 6446, 2226, 2442, 6190, 4745, 3887, 7257, 3268,\n",
      "          250, 2178,  485,  124, 7774, 1173,  923, 5284, 2786,  498, 1494,  360,\n",
      "          527, 2294, 4307, 6773, 7596,   57, 2367,  671,  881, 1322,  648, 2144,\n",
      "         3081, 2131, 1027,  518, 2447, 3157, 5483, 6527, 2761, 5259, 4470,   40,\n",
      "         1045,   53, 6417,   40,  739,  521, 1515, 2478, 2915, 2293,  800, 1060,\n",
      "         5948, 4110,   53, 1120, 1607, 2884,  514, 7507,  153, 3389, 2426,   37,\n",
      "          990, 1269, 3298, 4042, 3278, 3391,  859, 1865,  986, 4061,  485, 5034,\n",
      "            9,  345, 2148,  144, 1706, 1332,  851, 5272,  507, 4777,  639, 2370,\n",
      "         1376, 1706, 1165,  431, 5666,  313, 1321, 1907, 7629, 2438, 1018,  165,\n",
      "         1768, 1700, 3495, 6750, 4205, 1091, 1548, 2443,  669, 1556,  883,  818,\n",
      "         1932, 7387,  550,    5,  909, 3176, 6706,  235, 1705,  637, 2185, 3505,\n",
      "           54, 2521, 2384,  132, 3264, 1278,  749,  519, 5060, 3883,  223, 6629,\n",
      "         1891, 1830, 4373,  542,   16,  559,  701, 3037, 1932, 6282, 5494, 1290,\n",
      "         4589,  589, 1056, 4412, 7332, 4080,    6,  341, 1573, 6438, 1970, 4163,\n",
      "         3108, 3608, 1266, 7943, 1621,  970,   62, 1342,  240, 2371,  674, 1276,\n",
      "          823, 1589, 5783, 2204,  698, 4603,   39,  938, 2208, 2806, 1825, 7305,\n",
      "         6808, 6205, 1424,  251, 2016, 1878, 2263, 2319,  247,  925, 1174, 1656,\n",
      "         1884,  558, 4784,  213, 4277, 1109,  465,  788, 7230,  683,  736,  732,\n",
      "           16, 3608, 1619,  141, 2023,  596, 6075, 1348, 6035, 2641,  578,  268,\n",
      "           15,  524, 1585, 1789, 1229, 7187,  524,   91,  580, 7583, 3004,  298,\n",
      "          354, 6055,   88,  702, 6111,  409, 6372, 3162, 3259, 3791, 4687, 2395,\n",
      "         7882,   26, 7681,  149,   32, 6110, 1944, 1228, 2592,   41, 7666,  328,\n",
      "          389, 2593, 6585, 4728, 3908,  733, 2879, 1784, 2660, 5664,  707, 4646,\n",
      "         2328, 3114, 3534,  562,   67, 2532,  595, 7527,  364, 2903, 1064, 1160,\n",
      "         1622, 2042, 2608, 1622,  802,  440,  418, 6708,  411, 5478, 1390,  927,\n",
      "         2016,  482, 3820, 3447, 7464, 1931, 6325, 1859, 6760, 1506, 1780,  859,\n",
      "         7091,  493, 2693, 1726, 2747,   27,  796, 1993, 2616, 5090,  575, 1983,\n",
      "         7878, 6619, 2606,  564,   46, 6336, 4535, 4435, 2323, 2291, 1293,  846,\n",
      "         1737,  334,   42, 2115,  690, 1686,  690, 3573,  889, 2863, 2960, 5288,\n",
      "         6919, 1575,  466, 5678, 4465, 5072, 5180, 2209, 3739, 1062, 1561,  431,\n",
      "         1876,  702, 2039, 2216,  276, 4652,   96, 3176,  683, 3034,  684,  731,\n",
      "         7620, 3148, 2159, 1877,  516,  204, 1758, 1476, 1819, 2746, 1945, 2406,\n",
      "          853,  695, 1684,  795,  565, 1443, 1692, 1945, 5395, 5282,  855, 1223,\n",
      "         3511, 2982, 4654, 1677, 6411,  564, 4463, 5277, 2243, 4609, 4522, 1417,\n",
      "         4251,   25,  553,  841, 2736,  817, 5338,  856,  384, 4174, 3886,  681,\n",
      "           31, 5574, 6978, 3292, 4436, 2397, 5454, 2552]])}\n",
      "8 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), 'input_ids': tensor([[   1,   28, 6453,  680,   22, 1880, 1565, 7397,   21,  467,  172, 4011,\n",
      "         2840,   65, 1716, 4144, 5341, 7153,   95, 1302, 3134, 1218,   40,  569,\n",
      "         3901, 4377, 7080,  671,  839, 3562, 5169, 1489,  788, 3453, 1937, 2937,\n",
      "          917, 2994, 5936, 3429,   61, 2597,  192, 4080, 1778, 3501, 7105, 1284,\n",
      "         6087],\n",
      "        [   1,  820,   80, 7064, 3923, 4372,  320, 6875, 7776, 4440,  271,  367,\n",
      "          262, 2421, 1530, 1618, 1060,  618, 1038, 2575, 4182, 1162, 2899,  595,\n",
      "          253, 4150, 4739, 5450, 7959, 5157, 6346, 3391,  978, 1253, 6479, 1141,\n",
      "          569, 3869, 1097, 1741, 5074, 6452, 7739,  334, 4875, 6081, 4308, 1212,\n",
      "         1167],\n",
      "        [   1,  390,  446,  476, 2412,  329, 1170, 2164, 2501, 5297, 2520, 3721,\n",
      "         5549, 2832,  770, 7088, 2869, 4413,  621, 1395,  780, 1160, 1486,  258,\n",
      "         3808, 1937,  959, 3733, 2714,  889, 1910, 4976,  650,  310,  871, 2465,\n",
      "         2343, 1210,  546,  480,  467, 3437, 7975,  650, 4941,   47,  970, 7840,\n",
      "           69],\n",
      "        [   1, 3078, 3020, 2102, 3616, 4687, 3915, 4859,   61, 7021,  973, 2545,\n",
      "         2532, 6420, 5078,  174,  992, 1651, 2104, 4456, 4350,  785, 1979,   85,\n",
      "         1077, 1995, 5383, 6986, 5160, 5274,  429,  863, 3349, 1607,  383,  596,\n",
      "         1077,  933, 1515,    6, 2183, 3906, 3372, 4913,  644, 2185, 6256, 6112,\n",
      "          796],\n",
      "        [   1,  886, 2741, 3274,   58,  412,  588,   47, 6804, 2403,  145, 4424,\n",
      "         2965, 3697, 1187, 5727, 4186, 1941, 7871, 4077, 3459, 2420, 4931, 1487,\n",
      "         7903, 5315, 1220, 1653, 4119,  309,  726, 1356, 2087, 2357,  533,  361,\n",
      "         5701,  689,  378, 4889, 3398, 1445, 3697, 3574, 7881, 5323,  333, 2548,\n",
      "          395],\n",
      "        [   1,  260, 2607,  834,  349, 5409, 6418,  888,   21, 1247, 2745,  682,\n",
      "          224, 2038,  884, 3371, 2836,   39, 4109, 4946, 2359,   50,  498,   32,\n",
      "          892, 1241,   57, 2351, 2164,    6, 5959, 2300, 2991, 2220,  650, 5385,\n",
      "         1463,  337, 1816, 4961, 2861,  444,  516,  787, 2535,   59, 1015,  705,\n",
      "          395],\n",
      "        [   1,   28,  253,  986, 4484, 1477, 1451, 3395,  442, 2673, 1135, 1387,\n",
      "         1753, 3334,  811,  607, 1813,  624, 3739, 5673, 2284, 1481,  325,   88,\n",
      "          276, 1423,  837,  798,   61, 1717, 3282, 7161, 4641,  466,  503, 1295,\n",
      "         2178, 7566, 3086,  565, 2620,   43, 3166, 1253, 6649, 7219, 2632, 5411,\n",
      "         2761],\n",
      "        [   1,  390, 4496,  701,  465, 3589,  389,  816,  377, 1051, 3079,  360,\n",
      "         2144, 2073, 2852, 4445, 1770,  209,  526, 2056, 1546, 4386,  553, 1767,\n",
      "         3784, 1017, 2394, 1127, 4836,  888, 1310, 3268, 1428, 7126, 2287,  107,\n",
      "          636, 2194, 1620, 2763, 1211, 6391,  620, 4312, 2536,  730, 1136, 4439,\n",
      "         4809],\n",
      "        [   1,  260, 6524,  351,  579, 4149, 1110,  169, 5018,  519, 1225, 2944,\n",
      "         1034, 2241,  573, 1788,  101,  339,  348,  913, 1823, 2956,  217, 3258,\n",
      "          368, 6056,  869, 3740,  297, 2320, 6386,  955,  761,  360, 1719, 3396,\n",
      "         5062,  123, 5822, 1873,  223,  788, 4514,  836,  437, 1157, 5403,  467,\n",
      "         2695],\n",
      "        [   1,  252, 1057, 4695, 7152, 2314,   31,  597, 1678,  739, 5682, 1810,\n",
      "          191,  612,   66, 7621, 1708, 7091, 6328,   27,   25, 1133,  741, 5691,\n",
      "         2227, 3296, 4949,    3, 1633,  625, 7528, 3659, 7814, 1689,  586, 3808,\n",
      "         1996, 3191, 1745,  427, 2256,  427,   52,  324, 5150,  816, 1547, 1520,\n",
      "          453]]), 'labels': tensor([[   1,   28, 6453,  680,   22, 1880, 1565, 7397,   21,  467,  172, 4011,\n",
      "         2840,   65, 1716, 4144, 5341, 7153,   95, 1302, 3134, 1218,   40,  569,\n",
      "         3901, 4377, 7080,  671,  839, 3562, 5169, 1489,  788, 3453, 1937, 2937,\n",
      "          917, 2994, 5936, 3429,   61, 2597,  192, 4080, 1778, 3501, 7105, 1284,\n",
      "         6087],\n",
      "        [   1,  820,   80, 7064, 3923, 4372,  320, 6875, 7776, 4440,  271,  367,\n",
      "          262, 2421, 1530, 1618, 1060,  618, 1038, 2575, 4182, 1162, 2899,  595,\n",
      "          253, 4150, 4739, 5450, 7959, 5157, 6346, 3391,  978, 1253, 6479, 1141,\n",
      "          569, 3869, 1097, 1741, 5074, 6452, 7739,  334, 4875, 6081, 4308, 1212,\n",
      "         1167],\n",
      "        [   1,  390,  446,  476, 2412,  329, 1170, 2164, 2501, 5297, 2520, 3721,\n",
      "         5549, 2832,  770, 7088, 2869, 4413,  621, 1395,  780, 1160, 1486,  258,\n",
      "         3808, 1937,  959, 3733, 2714,  889, 1910, 4976,  650,  310,  871, 2465,\n",
      "         2343, 1210,  546,  480,  467, 3437, 7975,  650, 4941,   47,  970, 7840,\n",
      "           69],\n",
      "        [   1, 3078, 3020, 2102, 3616, 4687, 3915, 4859,   61, 7021,  973, 2545,\n",
      "         2532, 6420, 5078,  174,  992, 1651, 2104, 4456, 4350,  785, 1979,   85,\n",
      "         1077, 1995, 5383, 6986, 5160, 5274,  429,  863, 3349, 1607,  383,  596,\n",
      "         1077,  933, 1515,    6, 2183, 3906, 3372, 4913,  644, 2185, 6256, 6112,\n",
      "          796],\n",
      "        [   1,  886, 2741, 3274,   58,  412,  588,   47, 6804, 2403,  145, 4424,\n",
      "         2965, 3697, 1187, 5727, 4186, 1941, 7871, 4077, 3459, 2420, 4931, 1487,\n",
      "         7903, 5315, 1220, 1653, 4119,  309,  726, 1356, 2087, 2357,  533,  361,\n",
      "         5701,  689,  378, 4889, 3398, 1445, 3697, 3574, 7881, 5323,  333, 2548,\n",
      "          395],\n",
      "        [   1,  260, 2607,  834,  349, 5409, 6418,  888,   21, 1247, 2745,  682,\n",
      "          224, 2038,  884, 3371, 2836,   39, 4109, 4946, 2359,   50,  498,   32,\n",
      "          892, 1241,   57, 2351, 2164,    6, 5959, 2300, 2991, 2220,  650, 5385,\n",
      "         1463,  337, 1816, 4961, 2861,  444,  516,  787, 2535,   59, 1015,  705,\n",
      "          395],\n",
      "        [   1,   28,  253,  986, 4484, 1477, 1451, 3395,  442, 2673, 1135, 1387,\n",
      "         1753, 3334,  811,  607, 1813,  624, 3739, 5673, 2284, 1481,  325,   88,\n",
      "          276, 1423,  837,  798,   61, 1717, 3282, 7161, 4641,  466,  503, 1295,\n",
      "         2178, 7566, 3086,  565, 2620,   43, 3166, 1253, 6649, 7219, 2632, 5411,\n",
      "         2761],\n",
      "        [   1,  390, 4496,  701,  465, 3589,  389,  816,  377, 1051, 3079,  360,\n",
      "         2144, 2073, 2852, 4445, 1770,  209,  526, 2056, 1546, 4386,  553, 1767,\n",
      "         3784, 1017, 2394, 1127, 4836,  888, 1310, 3268, 1428, 7126, 2287,  107,\n",
      "          636, 2194, 1620, 2763, 1211, 6391,  620, 4312, 2536,  730, 1136, 4439,\n",
      "         4809],\n",
      "        [   1,  260, 6524,  351,  579, 4149, 1110,  169, 5018,  519, 1225, 2944,\n",
      "         1034, 2241,  573, 1788,  101,  339,  348,  913, 1823, 2956,  217, 3258,\n",
      "          368, 6056,  869, 3740,  297, 2320, 6386,  955,  761,  360, 1719, 3396,\n",
      "         5062,  123, 5822, 1873,  223,  788, 4514,  836,  437, 1157, 5403,  467,\n",
      "         2695],\n",
      "        [   1,  252, 1057, 4695, 7152, 2314,   31,  597, 1678,  739, 5682, 1810,\n",
      "          191,  612,   66, 7621, 1708, 7091, 6328,   27,   25, 1133,  741, 5691,\n",
      "         2227, 3296, 4949,    3, 1633,  625, 7528, 3659, 7814, 1689,  586, 3808,\n",
      "         1996, 3191, 1745,  427, 2256,  427,   52,  324, 5150,  816, 1547, 1520,\n",
      "          453]])}\n",
      "9 {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[   1,  252, 2448,  322, 2548, 1447,  700,  393,  756, 3601, 5972, 1739,\n",
      "          901, 2215, 1292,  287, 1219,  989, 6094,  928,  322, 1984, 1839,   83,\n",
      "         3678, 2752, 4697, 5776, 3200,   47, 1802, 2047, 1309,   82, 5076,  552,\n",
      "         3502, 1864,  871, 4538, 2236, 1689, 7283, 2391,  914, 6851,  971, 3847,\n",
      "         1658,  808,  871, 1714, 1048, 3512, 1542, 2340, 1923, 7950, 1234, 1068,\n",
      "         2594, 2250, 2353, 4228, 6540,  679, 1352, 2474, 1637,   22, 2467, 2880,\n",
      "         1039, 3372, 5574, 2538, 1451, 3265, 2146, 3724, 1284, 1356, 3160,  107,\n",
      "          763, 1109, 3183, 1116, 2139,  785, 2500, 1214, 2184, 1128, 4757, 4125,\n",
      "         1131,   26, 4087,  428, 2951, 2347, 1161,  388,  647, 7583,  625, 1762,\n",
      "         1708, 7135, 4529, 4424, 2968, 3529,  374, 2581,  191, 3397, 2882, 1950,\n",
      "         7919,  499, 4320, 3517, 5354, 2955, 3494,  903, 3280,  539, 7703, 6277,\n",
      "         1053,  373, 2033, 2482,  947, 3198, 1631, 1206, 1732, 5663,   25,  380,\n",
      "         1994,  492, 5350,  595,  443,  922, 7953, 4667,  217,  346, 3140, 3193,\n",
      "           30, 2567, 1698, 3900, 6880,  933, 1848,  793,  317, 3810,   54,  232,\n",
      "         3791, 2670, 1954, 1659, 2566, 5826, 2670, 1118, 2674, 2903, 3955, 1075,\n",
      "         1317,  406, 2158, 1380,   24, 3685, 5946,  721,  362,  793, 1872, 1511,\n",
      "         3632,  416, 5327, 2389,    3, 3779,  125, 1380, 3066, 5993,  183, 3026,\n",
      "         1761, 1670, 5368,  784, 1036, 6462, 1827, 2817,  555, 1256, 4201, 3995,\n",
      "          842, 1666,  726, 2282, 7013, 1358, 1296,  383, 2810, 1050, 1942, 2412],\n",
      "        [   1,  252, 2281,  326,  883, 1261, 2581, 1143,  776, 2936, 2467, 4494,\n",
      "         1906, 4745,   87,  258, 1200, 4555, 4555, 5092,  768, 3331,  803, 1861,\n",
      "         2185,  189, 1952, 6817, 7962, 1877, 3331,  239,  519, 6137,  572, 1823,\n",
      "         1189, 1581, 2070, 3031, 1881, 2176, 2072, 5513,   80, 1321, 3990,  976,\n",
      "         2781,  581,  578,  514, 2427,  794, 4555, 1105,  829, 2282, 1790,  566,\n",
      "         4466,  496, 2220, 5306, 2116, 1352, 2029, 2807, 1606, 3385,  863,  107,\n",
      "          961, 1043, 2648, 6007, 2215,  793, 4637,  741, 4849, 1719, 4524, 2460,\n",
      "         1067, 1794, 1461, 3585, 1510, 6820,  509, 5268, 2930,  409, 3769, 2208,\n",
      "         1577, 7240,  739, 4279, 6148, 1297,  136, 1909, 2914, 7211, 4755, 3313,\n",
      "         2928, 4053, 7194, 4905, 3081, 3916, 1912, 1668,  885, 3066,  997, 1565,\n",
      "         2357, 5253, 3166, 1354,  742, 4306,   61, 4070, 2430,  976,  256,  453,\n",
      "         1836, 2291, 2223,  575,  900, 1091, 3218, 2611, 4611,  557, 3357, 1526,\n",
      "         1176,  109, 1894, 4384, 3352,  494, 4340,  310, 2022, 3627, 1291, 1700,\n",
      "          614, 2568, 2124, 1929, 1969, 3437, 3467, 2700, 3259, 1599, 2302,  686,\n",
      "         4573,  509,  725, 5244, 6126, 2647, 1877,  845, 1877, 1552, 4880, 2263,\n",
      "         3073, 1253, 1156, 6368,  395, 4171, 3397, 4554,  282, 5591, 1345,  644,\n",
      "          802, 3805, 3792, 3434, 3953,  776, 3234, 1009, 1403, 6756, 2083, 3791,\n",
      "         1361,  129, 1877, 2419, 3050, 3004, 1553, 4552, 1239, 1716, 1477, 4238,\n",
      "         3125, 5266, 7945, 5489, 1684,  827, 3156, 3558,    6, 3485, 1589, 3212]]), 'labels': tensor([[   1,  252, 2448,  322, 2548, 1447,  700,  393,  756, 3601, 5972, 1739,\n",
      "          901, 2215, 1292,  287, 1219,  989, 6094,  928,  322, 1984, 1839,   83,\n",
      "         3678, 2752, 4697, 5776, 3200,   47, 1802, 2047, 1309,   82, 5076,  552,\n",
      "         3502, 1864,  871, 4538, 2236, 1689, 7283, 2391,  914, 6851,  971, 3847,\n",
      "         1658,  808,  871, 1714, 1048, 3512, 1542, 2340, 1923, 7950, 1234, 1068,\n",
      "         2594, 2250, 2353, 4228, 6540,  679, 1352, 2474, 1637,   22, 2467, 2880,\n",
      "         1039, 3372, 5574, 2538, 1451, 3265, 2146, 3724, 1284, 1356, 3160,  107,\n",
      "          763, 1109, 3183, 1116, 2139,  785, 2500, 1214, 2184, 1128, 4757, 4125,\n",
      "         1131,   26, 4087,  428, 2951, 2347, 1161,  388,  647, 7583,  625, 1762,\n",
      "         1708, 7135, 4529, 4424, 2968, 3529,  374, 2581,  191, 3397, 2882, 1950,\n",
      "         7919,  499, 4320, 3517, 5354, 2955, 3494,  903, 3280,  539, 7703, 6277,\n",
      "         1053,  373, 2033, 2482,  947, 3198, 1631, 1206, 1732, 5663,   25,  380,\n",
      "         1994,  492, 5350,  595,  443,  922, 7953, 4667,  217,  346, 3140, 3193,\n",
      "           30, 2567, 1698, 3900, 6880,  933, 1848,  793,  317, 3810,   54,  232,\n",
      "         3791, 2670, 1954, 1659, 2566, 5826, 2670, 1118, 2674, 2903, 3955, 1075,\n",
      "         1317,  406, 2158, 1380,   24, 3685, 5946,  721,  362,  793, 1872, 1511,\n",
      "         3632,  416, 5327, 2389,    3, 3779,  125, 1380, 3066, 5993,  183, 3026,\n",
      "         1761, 1670, 5368,  784, 1036, 6462, 1827, 2817,  555, 1256, 4201, 3995,\n",
      "          842, 1666,  726, 2282, 7013, 1358, 1296,  383, 2810, 1050, 1942, 2412],\n",
      "        [   1,  252, 2281,  326,  883, 1261, 2581, 1143,  776, 2936, 2467, 4494,\n",
      "         1906, 4745,   87,  258, 1200, 4555, 4555, 5092,  768, 3331,  803, 1861,\n",
      "         2185,  189, 1952, 6817, 7962, 1877, 3331,  239,  519, 6137,  572, 1823,\n",
      "         1189, 1581, 2070, 3031, 1881, 2176, 2072, 5513,   80, 1321, 3990,  976,\n",
      "         2781,  581,  578,  514, 2427,  794, 4555, 1105,  829, 2282, 1790,  566,\n",
      "         4466,  496, 2220, 5306, 2116, 1352, 2029, 2807, 1606, 3385,  863,  107,\n",
      "          961, 1043, 2648, 6007, 2215,  793, 4637,  741, 4849, 1719, 4524, 2460,\n",
      "         1067, 1794, 1461, 3585, 1510, 6820,  509, 5268, 2930,  409, 3769, 2208,\n",
      "         1577, 7240,  739, 4279, 6148, 1297,  136, 1909, 2914, 7211, 4755, 3313,\n",
      "         2928, 4053, 7194, 4905, 3081, 3916, 1912, 1668,  885, 3066,  997, 1565,\n",
      "         2357, 5253, 3166, 1354,  742, 4306,   61, 4070, 2430,  976,  256,  453,\n",
      "         1836, 2291, 2223,  575,  900, 1091, 3218, 2611, 4611,  557, 3357, 1526,\n",
      "         1176,  109, 1894, 4384, 3352,  494, 4340,  310, 2022, 3627, 1291, 1700,\n",
      "          614, 2568, 2124, 1929, 1969, 3437, 3467, 2700, 3259, 1599, 2302,  686,\n",
      "         4573,  509,  725, 5244, 6126, 2647, 1877,  845, 1877, 1552, 4880, 2263,\n",
      "         3073, 1253, 1156, 6368,  395, 4171, 3397, 4554,  282, 5591, 1345,  644,\n",
      "          802, 3805, 3792, 3434, 3953,  776, 3234, 1009, 1403, 6756, 2083, 3791,\n",
      "         1361,  129, 1877, 2419, 3050, 3004, 1553, 4552, 1239, 1716, 1477, 4238,\n",
      "         3125, 5266, 7945, 5489, 1684,  827, 3156, 3558,    6, 3485, 1589, 3212]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b595717d8e9a4ea496b6a3cd71c87c6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['attention_mask', 'input_ids', 'labels'])\n",
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'input_ids': tensor([[   1,  390,  817,  325,  881,  545, 4579, 2698, 3853,  400, 3222,  811,\n",
      "         5410,  757, 1580,  312, 2013, 1832,  689, 2295, 3041, 3967,  762, 5632,\n",
      "         2307, 4670, 3743,  300, 5307,  343, 2685, 3989, 5093, 4627, 4023,  771,\n",
      "         3396, 6661,  220,  379, 6834,  771, 3306, 1659, 4508, 5596, 2220, 2892,\n",
      "          461,    4, 2068, 1108, 1198, 2766, 2828, 1009,  585, 2566, 3824, 6189,\n",
      "          666, 1509, 5843, 1419,  172,  810, 4278,  931,  707, 4049,  470, 5006,\n",
      "         1181, 1208, 1271, 3306,  505, 3989, 4959, 3861,  356, 4102, 3154,  611],\n",
      "        [   1,  820, 1919, 4465, 1017, 1241, 4424, 2858, 1017,   53, 2874, 3400,\n",
      "         1248,  617,  737,   54,  409,  591,  924,   37, 4884, 6452, 1225, 3224,\n",
      "          378, 2301,  434, 6762,  663, 3534,   72, 4146,  464, 1098,   45, 1134,\n",
      "          348, 1982, 3944, 4862,  995,  485, 4882, 1472, 4226,   54,  995, 1209,\n",
      "         5196,  277, 1428,  582, 2211,  552,  784, 4702, 6476,  787, 3076,  236,\n",
      "          314, 5817, 1042, 1265,   61, 3873,  381, 2263, 5040,  330, 1234,  282,\n",
      "          742, 6747, 7776, 6029,  210, 4271, 5760,  907, 2704,  517, 5292, 1141],\n",
      "        [   1, 1171, 7708,   34, 4009, 1036, 3470,   74, 1039, 2396,  606, 2432,\n",
      "          337,  356,  402,  894, 1974,  212, 3452, 6420, 1611, 5894, 3857, 5713,\n",
      "         1353, 2464, 2909, 4248, 4887,   21, 5170, 2999, 5670, 3389,  729, 3524,\n",
      "         1726,  191,  337, 5388, 5772, 3095,  610,  946, 1610,  330,  339, 5085,\n",
      "         5794, 3690, 3926,  337, 1711, 7155, 6247,  306, 7910,    6,  845, 3122,\n",
      "         7642,  341,  846,  613,  416, 4251, 1209, 1946, 5173, 7705, 2679, 7705,\n",
      "          679, 1321, 4645, 1305,  716,  363,  790, 1968, 3273,  605,  101,  706],\n",
      "        [   1, 4052,   47,  516,   21, 1253, 1603, 1026, 1306, 4156, 4988,  661,\n",
      "         2514, 1590, 5005, 5831, 3966, 6830, 6751, 1786, 4531,  606, 2634, 1216,\n",
      "         1304, 4026, 4617,  383,  244,  412,  437,  947, 3502, 3457, 1408,  863,\n",
      "         2632, 1345,  383, 1905, 2024,  809, 1291, 5253, 2583, 1435,  903,   25,\n",
      "          804, 3076,  781, 2702,  137,   21,  500,  921,  891,  579, 1996, 3865,\n",
      "         1681, 1455,   22, 5327, 1399, 3981, 1424, 3171,   32, 2521, 1496,  838,\n",
      "         4514, 1324,  591, 2282,  483,  889, 7513,  276, 6409, 3009, 4022, 4962],\n",
      "        [   1,   28,  807, 6219,  114, 7396,  133, 4094, 2677,  791, 1501, 3151,\n",
      "         2209, 1532,  921,  867, 2447,  561, 2958, 7742, 1086, 5403, 3735, 4276,\n",
      "         5093,  998, 2591, 3703, 3297, 7128, 2520, 3234,  183, 2091, 2077,  970,\n",
      "          291,  519, 1742,  869, 2382,   33,  953, 2084, 2341,    3, 1365, 2507,\n",
      "         5127, 2217, 2430,  262, 3214, 4115, 3266,  381, 5441,  425, 5146, 4858,\n",
      "         1218,  426, 4543, 1727, 5532, 4994, 5937, 3778, 2912, 6576, 3879, 4238,\n",
      "         2751, 1493, 1522, 1090, 1214,  498, 6998,  137, 2846,  480,  366,  324],\n",
      "        [   1, 7322,  680,  648, 3056,  449,  634,  607, 1337, 3661, 1483,  599,\n",
      "          875, 1645, 3648,   47,  409, 3993, 2543, 1437,  317, 6480, 2885,  577,\n",
      "          478, 2763,  934, 1639, 4523, 1769, 7046, 3417, 1386,  620, 1788, 1711,\n",
      "         6623,  774, 6154, 1438, 3898,  505, 4123, 1321, 5935,   29, 1754,  878,\n",
      "         1755, 4279, 1447, 1102,  724, 1263, 5214,  618, 3792,  486,  342, 4051,\n",
      "         2855, 1510, 1531, 4306,  715,  136, 1182, 3362, 1651, 1342, 2957,  424,\n",
      "           65, 3007, 4999, 2133, 3529, 2606,  647, 1214, 3637, 2996, 5330, 6755]],\n",
      "       device='cuda:0'), 'labels': tensor([[   1,  390,  817,  325,  881,  545, 4579, 2698, 3853,  400, 3222,  811,\n",
      "         5410,  757, 1580,  312, 2013, 1832,  689, 2295, 3041, 3967,  762, 5632,\n",
      "         2307, 4670, 3743,  300, 5307,  343, 2685, 3989, 5093, 4627, 4023,  771,\n",
      "         3396, 6661,  220,  379, 6834,  771, 3306, 1659, 4508, 5596, 2220, 2892,\n",
      "          461,    4, 2068, 1108, 1198, 2766, 2828, 1009,  585, 2566, 3824, 6189,\n",
      "          666, 1509, 5843, 1419,  172,  810, 4278,  931,  707, 4049,  470, 5006,\n",
      "         1181, 1208, 1271, 3306,  505, 3989, 4959, 3861,  356, 4102, 3154,  611],\n",
      "        [   1,  820, 1919, 4465, 1017, 1241, 4424, 2858, 1017,   53, 2874, 3400,\n",
      "         1248,  617,  737,   54,  409,  591,  924,   37, 4884, 6452, 1225, 3224,\n",
      "          378, 2301,  434, 6762,  663, 3534,   72, 4146,  464, 1098,   45, 1134,\n",
      "          348, 1982, 3944, 4862,  995,  485, 4882, 1472, 4226,   54,  995, 1209,\n",
      "         5196,  277, 1428,  582, 2211,  552,  784, 4702, 6476,  787, 3076,  236,\n",
      "          314, 5817, 1042, 1265,   61, 3873,  381, 2263, 5040,  330, 1234,  282,\n",
      "          742, 6747, 7776, 6029,  210, 4271, 5760,  907, 2704,  517, 5292, 1141],\n",
      "        [   1, 1171, 7708,   34, 4009, 1036, 3470,   74, 1039, 2396,  606, 2432,\n",
      "          337,  356,  402,  894, 1974,  212, 3452, 6420, 1611, 5894, 3857, 5713,\n",
      "         1353, 2464, 2909, 4248, 4887,   21, 5170, 2999, 5670, 3389,  729, 3524,\n",
      "         1726,  191,  337, 5388, 5772, 3095,  610,  946, 1610,  330,  339, 5085,\n",
      "         5794, 3690, 3926,  337, 1711, 7155, 6247,  306, 7910,    6,  845, 3122,\n",
      "         7642,  341,  846,  613,  416, 4251, 1209, 1946, 5173, 7705, 2679, 7705,\n",
      "          679, 1321, 4645, 1305,  716,  363,  790, 1968, 3273,  605,  101,  706],\n",
      "        [   1, 4052,   47,  516,   21, 1253, 1603, 1026, 1306, 4156, 4988,  661,\n",
      "         2514, 1590, 5005, 5831, 3966, 6830, 6751, 1786, 4531,  606, 2634, 1216,\n",
      "         1304, 4026, 4617,  383,  244,  412,  437,  947, 3502, 3457, 1408,  863,\n",
      "         2632, 1345,  383, 1905, 2024,  809, 1291, 5253, 2583, 1435,  903,   25,\n",
      "          804, 3076,  781, 2702,  137,   21,  500,  921,  891,  579, 1996, 3865,\n",
      "         1681, 1455,   22, 5327, 1399, 3981, 1424, 3171,   32, 2521, 1496,  838,\n",
      "         4514, 1324,  591, 2282,  483,  889, 7513,  276, 6409, 3009, 4022, 4962],\n",
      "        [   1,   28,  807, 6219,  114, 7396,  133, 4094, 2677,  791, 1501, 3151,\n",
      "         2209, 1532,  921,  867, 2447,  561, 2958, 7742, 1086, 5403, 3735, 4276,\n",
      "         5093,  998, 2591, 3703, 3297, 7128, 2520, 3234,  183, 2091, 2077,  970,\n",
      "          291,  519, 1742,  869, 2382,   33,  953, 2084, 2341,    3, 1365, 2507,\n",
      "         5127, 2217, 2430,  262, 3214, 4115, 3266,  381, 5441,  425, 5146, 4858,\n",
      "         1218,  426, 4543, 1727, 5532, 4994, 5937, 3778, 2912, 6576, 3879, 4238,\n",
      "         2751, 1493, 1522, 1090, 1214,  498, 6998,  137, 2846,  480,  366,  324],\n",
      "        [   1, 7322,  680,  648, 3056,  449,  634,  607, 1337, 3661, 1483,  599,\n",
      "          875, 1645, 3648,   47,  409, 3993, 2543, 1437,  317, 6480, 2885,  577,\n",
      "          478, 2763,  934, 1639, 4523, 1769, 7046, 3417, 1386,  620, 1788, 1711,\n",
      "         6623,  774, 6154, 1438, 3898,  505, 4123, 1321, 5935,   29, 1754,  878,\n",
      "         1755, 4279, 1447, 1102,  724, 1263, 5214,  618, 3792,  486,  342, 4051,\n",
      "         2855, 1510, 1531, 4306,  715,  136, 1182, 3362, 1651, 1342, 2957,  424,\n",
      "           65, 3007, 4999, 2133, 3529, 2606,  647, 1214, 3637, 2996, 5330, 6755]],\n",
      "       device='cuda:0')}\n",
      "torch.Size([6, 84])\n",
      "train tensor(9.1518, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(9431.2861, grad_fn=<ExpBackward0>) 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "923ffc4249aa4b53a282fc57245a93fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val tensor(9.1401) tensor(9321.6484) 0.0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from protllama.bin.data import PretrainDataset\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, TQDMProgressBar, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# set wandb offline on HPC\n",
    "os.environ['WANDB_MODE'] = \"offline\"\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "hparam = SimpleNamespace(\n",
    "    date='Oct_11',\n",
    "    target='protein',\n",
    "    max_position_embeddings=512,\n",
    "    vocab_size='8k',\n",
    "    hidden_size=640,\n",
    "    intermediate_size=1720,\n",
    "    save_top_k=1,\n",
    "    scheduler='linear',\n",
    "    learning_rate=3e-4,\n",
    "    epoch=1\n",
    "    #... add all other arguments similarly\n",
    ")\n",
    "\n",
    "\n",
    "#dm = PretrainDataset(target=hparam.target,\n",
    "                     #max_sequence_length=hparam.max_position_embeddings)\n",
    "data_module = CustomDataModule(dataset_dict=small_dataset_dict,\n",
    "                               batch_indices_train=batch_indices_train,\n",
    "                               batch_indices_val=batch_indices_val,\n",
    "                               batch_size=1)\n",
    "\n",
    "# make sure dataset has \"training\" key\n",
    "hparam.train_dataset_length = 10\n",
    "training_log_path = str('protllama/pl_logs/')\n",
    "if not os.path.exists(training_log_path):\n",
    "    os.makedirs(training_log_path)\n",
    "logger = WandbLogger(project=\"protllama2\",\n",
    "                     name=f\"{hparam.target}_{hparam.date}_pre-training_log\", #display on the web\n",
    "                     save_dir='protllama/pl_logs/',\n",
    "                     job_type='model-training',\n",
    "                     group=f'pretrain_protllama2_{hparam.vocab_size}_{hparam.max_position_embeddings}',\n",
    "                     id='version_%s' % str(1))\n",
    "seed_everything(42)\n",
    "model = pretrainLlama(hparam)\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    min_delta=0.0,\n",
    "    patience=0,  # number of epoch with no improvement\n",
    "    verbose=True,\n",
    "    mode=\"min\",\n",
    ")\n",
    "training_model_path = str('protllama/pl_model_cache/')\n",
    "if not os.path.exists(training_model_path):\n",
    "    os.makedirs(training_model_path)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=training_model_path,\n",
    "    filename=\"{epoch}-{train_loss:.2f}-{val_loss:.2f}-%s_%s_%s_%s\" % (hparam.target, hparam.date, hparam.vocab_size, hparam.max_position_embeddings),\n",
    "    save_top_k=hparam.save_top_k,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(\n",
    "    logging_interval='epoch'\n",
    ")\n",
    "#os.environ[\"NCCL_SOCKET_IFNAME\"] = \"lo\"  # Or another interface if not eth0\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0,1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_SOCKET_IFNAME\"] = \"eth0\"\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "os.environ[\"NCCL_PROTO\"] = \"TCP\"\n",
    "os.environ[\"NCCL_BLOCKING_WAIT\"] = \"1\"\n",
    "os.environ[\"NCCL_DEBUG_SUBSYS\"] = \"ALL\"\n",
    "\n",
    "print(\"About to initialize the Trainer...\")\n",
    "trainer = Trainer(\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    #strategy='ddp_notebook',\n",
    "    num_nodes=1,\n",
    "    fast_dev_run=True,\n",
    "    limit_train_batches=2,\n",
    "    max_epochs=1,\n",
    "    logger=logger,\n",
    "    # max_epochs=1,\n",
    "    # min_epochs=1,\n",
    "    #callbacks=[TQDMProgressBar(refresh_rate=10), lr_monitor],\n",
    "    #deterministic=True,\n",
    "    enable_model_summary=True\n",
    ")\n",
    "print(\"Trainer initialized.\")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "# automatic garbage collection\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "if torch.distributed.is_initialized():\n",
    "    print(f\"Process {torch.distributed.get_rank()} initialized\")\n",
    "\n",
    "trainer.fit(model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outputs = np.array([[5876, 5876, 5876, 5876, 5876, 2376, 2376, 2376, 2376, 2376, 2376, 2376,\n",
    "         2376, 2376, 5394, 2376, 2376, 2376, 5394,  547, 5394,  547,  547,  547,\n",
    "          547,  547, 5662,  547,  547,  547,  547,  547,  547,  547,  547,  547,\n",
    "          547,  547,  547,  547,  547,  547,  547,  547,  547,  547,  547,  547,\n",
    "          547,  547,  547,  547,  547,  547,  547,  547,  547,  547,  547,  547,\n",
    "          547,  547,  547,  547,  547,  547,  547,  547,  547,  547,  547,  547,\n",
    "          547,  547,  547,  547,  547,  547,  547,  547,  547,  547,  547]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "        shift_logits = outputs[1][..., :-1, :].contiguous().argmax(\n",
    "            dim=-1).cpu()  # Ensure outputs and argmax result are on CPU\n",
    "        if verbose:\n",
    "            print('model predict?')\n",
    "            print(shift_logits)\n",
    "\n",
    "        # Assuming 'labels' is a key in batch containing true token IDs\n",
    "        shift_labels = batch['labels'][..., 1:].contiguous().cpu()  # Move labels to CPU\n",
    "        if verbose:\n",
    "            print('model true?')\n",
    "            print(shift_logits)\n",
    "\n",
    "        non_padding_mask = shift_labels != -100\n",
    "\n",
    "        # Compare predictions to true labels, but only for non-padding tokens\n",
    "        acc_train = ((shift_logits == shift_labels) & non_padding_mask).sum().item() / non_padding_mask.sum().item()\n",
    "        if verbose:\n",
    "            print(acc_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# batch indices\n",
    "with open('/data/rozen/home/e0833634/lama/protllama/batch_script/train_intermediate_checkpoint_batches_1000000.pkl', 'rb') as f:\n",
    "    batch_indices_train = pickle.load(f)\n",
    "# batch indices\n",
    "with open('/data/rozen/home/e0833634/lama/protllama/batch_script/valid_intermediate_checkpoint_batches_1000000.pkl', 'rb') as f:\n",
    "    batch_indices_valid = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(batch_indices_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(batch_indices_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build smaller test set\n",
    "small_batches = [batch for batch in batch_indices_train if all(idx < 1000 for idx in batch)]\n",
    "small_batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_indices = small_batches\n",
    "train_dataset = CustomDataset(dataset, batch_indices)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=None, shuffle=False)  # Note that batch_size is None because your dataset itself is returning batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Flatten the batch indices to select the data from the original dataset\n",
    "flat_indices = [idx for batch in small_batches for idx in batch]\n",
    "\n",
    "# Create the shrunken dataset using the flattened indices\n",
    "shrunken_dataset_train = dataset[\"train\"].select(flat_indices)\n",
    "\n",
    "# Create a mapping from original indices to their position in the shrunken dataset\n",
    "index_mapping = {original_idx: shrunken_idx for shrunken_idx, original_idx in enumerate(flat_indices)}\n",
    "\n",
    "# Define the custom collate function\n",
    "def collate_fn(batch_indices_list):\n",
    "    # Convert the original indices to shrunken dataset indices\n",
    "    mapped_indices = [index_mapping[idx] for idx_list in batch_indices_list for idx in idx_list]\n",
    "\n",
    "    batch_ = {\n",
    "        'attention_mask': [shrunken_dataset_train['attention_mask'][i] for i in mapped_indices],\n",
    "        'input_ids': [shrunken_dataset_train['input_ids'][i] for i in mapped_indices],\n",
    "        'labels': [shrunken_dataset_train['labels'][i] for i in mapped_indices]\n",
    "    }\n",
    "    return batch_\n",
    "\n",
    "# Custom Dataset to wrap the batch indices\n",
    "class BatchedDataset(Dataset):\n",
    "    def __init__(self, batch_indices):\n",
    "        self.batch_indices = batch_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.batch_indices[idx]\n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(BatchedDataset(small_batches), batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Usage\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(small_batches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flattened_list = [num for sublist in small_batches for num in sublist]\n",
    "mapping_dict = {num: idx for idx, num in enumerate(flattened_list)}\n",
    "mapping_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(mapping_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build smaller test set\n",
    "small_batches_valid = [batch for batch in batch_indices_valid if all(idx < 1000 for idx in batch)]\n",
    "small_batches_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(small_batches_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flattened_list_valid = [num for sublist in small_batches_valid for num in sublist]\n",
    "mapping_dict_valid = {num: idx for idx, num in enumerate(flattened_list_valid)}\n",
    "mapping_dict_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mapping_dict_valid[787]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for batch in small_batches:\n",
    "    print(dataset[\"train\"].select(batch))\n",
    "    print(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "small_datasets_train = [dataset[\"train\"].select(batch) for batch in small_batches]\n",
    "small_datasets_valid = [dataset[\"valid\"].select(batch) for batch in small_batches_valid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "small_train_dataset = concatenate_datasets(small_datasets_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "small_valid_dataset = concatenate_datasets(small_datasets_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use list comprehension to get all small datasets and then concatenate them\n",
    "dataset_ = DatasetDict({\n",
    "            'train': small_train_dataset,\n",
    "            'valid': small_valid_dataset\n",
    "        })\n",
    "dataset_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "small_batches[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_['train']['original_index']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in dataset_['train']['original_index']:\n",
    "    if i == 819:\n",
    "        print(dataset_['train']['input_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "small_batches[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mapping_table[181]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_indices = [mapping_table[idx] for idx in small_batches[0]]\n",
    "original_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_indices = [mapping_dict[idx] for idx in small_batches[1]]\n",
    "original_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "small_batches[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mapping_dict[181]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(dataset_['train']['attention_mask'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[dataset_[split_name]['input_ids'][i] for i in small_batches[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def collate_fn(batch_indices, split_name):\n",
    "    # Use the mapping table to get the original indices\n",
    "    mapped_indices = [mapping_dict[idx] for idx in batch_indices[0]]\n",
    "\n",
    "    batch_ = {\n",
    "        'attention_mask': [dataset_[split_name]['attention_mask'][i] for i in mapped_indices],\n",
    "        'input_ids': [dataset_[split_name]['input_ids'][i] for i in mapped_indices],\n",
    "        'labels': [dataset_[split_name]['labels'][i] for i in mapped_indices]\n",
    "    }\n",
    "    return batch_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def collate_fn(batch_indices, split_name):\n",
    "        # Given a list of indices, retrieve the corresponding batch from your HuggingFace Dataset\n",
    "    batch_ = {\n",
    "        'attention_mask': [dataset[split_name]['attention_mask'][i] for i in batch_indices[0]],\n",
    "        'input_ids': [dataset[split_name]['input_ids'][i] for i in batch_indices[0]],\n",
    "        'labels': [dataset[split_name]['labels'][i] for i in batch_indices[0]]\n",
    "    }\n",
    "    return batch_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['train']['input_ids'][435]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "train_dataloader = DataLoader(small_batches, batch_size=1, pin_memory=True, shuffle=False, num_workers=1,\n",
    "                                    collate_fn=partial(collate_fn, split_name='train'))\n",
    "train_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for batch in enumerate(train_dataloader):\n",
    "    print(batch)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}