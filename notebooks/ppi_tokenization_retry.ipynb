{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/rh-python38/root/usr/local/lib64/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "2023-10-19 10:57:38.108608: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import glob\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import pickle\n",
    "from datasets import Dataset, DatasetDict, load_from_disk, concatenate_datasets\n",
    "from functools import partial\n",
    "from transformers.models.llama.tokenization_llama import LlamaTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from pytorch_lightning import seed_everything\n",
    "import random\n",
    "import gc\n",
    "import h5py\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = '/data/rozen/home/e0833634/lama/data/ppi_8000'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0 UniProtID_1 UniProtID_2     symbol_1     symbol_2  \\\n0               4      Q8SYG2      O46106   CSN3_DROME    NOI_DROME   \n1              25      P38961      P38961   RRP8_YEAST   RRP8_YEAST   \n2              26      P38961      Q06142   RRP8_YEAST   IMB1_YEAST   \n3              27      P38961      Q02821   RRP8_YEAST   IMA1_YEAST   \n4              39      P38064      P12687   RM16_YEAST   RM02_YEAST   \n...           ...         ...         ...          ...          ...   \n49343      480409      Q05655      Q9NR28   KPCD_HUMAN  DBLOH_HUMAN   \n49344      480414      P00749      P05121   UROK_HUMAN   PAI1_HUMAN   \n49345      480416      P02930      P75831   TOLC_ECOLI   MACB_ECOLI   \n49346      480419      P26231      P14923  CTNA1_MOUSE   PLAK_HUMAN   \n49347      480485      O15357      P56945  SHIP2_HUMAN  BCAR1_HUMAN   \n\n                                                   seq_1  \\\n0      MGSALENYVNQVRTLSASGSYRELAEELPESLSLLARNWSILDNVL...   \n1      MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...   \n2      MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...   \n3      MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...   \n4      MFPYLTRMNLSIKMGGLTLKESSPNAFLNNTTIARRFKHEYAPRFK...   \n...                                                  ...   \n49343  MAPFLRIAFNSYELGSLQAEDEANQPFCAVKMKEALSTERGKTLVQ...   \n49344  MRALLARLLLCVLVVSDSKGSNELHQVPSNCDCLNGGTCVSNKYFS...   \n49345  MKKLLPILIGLSLSGFSSLSQAENLMQVYQQARLSNPELRKSAADR...   \n49346  MTAVHAGNINFKWDPKSLEIRTLAVERLLEPLVTQVTTLVNTNSKG...   \n49347  MASACGAPGPGGALGSQAPSWYHRDLSRAAAEELLARAGRDGSFLV...   \n\n                                                   seq_2  \\\n0      METLLEQQRRLHEERERLVKLMVDEHATKKPGEKERIHSEHRLKYL...   \n1      MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...   \n2      MSTAEFAQLLENSILSPDQNIRLTSETQLKKLSNDNFLQFAGLSSQ...   \n3      MDNGTDSSTSKFVPEYRRTNFKNKGRFSADELRRRRDTQQVELRKA...   \n4      MWNPILLDTSSFSFQKHVSGVFLQVRNATKRAAGSRTSMKDSAGRR...   \n...                                                  ...   \n49343  MAALKSWLSRSVTSFFRYRQCLCVPVVANFKKRCFSELIRPWHKTV...   \n49344  MQMSPALTCLVLGLALVFGEGSAVHHPPSYVAHLASDFGVRVFQQV...   \n49345  MTPLLELKDIRRSYPAGDEQVEVLKGISLDIYAGEMVAIVGASGSG...   \n49346  MEVMNLMEQPIKVTEWQQTYTYDSGIHSGANTCVPSVSSKGIMEED...   \n49347  MNHLNVLAKALYDNVAESPDELSFRKGDIMTVLEQDTQGLDGWWLC...   \n\n                                                     ppi  ppi_len cluster  \\\n0      MGSALENYVNQVRTLSASGSYRELAEELPESLSLLARNWSILDNVL...      948  Q8SYG2   \n1      MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...      784  P38961   \n2      MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...     1253  P38961   \n3      MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...      934  P38961   \n4      MFPYLTRMNLSIKMGGLTLKESSPNAFLNNTTIARRFKHEYAPRFK...      603  P38064   \n...                                                  ...      ...     ...   \n49343  MAPFLRIAFNSYELGSLQAEDEANQPFCAVKMKEALSTERGKTLVQ...      915  Q9WTQ0   \n49344  MRALLARLLLCVLVVSDSKGSNELHQVPSNCDCLNGGTCVSNKYFS...      833  P06869   \n49345  MKKLLPILIGLSLSGFSSLSQAENLMQVYQQARLSNPELRKSAADR...     1141  P02930   \n49346  MTAVHAGNINFKWDPKSLEIRTLAVERLLEPLVTQVTTLVNTNSKG...     1651  P26232   \n49347  MASACGAPGPGGALGSQAPSWYHRDLSRAAAEELLARAGRDGSFLV...     2128  O15357   \n\n       cluster_size  \n0                 4  \n1                 1  \n2                 1  \n3                 1  \n4                 1  \n...             ...  \n49343             6  \n49344             2  \n49345             1  \n49346             5  \n49347             2  \n\n[49348 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>UniProtID_1</th>\n      <th>UniProtID_2</th>\n      <th>symbol_1</th>\n      <th>symbol_2</th>\n      <th>seq_1</th>\n      <th>seq_2</th>\n      <th>ppi</th>\n      <th>ppi_len</th>\n      <th>cluster</th>\n      <th>cluster_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>Q8SYG2</td>\n      <td>O46106</td>\n      <td>CSN3_DROME</td>\n      <td>NOI_DROME</td>\n      <td>MGSALENYVNQVRTLSASGSYRELAEELPESLSLLARNWSILDNVL...</td>\n      <td>METLLEQQRRLHEERERLVKLMVDEHATKKPGEKERIHSEHRLKYL...</td>\n      <td>MGSALENYVNQVRTLSASGSYRELAEELPESLSLLARNWSILDNVL...</td>\n      <td>948</td>\n      <td>Q8SYG2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n      <td>P38961</td>\n      <td>P38961</td>\n      <td>RRP8_YEAST</td>\n      <td>RRP8_YEAST</td>\n      <td>MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...</td>\n      <td>MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...</td>\n      <td>MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...</td>\n      <td>784</td>\n      <td>P38961</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26</td>\n      <td>P38961</td>\n      <td>Q06142</td>\n      <td>RRP8_YEAST</td>\n      <td>IMB1_YEAST</td>\n      <td>MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...</td>\n      <td>MSTAEFAQLLENSILSPDQNIRLTSETQLKKLSNDNFLQFAGLSSQ...</td>\n      <td>MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...</td>\n      <td>1253</td>\n      <td>P38961</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27</td>\n      <td>P38961</td>\n      <td>Q02821</td>\n      <td>RRP8_YEAST</td>\n      <td>IMA1_YEAST</td>\n      <td>MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...</td>\n      <td>MDNGTDSSTSKFVPEYRRTNFKNKGRFSADELRRRRDTQQVELRKA...</td>\n      <td>MALFNVEGWSIKTKTVAFDNKTNKSSKDKKKNNRKNGKLTREQKLK...</td>\n      <td>934</td>\n      <td>P38961</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39</td>\n      <td>P38064</td>\n      <td>P12687</td>\n      <td>RM16_YEAST</td>\n      <td>RM02_YEAST</td>\n      <td>MFPYLTRMNLSIKMGGLTLKESSPNAFLNNTTIARRFKHEYAPRFK...</td>\n      <td>MWNPILLDTSSFSFQKHVSGVFLQVRNATKRAAGSRTSMKDSAGRR...</td>\n      <td>MFPYLTRMNLSIKMGGLTLKESSPNAFLNNTTIARRFKHEYAPRFK...</td>\n      <td>603</td>\n      <td>P38064</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49343</th>\n      <td>480409</td>\n      <td>Q05655</td>\n      <td>Q9NR28</td>\n      <td>KPCD_HUMAN</td>\n      <td>DBLOH_HUMAN</td>\n      <td>MAPFLRIAFNSYELGSLQAEDEANQPFCAVKMKEALSTERGKTLVQ...</td>\n      <td>MAALKSWLSRSVTSFFRYRQCLCVPVVANFKKRCFSELIRPWHKTV...</td>\n      <td>MAPFLRIAFNSYELGSLQAEDEANQPFCAVKMKEALSTERGKTLVQ...</td>\n      <td>915</td>\n      <td>Q9WTQ0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>49344</th>\n      <td>480414</td>\n      <td>P00749</td>\n      <td>P05121</td>\n      <td>UROK_HUMAN</td>\n      <td>PAI1_HUMAN</td>\n      <td>MRALLARLLLCVLVVSDSKGSNELHQVPSNCDCLNGGTCVSNKYFS...</td>\n      <td>MQMSPALTCLVLGLALVFGEGSAVHHPPSYVAHLASDFGVRVFQQV...</td>\n      <td>MRALLARLLLCVLVVSDSKGSNELHQVPSNCDCLNGGTCVSNKYFS...</td>\n      <td>833</td>\n      <td>P06869</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>49345</th>\n      <td>480416</td>\n      <td>P02930</td>\n      <td>P75831</td>\n      <td>TOLC_ECOLI</td>\n      <td>MACB_ECOLI</td>\n      <td>MKKLLPILIGLSLSGFSSLSQAENLMQVYQQARLSNPELRKSAADR...</td>\n      <td>MTPLLELKDIRRSYPAGDEQVEVLKGISLDIYAGEMVAIVGASGSG...</td>\n      <td>MKKLLPILIGLSLSGFSSLSQAENLMQVYQQARLSNPELRKSAADR...</td>\n      <td>1141</td>\n      <td>P02930</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49346</th>\n      <td>480419</td>\n      <td>P26231</td>\n      <td>P14923</td>\n      <td>CTNA1_MOUSE</td>\n      <td>PLAK_HUMAN</td>\n      <td>MTAVHAGNINFKWDPKSLEIRTLAVERLLEPLVTQVTTLVNTNSKG...</td>\n      <td>MEVMNLMEQPIKVTEWQQTYTYDSGIHSGANTCVPSVSSKGIMEED...</td>\n      <td>MTAVHAGNINFKWDPKSLEIRTLAVERLLEPLVTQVTTLVNTNSKG...</td>\n      <td>1651</td>\n      <td>P26232</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>49347</th>\n      <td>480485</td>\n      <td>O15357</td>\n      <td>P56945</td>\n      <td>SHIP2_HUMAN</td>\n      <td>BCAR1_HUMAN</td>\n      <td>MASACGAPGPGGALGSQAPSWYHRDLSRAAAEELLARAGRDGSFLV...</td>\n      <td>MNHLNVLAKALYDNVAESPDELSFRKGDIMTVLEQDTQGLDGWWLC...</td>\n      <td>MASACGAPGPGGALGSQAPSWYHRDLSRAAAEELLARAGRDGSFLV...</td>\n      <td>2128</td>\n      <td>O15357</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>49348 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path+'/ppigpt_test_merged_MI0915_LTPHTP_8000AA_oct10_2023.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "tokenizer_path = '/data/rozen/home/e0833634/lama/protllama/batch_script/'\n",
    "tokenizer = spm.SentencePieceProcessor(model_file=tokenizer_path+\"protein_8k.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = tokenizer.unk_id()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[523, 33, 897, 3046, 5765, 0, 5607]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('METLLEDYLHHFI<s>MET')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "49348"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1 = df['seq_1'].values.tolist()\n",
    "len(seq1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "49348"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2 = df['seq_2'].values.tolist()\n",
    "len(seq1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "        Unnamed: 0 UniProtID_1 UniProtID_2     symbol_1     symbol_2  \\\n0                0      P67809      Q13242  YBOX1_HUMAN  SRSF9_HUMAN   \n1                1      Q8NER1      Q86SS6  TRPV1_HUMAN   SYT9_HUMAN   \n2                2      O75319      Q13242  DUS11_HUMAN  SRSF9_HUMAN   \n3                3      Q9W3N6      Q8SYG2   USO1_DROME   CSN3_DROME   \n4                5      Q9W0S8      Q9VKD6   WAGC_DROME   DGT2_DROME   \n...            ...         ...         ...          ...          ...   \n431133      480480      P9WNU1      P9WNT5  DPO3B_MYCTU  DNAE2_MYCTU   \n431134      480481      P9WNU1      P9WNT7  DPO3B_MYCTU  DPO3A_MYCTU   \n431135      480482      P9WNU1      P9WNT3  DPO3B_MYCTU  DPO41_MYCTU   \n431136      480483      P05648      P45707   DNAA_BACSU   SIRA_BACSU   \n431137      480484      P02919      P0ABG4   PBPB_ECOLI   FTSW_ECOLI   \n\n                                                    seq_1  \\\n0       MSSEAETQQPPAAPPAAPALSAADTKPGTTGSGAGSGGPGGLTSAA...   \n1       MKKWSSTDLGAAADPLQKDTCPDPLDGDPNSRPPPAKPQLSTAKSR...   \n2       MRNSETLERGVGGCRVFSCLGSYPGIEGAGLALLADLALGGRLLGT...   \n3       MEFLKSGIKTVLGSTEPGQQPSAAETVEKLVDRVYSSTLLEDRRDA...   \n4       MQNLKIQEEVNSLMRLGQHFDDQLKLASVELGDFSDDDLALLDKCA...   \n...                                                   ...   \n431133  MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...   \n431134  MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...   \n431135  MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...   \n431136  MENILDLWNQALAQIEKKLSKPSFETWMKSTKAHSLQGDTLTITAP...   \n431137  MAGNDREPIGRKGKPTRPVKQKVSRRRYEDDDDYDDYDDYEDEEPM...   \n\n                                                    seq_2  \\\n0       MSGWADERGGEGDGRIYVGNLPTDVREKDLEDLFYKYGRIREIELK...   \n1       MPGARDALCHQALQLLAELCARGALEHDSCQDFIYHLRDRARPRLR...   \n2       MSGWADERGGEGDGRIYVGNLPTDVREKDLEDLFYKYGRIREIELK...   \n3       MGSALENYVNQVRTLSASGSYRELAEELPESLSLLARNWSILDNVL...   \n4       MDDPSATLLPEHSEDLRLARDAELKKVLKLKLVLDELRRLDVGPNP...   \n...                                                   ...   \n431133  MFDILWNVGWSNGPPSWAEMERVLNGKPRHAGVPAFDADGDVPRSR...   \n431134  MSGSSAGSSFVHLHNHTEYSMLDGAAKITPMLAEVERLGMPAVGMT...   \n431135  MESRWVLHLDMDAFFASVEQLTRPTLRGRPVLVGGLGGRGVVAGAS...   \n431136  MERHYYTYLIKEEFANHYFGRESVMFELFQDYHWTSLEKQQYEMTE...   \n431137  MRLSLPRLKMPRLPGFSILVWISTALKGWVMGSREKDTDSLIMYDR...   \n\n                                                      ppi  ppi_len cluster  \\\n0       MSSEAETQQPPAAPPAAPALSAADTKPGTTGSGAGSGGPGGLTSAA...      545  P16989   \n1       MKKWSSTDLGAAADPLQKDTCPDPLDGDPNSRPPPAKPQLSTAKSR...     1330  Q8NER1   \n2       MRNSETLERGVGGCRVFSCLGSYPGIEGAGLALLADLALGGRLLGT...      598  O75319   \n3       MEFLKSGIKTVLGSTEPGQQPSAAETVEKLVDRVYSSTLLEDRRDA...     1281  O60763   \n4       MQNLKIQEEVNSLMRLGQHFDDQLKLASVELGDFSDDDLALLDKCA...      394  Q9W0S8   \n...                                                   ...      ...     ...   \n431133  MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...     1500  P9WNU1   \n431134  MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...     1586  P9WNU1   \n431135  MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...      870  P9WNU1   \n431136  MENILDLWNQALAQIEKKLSKPSFETWMKSTKAHSLQGDTLTITAP...      594  P05648   \n431137  MAGNDREPIGRKGKPTRPVKQKVSRRRYEDDDDYDDYDDYEDEEPM...     1258  P02919   \n\n        cluster_size  \n0                  6  \n1                  2  \n2                  1  \n3                  4  \n4                  1  \n...              ...  \n431133             1  \n431134             1  \n431135             1  \n431136             1  \n431137             1  \n\n[431138 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>UniProtID_1</th>\n      <th>UniProtID_2</th>\n      <th>symbol_1</th>\n      <th>symbol_2</th>\n      <th>seq_1</th>\n      <th>seq_2</th>\n      <th>ppi</th>\n      <th>ppi_len</th>\n      <th>cluster</th>\n      <th>cluster_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>P67809</td>\n      <td>Q13242</td>\n      <td>YBOX1_HUMAN</td>\n      <td>SRSF9_HUMAN</td>\n      <td>MSSEAETQQPPAAPPAAPALSAADTKPGTTGSGAGSGGPGGLTSAA...</td>\n      <td>MSGWADERGGEGDGRIYVGNLPTDVREKDLEDLFYKYGRIREIELK...</td>\n      <td>MSSEAETQQPPAAPPAAPALSAADTKPGTTGSGAGSGGPGGLTSAA...</td>\n      <td>545</td>\n      <td>P16989</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Q8NER1</td>\n      <td>Q86SS6</td>\n      <td>TRPV1_HUMAN</td>\n      <td>SYT9_HUMAN</td>\n      <td>MKKWSSTDLGAAADPLQKDTCPDPLDGDPNSRPPPAKPQLSTAKSR...</td>\n      <td>MPGARDALCHQALQLLAELCARGALEHDSCQDFIYHLRDRARPRLR...</td>\n      <td>MKKWSSTDLGAAADPLQKDTCPDPLDGDPNSRPPPAKPQLSTAKSR...</td>\n      <td>1330</td>\n      <td>Q8NER1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>O75319</td>\n      <td>Q13242</td>\n      <td>DUS11_HUMAN</td>\n      <td>SRSF9_HUMAN</td>\n      <td>MRNSETLERGVGGCRVFSCLGSYPGIEGAGLALLADLALGGRLLGT...</td>\n      <td>MSGWADERGGEGDGRIYVGNLPTDVREKDLEDLFYKYGRIREIELK...</td>\n      <td>MRNSETLERGVGGCRVFSCLGSYPGIEGAGLALLADLALGGRLLGT...</td>\n      <td>598</td>\n      <td>O75319</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Q9W3N6</td>\n      <td>Q8SYG2</td>\n      <td>USO1_DROME</td>\n      <td>CSN3_DROME</td>\n      <td>MEFLKSGIKTVLGSTEPGQQPSAAETVEKLVDRVYSSTLLEDRRDA...</td>\n      <td>MGSALENYVNQVRTLSASGSYRELAEELPESLSLLARNWSILDNVL...</td>\n      <td>MEFLKSGIKTVLGSTEPGQQPSAAETVEKLVDRVYSSTLLEDRRDA...</td>\n      <td>1281</td>\n      <td>O60763</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Q9W0S8</td>\n      <td>Q9VKD6</td>\n      <td>WAGC_DROME</td>\n      <td>DGT2_DROME</td>\n      <td>MQNLKIQEEVNSLMRLGQHFDDQLKLASVELGDFSDDDLALLDKCA...</td>\n      <td>MDDPSATLLPEHSEDLRLARDAELKKVLKLKLVLDELRRLDVGPNP...</td>\n      <td>MQNLKIQEEVNSLMRLGQHFDDQLKLASVELGDFSDDDLALLDKCA...</td>\n      <td>394</td>\n      <td>Q9W0S8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>431133</th>\n      <td>480480</td>\n      <td>P9WNU1</td>\n      <td>P9WNT5</td>\n      <td>DPO3B_MYCTU</td>\n      <td>DNAE2_MYCTU</td>\n      <td>MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...</td>\n      <td>MFDILWNVGWSNGPPSWAEMERVLNGKPRHAGVPAFDADGDVPRSR...</td>\n      <td>MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...</td>\n      <td>1500</td>\n      <td>P9WNU1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>431134</th>\n      <td>480481</td>\n      <td>P9WNU1</td>\n      <td>P9WNT7</td>\n      <td>DPO3B_MYCTU</td>\n      <td>DPO3A_MYCTU</td>\n      <td>MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...</td>\n      <td>MSGSSAGSSFVHLHNHTEYSMLDGAAKITPMLAEVERLGMPAVGMT...</td>\n      <td>MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...</td>\n      <td>1586</td>\n      <td>P9WNU1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>431135</th>\n      <td>480482</td>\n      <td>P9WNU1</td>\n      <td>P9WNT3</td>\n      <td>DPO3B_MYCTU</td>\n      <td>DPO41_MYCTU</td>\n      <td>MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...</td>\n      <td>MESRWVLHLDMDAFFASVEQLTRPTLRGRPVLVGGLGGRGVVAGAS...</td>\n      <td>MDAATTRVGLTDLTFRLLRESFADAVSWVAKNLPARPAVPVLSGVL...</td>\n      <td>870</td>\n      <td>P9WNU1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>431136</th>\n      <td>480483</td>\n      <td>P05648</td>\n      <td>P45707</td>\n      <td>DNAA_BACSU</td>\n      <td>SIRA_BACSU</td>\n      <td>MENILDLWNQALAQIEKKLSKPSFETWMKSTKAHSLQGDTLTITAP...</td>\n      <td>MERHYYTYLIKEEFANHYFGRESVMFELFQDYHWTSLEKQQYEMTE...</td>\n      <td>MENILDLWNQALAQIEKKLSKPSFETWMKSTKAHSLQGDTLTITAP...</td>\n      <td>594</td>\n      <td>P05648</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>431137</th>\n      <td>480484</td>\n      <td>P02919</td>\n      <td>P0ABG4</td>\n      <td>PBPB_ECOLI</td>\n      <td>FTSW_ECOLI</td>\n      <td>MAGNDREPIGRKGKPTRPVKQKVSRRRYEDDDDYDDYDDYEDEEPM...</td>\n      <td>MRLSLPRLKMPRLPGFSILVWISTALKGWVMGSREKDTDSLIMYDR...</td>\n      <td>MAGNDREPIGRKGKPTRPVKQKVSRRRYEDDDDYDDYDDYEDEEPM...</td>\n      <td>1258</td>\n      <td>P02919</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>431138 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(path+'/ppigpt_train_merged_MI0915_LTPHTP_8000AA_oct10_2023.csv')\n",
    "df2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "431138"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1_train = df2['seq_1'].values.tolist()\n",
    "seq2_train  = df2['seq_2'].values.tolist()\n",
    "len(seq1_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['sequence_1', 'sequence_2'],\n        num_rows: 431138\n    })\n    valid: Dataset({\n        features: ['sequence_1', 'sequence_2'],\n        num_rows: 49348\n    })\n})"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict({'sequence_1': seq1_train,\n",
    "                                   'sequence_2': seq2_train})\n",
    "test_dataset = Dataset.from_dict({'sequence_1': seq1,\n",
    "                                  'sequence_2': seq2,})\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'valid': test_dataset\n",
    "})\n",
    "dataset_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['sequence_1', 'sequence_2'],\n        num_rows: 10\n    })\n    valid: Dataset({\n        features: ['sequence_1', 'sequence_2'],\n        num_rows: 10\n    })\n})"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset_dict = DatasetDict({\n",
    "    'train': dataset_dict['train'].select(range(10)),\n",
    "    'valid': dataset_dict['valid'].select(range(10))\n",
    "})\n",
    "small_dataset_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78c8c71b28e84bd693e7f25a641695f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0f7a90d28f946b69d8df46be3604a65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_dataset_dict.save_to_disk('/data/rozen/home/e0833634/lama/data/ppi_8000/ppi_8000_raw.hf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[[2, 3, 4, 5], [1, 2, 3, 4, 5, 6, 7]]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[2, 3, 4, 5], [1,2,3,4,5,6,7]]\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[[5, 4, 3, 2], [7, 6, 5, 4, 3, 2, 1]]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[seq[::-1] for seq in a]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "global_tokenizer = None\n",
    "\n",
    "\n",
    "def init_pool(tokenizer):\n",
    "    global global_tokenizer\n",
    "    tokenizer_path = '/data/rozen/home/e0833634/lama/protllama/batch_script/'\n",
    "    tokenizer = spm.SentencePieceProcessor(model_file=tokenizer_path+\"protein_8k.model\")\n",
    "    global_tokenizer = tokenizer\n",
    "\n",
    "\n",
    "def standalone_tokenize_function(tup, max_sequence_length, extra_toks_per_seq=2):\n",
    "    tokenizer_path = '/data/rozen/home/e0833634/lama/protllama/batch_script/'\n",
    "    tokenizer = spm.SentencePieceProcessor(model_file=tokenizer_path+\"protein_8k.model\")\n",
    "    global_tokenizer = tokenizer\n",
    "    s1, s2 = tup\n",
    "    try:\n",
    "        tokens_1 = global_tokenizer.encode(s1)\n",
    "        tokens_2 = global_tokenizer.encode(s2)\n",
    "        return tokens_1, tokens_2\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error during tokenization of string {s1} {s2}: {e}\")\n",
    "\n",
    "\n",
    "class TokenizeBatch(object):\n",
    "    \"\"\"add padding, create labels for GPT-alike training, used as collate_fn, need processed batch indices\n",
    "    processed (labels + tensor) batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer):\n",
    "        self.pad_token_id = tokenizer.unk_id()\n",
    "\n",
    "    def __call__(self, batches):\n",
    "        data_tokens = [torch.tensor(token_list) for token_list in batches]\n",
    "        data_tokens_padded = pad_sequence(data_tokens, batch_first=True, padding_value=self.pad_token_id)\n",
    "\n",
    "        # Create attention masks\n",
    "        attention_masks = (data_tokens_padded != self.pad_token_id).long()\n",
    "\n",
    "        # skip label==-100 during training so that these tokens won't be used in loss calculation\n",
    "        labels = data_tokens_padded.clone()\n",
    "        labels[data_tokens_padded == self.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': data_tokens_padded,\n",
    "            'attention_mask': attention_masks,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "\n",
    "class BatchedPPIDataset(object):\n",
    "    \"\"\"inspired by esm2, but instead of sorting the original sequences,\n",
    "    we should really sorting based on tokenized sequences\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sequence_strs, tokenizer, max_sequence_length):\n",
    "        self.batch_indices = None\n",
    "        self.sequence_str_1 = sequence_strs['sequence_1']\n",
    "        self.sequence_str_2 = sequence_strs['sequence_2']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.tokenized_sequences = []\n",
    "        self.accumulated_length = 0\n",
    "        # automatically tokenize sequences upon creation of the object\n",
    "        # if need manual, change it to call object.tokenize_sequence() in a separate line\n",
    "\n",
    "    def tokenize_sequences_forward(self):\n",
    "        prot_tuples = list(zip(self.sequence_str_1, self.sequence_str_2))\n",
    "        tokenized_pairs  = []\n",
    "        for i in prot_tuples:\n",
    "            tokenized_pairs.append(standalone_tokenize_function(i, max_sequence_length=self.max_sequence_length))\n",
    "\n",
    "        for tokens_1, tokens_2 in tokenized_pairs:\n",
    "            seq_length = len(tokens_1) + len(tokens_2) + 2  # for both bos, eos tokens\n",
    "            if seq_length <= self.max_sequence_length:\n",
    "                forward_sequence = [self.tokenizer.bos_id()] + tokens_1 + [self.tokenizer.eos_id()] + tokens_2\n",
    "                self.tokenized_sequences.append(forward_sequence)\n",
    "        print(self.tokenized_sequences)\n",
    "\n",
    "    def tokenize_sequences_backward(self):\n",
    "        self.reversed_tokenized_sequences=[]\n",
    "        for sequence in self.tokenized_sequences:\n",
    "            eos_position = sequence.index(self.tokenizer.eos_id())\n",
    "            print('backward', sequence)\n",
    "            tokens_1 = sequence[1:eos_position]  # Extract tokens1 without bos and eos\n",
    "            tokens_2 = sequence[eos_position+1:] # Extract tokens2 after eos\n",
    "            reversed_sequence = [self.tokenizer.bos_id()] + tokens_2 + [self.tokenizer.eos_id()] + tokens_1\n",
    "            self.reversed_tokenized_sequences.append(reversed_sequence)\n",
    "        self.tokenized_sequences.extend(self.reversed_tokenized_sequences)\n",
    "\n",
    "    def process_all(self):\n",
    "        self.tokenize_sequences_forward()\n",
    "        forward_batches = self.process_chunk(self.tokenized_sequences, self.get_batch_indices())\n",
    "        offset = len(self.tokenized_sequences)\n",
    "        self.tokenize_sequences_backward()\n",
    "        backward_batches = self.process_chunk(self.tokenized_sequences, self.get_batch_indices(offset))\n",
    "        self.tokenized_sequences = []\n",
    "        combined_dataset = concatenate_datasets([forward_batches, backward_batches])\n",
    "        # shuffle the datasets overall again\n",
    "        shuffled_dataset = combined_dataset.shuffle()\n",
    "        return shuffled_dataset\n",
    "\n",
    "    def get_batch_indices(self, offset=0, end=None):\n",
    "        if end is None:\n",
    "            end=len(self.tokenized_sequences)\n",
    "        sizes = [(len(tokens), i) for i, tokens in enumerate(self.tokenized_sequences[offset:end])]\n",
    "        sizes = [(sz, idx + offset) for sz, idx in sizes]\n",
    "        sizes.sort()\n",
    "        batches = []\n",
    "        buf = []\n",
    "        current_buf_len = 0\n",
    "\n",
    "        def _flush_current_buf():\n",
    "            nonlocal current_buf_len, buf\n",
    "            if len(buf) == 0:\n",
    "                return\n",
    "            batches.append(buf)\n",
    "            buf = []\n",
    "            current_buf_len = 0\n",
    "            #print('my batches is:')\n",
    "            #print(batches)\n",
    "\n",
    "        for sz, i in sizes:\n",
    "            # sz already has the length of special tokens, handled at tokenization level\n",
    "            # check accumulative seq length in the buffer\n",
    "            if current_buf_len + sz > self.max_sequence_length:\n",
    "                _flush_current_buf()\n",
    "            buf.append(i)\n",
    "            current_buf_len += sz\n",
    "            #print('my buffer is:')\n",
    "            #print(buf)\n",
    "\n",
    "        _flush_current_buf()\n",
    "        return batches\n",
    "\n",
    "    def process_chunk(self, tokenized_sequences, batch_indices):\n",
    "        token_batch_fn = TokenizeBatch(self.tokenizer)\n",
    "        print(batch_indices)\n",
    "        processed_batches = [\n",
    "            token_batch_fn([tokenized_sequences[i] for i in batch]) for batch\n",
    "            in batch_indices]\n",
    "        assert len(processed_batches) == len(batch_indices)\n",
    "\n",
    "        # Shuffle together using a permutation\n",
    "        permutation = list(torch.randperm(len(processed_batches)))\n",
    "        processed_batches = [processed_batches[i] for i in permutation]\n",
    "\n",
    "        all_attention_masks = []\n",
    "        all_input_ids = []\n",
    "        all_labels = []\n",
    "\n",
    "        all_attention_masks.extend([batch['attention_mask'] for batch in processed_batches])\n",
    "        all_input_ids.extend([batch['input_ids'] for batch in processed_batches])\n",
    "        all_labels.extend([batch['labels'] for batch in processed_batches])\n",
    "\n",
    "        combined_dataset = Dataset.from_dict({\n",
    "            'attention_mask': all_attention_masks,\n",
    "            'input_ids': all_input_ids,\n",
    "            'labels': all_labels\n",
    "        })\n",
    "        print(combined_dataset)\n",
    "        return combined_dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['sequence_1', 'sequence_2'],\n    num_rows: 4\n})"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = ['GLTNAFIASAPAREVRYDGVITPANANYRFMGGDKGGSLTVGSHLTGSNMVTIGPMGVVVFTNNNDYTGNTFIMGGGTLQLGSNTAWGSLPN\\n',\n",
    "        'MDRLDFGGNGEAGSEVAPVPVSGQPVSSEQLFPLSPAQLGIWYAQHLDPQVPITIAQYVDLHGALDVEVLERASIDASHELGSGFLRIVERDGEPLQYV\\n',\n",
    "        'MDRLDFGGNGEAGSEVAPVPVSGQPVSSEQLFP\\n',\n",
    "        'MDRLDFGGGE\\n']\n",
    "text2 = ['MDRLDFGGGE\\n',\n",
    "        'MDRLDFGGNGEAGSEVAPVPVSGQPVSSEQLFPLSPAQLGIWYAQHLDPQVPITIAQYVDLHGALDVEVLERASIDASHELGSGFLRIVERDGEPLQYV\\n',\n",
    "        'MDRLDFGGNGEAGSEVAPVPVSGQPVSSEQLFP\\n',\n",
    "        'MDRLDFGE\\n']\n",
    "train_dataset = Dataset.from_dict({'sequence_1': text1,\n",
    "                                   'sequence_2': text2,})\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['sequence_1', 'sequence_2'],\n        num_rows: 431138\n    })\n    valid: Dataset({\n        features: ['sequence_1', 'sequence_2'],\n        num_rows: 49348\n    })\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset=load_from_disk(path+'/ppi_8000_raw.hf')\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m tokenizer_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/data/rozen/home/e0833634/lama/protllama/batch_script/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      3\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m spm\u001B[38;5;241m.\u001B[39mSentencePieceProcessor(model_file\u001B[38;5;241m=\u001B[39mtokenizer_path\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprotein_32k.model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mBatchedPPIDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m dataset\n",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36mBatchedPPIDataset.process_all\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_all\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 93\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize_sequences_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     94\u001B[0m     forward_batches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_chunk(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenized_sequences, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_batch_indices())\n\u001B[1;32m     95\u001B[0m     offset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenized_sequences)\n",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36mBatchedPPIDataset.tokenize_sequences_forward\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     70\u001B[0m tokenized_pairs  \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m prot_tuples:\n\u001B[0;32m---> 72\u001B[0m     tokenized_pairs\u001B[38;5;241m.\u001B[39mappend(\u001B[43mstandalone_tokenize_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_sequence_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_sequence_length\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tokens_1, tokens_2 \u001B[38;5;129;01min\u001B[39;00m tokenized_pairs:\n\u001B[1;32m     75\u001B[0m     seq_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(tokens_1) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlen\u001B[39m(tokens_2) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m  \u001B[38;5;66;03m# for both bos, eos tokens\u001B[39;00m\n",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36mstandalone_tokenize_function\u001B[0;34m(tup, max_sequence_length, extra_toks_per_seq)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstandalone_tokenize_function\u001B[39m(tup, max_sequence_length, extra_toks_per_seq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m     14\u001B[0m     tokenizer_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/data/rozen/home/e0833634/lama/protllama/batch_script/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 15\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mspm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSentencePieceProcessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer_path\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprotein_8k.model\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m     global_tokenizer \u001B[38;5;241m=\u001B[39m tokenizer\n\u001B[1;32m     17\u001B[0m     s1, s2 \u001B[38;5;241m=\u001B[39m tup\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/sentencepiece/__init__.py:218\u001B[0m, in \u001B[0;36mSentencePieceProcessor.Init\u001B[0;34m(self, model_file, model_proto, out_type, add_bos, add_eos, reverse, enable_sampling, nbest_size, alpha)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m alpha\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_file \u001B[38;5;129;01mor\u001B[39;00m model_proto:\n\u001B[0;32m--> 218\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLoad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_proto\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_proto\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/sentencepiece/__init__.py:367\u001B[0m, in \u001B[0;36mSentencePieceProcessor.Load\u001B[0;34m(self, model_file, model_proto)\u001B[0m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_proto:\n\u001B[1;32m    366\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLoadFromSerializedProto(model_proto)\n\u001B[0;32m--> 367\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLoadFromFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/sentencepiece/__init__.py:171\u001B[0m, in \u001B[0;36mSentencePieceProcessor.LoadFromFile\u001B[0;34m(self, arg)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mLoadFromFile\u001B[39m(\u001B[38;5;28mself\u001B[39m, arg):\n\u001B[0;32m--> 171\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_sentencepiece\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSentencePieceProcessor_LoadFromFile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "tokenizer_path = '/data/rozen/home/e0833634/lama/protllama/batch_script/'\n",
    "tokenizer = spm.SentencePieceProcessor(model_file=tokenizer_path+\"protein_32k.model\")\n",
    "dataset = BatchedPPIDataset(train_dataset['train'], tokenizer, 1024).process_all()\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 1 in Batch 1:\n",
      "Input IDs: [1, 854, 1642, 2494, 2, 854, 1642, 653, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Labels: [1, 854, 1642, 2494, 2, 854, 1642, 653, 91, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 2 in Batch 1:\n",
      "Input IDs: [1, 854, 1642, 653, 1279, 639, 86, 1195, 1214, 6817, 49, 141, 2076, 2, 854, 1642, 653, 1279, 639, 86, 1195, 1214, 6817, 49, 141, 2076]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [1, 854, 1642, 653, 1279, 639, 86, 1195, 1214, 6817, 49, 141, 2076, 2, 854, 1642, 653, 1279, 639, 86, 1195, 1214, 6817, 49, 141, 2076]\n",
      "--------------------------------------------------------------------------------\n",
      "Batch 2\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 1 in Batch 2:\n",
      "Input IDs: [1, 854, 1642, 653, 91, 2, 820, 814, 3992, 37, 1313, 7791, 245, 7689, 701, 4163, 6182, 1302, 4844, 7660, 1104, 3455, 2232, 4290, 2886, 2351, 2844, 3768, 4240, 2298, 3576, 1302, 828, 114, 2232, 43, 6101, 1894]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [1, 854, 1642, 653, 91, 2, 820, 814, 3992, 37, 1313, 7791, 245, 7689, 701, 4163, 6182, 1302, 4844, 7660, 1104, 3455, 2232, 4290, 2886, 2351, 2844, 3768, 4240, 2298, 3576, 1302, 828, 114, 2232, 43, 6101, 1894]\n",
      "--------------------------------------------------------------------------------\n",
      "Batch 3\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 1 in Batch 3:\n",
      "Input IDs: [1, 820, 814, 3992, 37, 1313, 7791, 245, 7689, 701, 4163, 6182, 1302, 4844, 7660, 1104, 3455, 2232, 4290, 2886, 2351, 2844, 3768, 4240, 2298, 3576, 1302, 828, 114, 2232, 43, 6101, 1894, 2, 854, 1642, 653, 91]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [1, 820, 814, 3992, 37, 1313, 7791, 245, 7689, 701, 4163, 6182, 1302, 4844, 7660, 1104, 3455, 2232, 4290, 2886, 2351, 2844, 3768, 4240, 2298, 3576, 1302, 828, 114, 2232, 43, 6101, 1894, 2, 854, 1642, 653, 91]\n",
      "--------------------------------------------------------------------------------\n",
      "Batch 4\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 1 in Batch 4:\n",
      "Input IDs: [1, 854, 1642, 653, 91, 2, 854, 1642, 2494, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Labels: [1, 854, 1642, 653, 91, 2, 854, 1642, 2494, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "--------------------------------------------------------------------------------\n",
      "Sample 2 in Batch 4:\n",
      "Input IDs: [1, 854, 1642, 653, 1279, 639, 86, 1195, 1214, 6817, 49, 141, 2076, 2, 854, 1642, 653, 1279, 639, 86, 1195, 1214, 6817, 49, 141, 2076]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [1, 854, 1642, 653, 1279, 639, 86, 1195, 1214, 6817, 49, 141, 2076, 2, 854, 1642, 653, 1279, 639, 86, 1195, 1214, 6817, 49, 141, 2076]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def visualize_batched_dataset(dataset, num_batches=5):\n",
    "    for batch_idx in range(min(num_batches, len(dataset))):\n",
    "        batch = dataset[batch_idx]\n",
    "        input_ids_batch = batch['input_ids']\n",
    "        attention_mask_batch = batch['attention_mask']\n",
    "        labels_batch = batch['labels']\n",
    "\n",
    "        print(f\"Batch {batch_idx + 1}\")\n",
    "        print(\"----\" * 20)\n",
    "\n",
    "        for seq_idx, input_ids in enumerate(input_ids_batch):\n",
    "            print(f\"Sample {seq_idx + 1} in Batch {batch_idx + 1}:\")\n",
    "            print(\"Input IDs:\", input_ids)\n",
    "            print(\"Attention Mask:\", attention_mask_batch[seq_idx])\n",
    "            print(\"Labels:\", labels_batch[seq_idx])\n",
    "            print(\"----\" * 20)\n",
    "# Call the function\n",
    "visualize_batched_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}